# utils_chatgpt.py
# Last modified: 2025-11-05 by Andr√©s Berm√∫dez

from openai import OpenAI
import logging
from typing import Any, Optional, Tuple, Dict
import os
import json
from utils import send_text_response, limpiar_respuesta_json, log_message

def get_openai_key() -> str:
    try:
        """Obtiene la clave API de OpenAI desde variables de entorno."""
        log_message('Iniciando funci√≥n <GetOpenAIKey>.', 'INFO')
        logging.info('Obteniendo clave de OpenAI')
        api_key: Optional[str] = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("No se encontr√≥ la clave OPENAI_API_KEY en las variables de entorno.")
        logging.info('Clave de OpenAI obtenida')
        log_message('Finalizando funci√≥n <GetOpenAIKey>.', 'INFO')
        return api_key
    except Exception as e:
        log_message(f"Error al obtener la clave de OpenAI: {e}", 'ERROR')
        logging.error(f"Error al obtener la clave de OpenAI: {e}")
        raise
    
def get_classifier(msj: str, sender: str) -> Tuple[Optional[str], Optional[str], Dict[str, Any]]:
    try:
        """Clasifica un mensaje de WhatsApp usando un modelo fine-tuned de OpenAI."""
        log_message('Iniciando funci√≥n <GetClassifier>.', 'INFO')
        logging.info('Clasificando mensaje')
        classification_prompt: str = """
        Eres un clasificador de mensajes para un asistente de WhatsApp de un restaurante.
        Tu tarea es identificar la **intenci√≥n (intent)**, el **tipo de mensaje (type)** y cualquier **entidad relevante (entities)**.
        Debes responder **√∫nicamente** en formato JSON v√°lido con la siguiente estructura:
        {
          "intent": "<una de las intenciones permitidas>",
          "type": "<tipo de mensaje>",
          "entities": { }
        }
        Lista de intenciones posibles:
        - confirmacion_general (puede ser en otros idiomas: yes, oui, ja, etc.)
        - consulta_menu
        - consulta_pedido
        - consulta_promociones
        - continuacion_pedido (puede ser en otros idiomas: yes, oui, ja, etc.)
        - direccion
        - info_personal
        - mas_datos_direccion
        - modificar_pedido
        - negacion_general (puede ser en otros idiomas: no, non, nein, etc.)
        - preguntas_generales
        - quejas (quejas de menor nivel: retraso en la entrega, mal servicio del domiciliario, problemas con la app, cocci√≥n desfasada solamente)
        - saludo
        - sin_intencion
        - solicitud_pedido
        - transferencia (quejas de mayor nivel: no entrega de domicilio, pedido equivocado, mal estado del pedido solamente)
        - validacion_pago

        Instrucciones importantes:
        - No incluyas texto fuera del JSON.
        - No uses comentarios, explicaciones o saltos de l√≠nea innecesarios.
        - Si no puedes determinar la intenci√≥n, usa "sin_intencion".
        """
        messages = [
            {"role": "system", "content": classification_prompt},
            {"role": "user", "content": msj}
        ]
        client: OpenAI = OpenAI(api_key=get_openai_key())
        respuesta: Any = client.chat.completions.create(
            model="ft:gpt-3.5-turbo-0125:net-applications:domicilios:CaSlaPnG",
            messages=messages,
            max_tokens=500,
            temperature=0
        )
        raw_response: str = respuesta.choices[0].message.content.strip()
        logging.info(f"[Clasificador RAW] {raw_response!r}")
        json_str: str = limpiar_respuesta_json(raw_response)
        result: Dict[str, Any] = json.loads(json_str)
        intent: Optional[str] = result.get("intent")
        type_: Optional[str] = result.get("type")
        entities: Dict[str, Any] = result.get("entities", {})
        if not intent or not type_:
            raise ValueError(f"Respuesta inv√°lida, faltan claves: {result}")
        logging.info(f"Respuesta del clasificador: {result}")
        logging.info(f"Intent: {intent}, Type: {type_}, Entities: {entities}")
        log_message('Finalizando funci√≥n <GetClassifier>.', 'INFO')
        return intent, type_, entities
    except Exception as e:
        log_message(f'Error al hacer uso de funci√≥n <GetClassifier>: {e}.', 'ERROR')
        logging.error(f"Error al clasificar el mensaje: {e}")
        send_text_response(sender, "Lo siento, hubo un error al procesar tu mensaje. ¬øPodr√≠as repetirlo?")
        return None, None, {}

def clasificar_pregunta_menu_chatgpt(pregunta_usuario: str, model: str = "gpt-3.5-turbo") -> dict:
    """
    Clasifica si una pregunta del usuario est√° relacionada con el men√∫ o con servicios
    del negocio (hamburgueser√≠a) usando un modelo de lenguaje (ChatGPT).
    """

    log_message('Iniciando funci√≥n <ClasificarPreguntaMenuChatGPT>.', 'INFO')
    client: OpenAI = OpenAI()

    prompt: str = f"""
    Eres un asistente que clasifica preguntas de clientes de una hamburgueser√≠a.

    Debes responder con un JSON EXACTO con la siguiente forma:
    {{
        "clasificacion": "relacionada" o "no_relacionada"
    }}

    Instrucciones:
    - Si la pregunta se refiere a comidas, hamburguesas, bebidas, malteadas, ingredientes, precios, combos,
      opciones vegetarianas o cualquier cosa del men√∫ ‚Üí "relacionada".
    - Tambi√©n clasifica como "relacionada" si el cliente pregunta sobre:
        ‚Ä¢ formas de pago (Nequi, Daviplata, efectivo, tarjetas, etc.)
        ‚Ä¢ si hacen domicilios o env√≠os
        ‚Ä¢ horarios de atenci√≥n
        ‚Ä¢ direcci√≥n o ubicaci√≥n del local
        ‚Ä¢ contacto, pedidos o reservas
        ‚Ä¢ promociones o descuentos
    - Si la pregunta es sobre temas generales, ajenos al restaurante (por ejemplo: Bogot√°, clima, pel√≠culas, tecnolog√≠a, etc.) ‚Üí "no_relacionada".

    Ejemplos:
    1Ô∏è‚É£ "qu√© hamburguesas tienen?" ‚Üí {{"clasificacion": "relacionada"}}
    2Ô∏è‚É£ "hay hamburguesas de pollo?" ‚Üí {{"clasificacion": "relacionada"}}
    3Ô∏è‚É£ "qu√© malteadas tienen?" ‚Üí {{"clasificacion": "relacionada"}}
    4Ô∏è‚É£ "tienen opciones vegetarianas?" ‚Üí {{"clasificacion": "relacionada"}}
    5Ô∏è‚É£ "aceptan pagos por nequi?" ‚Üí {{"clasificacion": "relacionada"}}
    6Ô∏è‚É£ "hacen env√≠os a suba?" ‚Üí {{"clasificacion": "relacionada"}}
    7Ô∏è‚É£ "cu√°l es su horario?" ‚Üí {{"clasificacion": "relacionada"}}
    8Ô∏è‚É£ "d√≥nde est√°n ubicados?" ‚Üí {{"clasificacion": "relacionada"}}
    9Ô∏è‚É£ "d√≥nde queda Bogot√°?" ‚Üí {{"clasificacion": "no_relacionada"}}
    üîü "qu√© es Python?" ‚Üí {{"clasificacion": "no_relacionada"}}

    Ahora clasifica la siguiente pregunta del usuario:
    "{pregunta_usuario}"

    Devuelve SOLO el JSON, sin explicaci√≥n adicional.
    """

    try:
        response = client.responses.create(
            model=model,
            input=prompt,
            temperature=0
        )
        text_output = response.output[0].content[0].text.strip()
        result = json.loads(text_output)
        log_message('Finalizando funci√≥n <ClasificarPreguntaMenuChatGPT>.', 'INFO')
        return result

    except json.JSONDecodeError:
        logging.error(f"Error al parsear JSON: {text_output}")
        log_message(f'Error al parsear JSON en <ClasificarPreguntaMenuChatGPT>: {text_output}', 'ERROR')
        return {"clasificacion": "no_relacionada"}
    except Exception as e:
        logging.error(f"Error en <ClasificarPreguntaMenuChatGPT>: {e}")
        log_message(f'Error en <ClasificarPreguntaMenuChatGPT>: {e}.', 'ERROR')
        return {"clasificacion": "no_relacionada"}

def _clean_model_output(raw: str) -> str:
    """
    Limpia output que pueda venir en triple-backticks o con '```json' al inicio.
    Devuelve el string JSON limpio (o el raw si no hab√≠a marcas).
    """
    if not raw:
        return ""
    s = raw.strip()

    # Si el modelo devolvi√≥ bloque con ```json ... ```
    if s.startswith("```"):
        # eliminar backticks al inicio y final
        s = s.strip("`").strip()
        # si a√∫n tiene prefijo 'json' eliminarlo
        if s.lower().startswith("json"):
            s = s[len("json"):].lstrip("\r\n ").strip()

    return s

def _extract_text_from_response(response) -> str:
    """
    Extrae texto del objeto devuelto por client.responses.create de forma robusta.
    Prioriza response.output_text, luego response.output[*].content[*].text, 
    luego intenta concatenar todo lo que encuentre.
    """
    # 1) output_text (forma simple)
    try:
        output_text = getattr(response, "output_text", None)
        if output_text:
            return str(output_text).strip()
    except Exception:
        pass

    # 2) response.output -> content
    try:
        if hasattr(response, "output") and response.output:
            parts = []
            for out in response.output:
                # cada out puede tener 'content' que es lista de dicts
                content = getattr(out, "content", None) or out.get("content", None) if isinstance(out, dict) else None
                if content:
                    for c in content:
                        # c puede ser dict con 'text' u 'type' y 'content'
                        if isinstance(c, dict):
                            if "text" in c and c["text"]:
                                parts.append(c["text"])
                            elif "type" in c and c["type"] == "output_text" and "text" in c:
                                parts.append(c["text"])
                            else:
                                # intentar stringify
                                parts.append(json.dumps(c, ensure_ascii=False))
                        else:
                            parts.append(str(c))
            if parts:
                return "\n".join(parts).strip()
    except Exception:
        pass

    # 3) fallback: str(response)
    try:
        return str(response).strip()
    except Exception:
        return ""

def responder_pregunta_menu_chatgpt(pregunta_usuario: str, items, model: str = "gpt-4o") -> dict:
    """
    Responde preguntas del usuario sobre el men√∫ o servicios del restaurante Sierra Nevada üçî.
    Incluye informaci√≥n sobre horarios, sedes y medios de pago.
    Devuelve: (result: dict, prompt: str)
    """
    log_message('Iniciando funci√≥n <ResponderPreguntaMenuChatGPT>.', 'INFO')

    # Prompt unificado
    prompt = f"""
        Eres PAKO, el asistente c√°lido y cercano de Sierra Nevada, La Cima del Sabor üèîÔ∏èüçî.
        Tu tarea es ayudar al cliente con informaci√≥n sobre el men√∫, horarios, sedes y servicios,
        siempre con el tono oficial de la marca: amable, natural y con un toque sabroso, sin exagerar.

        Informaci√≥n del restaurante:
        üïê Horario: Todos los d√≠as de 12:00 p.m. a 7:00 p.m.
        üìç Sedes:
        - Galer√≠as: Calle 53 #27-16
        - Centro Mayor: CC Centro Mayor, local 3-019
        - Centro Internacional: Calle 32 #07-10
        - Chic√≥ 2.0: Calle 100 #9A-45, local 7A
        - Virrey: Carrera 15 #88-67
        üí≥ Medios de pago: Nequi, Daviplata, tarjeta d√©bito, cr√©dito y efectivo.

        El cliente pregunt√≥: "{pregunta_usuario}"

        Este es el men√∫ completo:
        {json.dumps(items, ensure_ascii=False)}

        PAUTAS DE TONO (OBLIGATORIAS):
        - Habla como un buen anfitri√≥n bogotano: c√°lido, natural y claro.
        - Siempre cordial, sin sarcasmo, sin iron√≠a y sin jerga barrial.
        - Puedes usar m√°ximo 1 emoji suave si queda natural.
        - No inventes productos, ingredientes ni sedes.
        - S√© breve y humano, como si hablaras por WhatsApp.
        - Mant√©n un toque emocional o visual de sabor cuando sea apropiado.

        INSTRUCCIONES DE RESPUESTA:
        - Si la pregunta es sobre horarios, sedes, medios de pago o env√≠os, responde con la informaci√≥n dada.
        - Si el cliente pide algo que s√≠ aparece en el men√∫, descr√≠belo brevemente o conf√≠rmalo.
        - Si pide algo que NO est√° en el men√∫, ind√≠calo con amabilidad y sugiere m√°ximo 2 opciones similares.
        - Si pregunta por categor√≠as (picante, vegetariano, pollo, bebidas, postres, etc.), responde seg√∫n el men√∫.
        - Si pregunta por algo ambiguo, aclara con amabilidad.
        - Evita frases impersonales (ej. ‚Äúsu solicitud ha sido procesada‚Äù).
        - Evita exageraciones o tono juvenil extremo.
        - Mant√©n la respuesta en m√°ximo 2 frases si es posible.

        FORMATO OBLIGATORIO DE SALIDA:
        Devuelve SOLO un JSON v√°lido con esta estructura EXACTA:

        {{
            "respuesta": "texto amigable para el cliente",
            "recomendacion": true o false,
            "productos": ["nombre1", "nombre2"]
        }}

        Ejemplo:
        Usuario: "¬øTienen opciones picantes?"
        -> {{
            "respuesta": "Claro üëç Tenemos opciones con car√°cter como la Sierra Picante y la Sierra BBQ, ambas con un toque fuerte.",
            "recomendacion": false,
            "productos": ["Sierra Picante", "Sierra BBQ"]
        }}
        """
    try:
        client = OpenAI()
        response = client.responses.create(
            model=model,
            input=prompt
        )

        raw_text = _extract_text_from_response(response)
        raw_text = _clean_model_output(raw_text)
        logging.info(f"[DEBUG] Texto crudo del modelo: {raw_text!r}")

        if not raw_text:
            raise ValueError("Respuesta vac√≠a del modelo")

        try:
            result = json.loads(raw_text)
        except json.JSONDecodeError:
            import re
            m = re.search(r"(\{[\s\S]*\})", raw_text)
            if m:
                result = json.loads(m.group(1))
            else:
                result = {"respuesta": raw_text, "recomendacion": False, "productos": []}

        if "productos" in result and isinstance(result["productos"], list):
            result["productos"] = [p.replace('\u00a0', ' ').strip() for p in result["productos"]]

        pregunta_lower = pregunta_usuario.lower()
        if any(token in pregunta_lower for token in ["?", "tienen", "hay", "venden", "cu√°les", "qu√© opciones", "me recomiendas", "qu√© hay"]):
            respuesta_txt = str(result.get("respuesta", "")).strip()
            if respuesta_txt and not respuesta_txt.endswith(("?", ".", "!", "üòã", "üòâ", "üòé")):
                result["respuesta"] = respuesta_txt + " ¬øQuieres probarla? üòã"

        result.setdefault("productos", [])
        result.setdefault("recomendacion", False)

        log_message('Finalizando funci√≥n <ResponderPreguntaMenuChatGPT>.', 'INFO')
        return result

    except Exception as e:
        logging.error(f"Error en <ResponderPreguntaMenuChatGPT>: {e}")
        log_message(f'Error en <ResponderPreguntaMenuChatGPT>: {e}', 'ERROR')
        return {
            "respuesta": "Lo siento üòî, tuve un problema para responder tu pregunta.",
            "recomendacion": False,
            "productos": []
        }

def mapear_pedido_al_menu(contenido_clasificador: dict, menu_items: list, model: str = "gpt-4o") -> dict:
    """
    Mapear los items provenientes del clasificador al men√∫ usando gpt-4o.
    - contenido_clasificador: dict con la salida del clasificador (ver ejemplo en tu mensaje).
    - menu_items: lista de dicts con cada producto del men√∫, por ejemplo:
        [
          {"id": "p_001", "name": "Sierra Picante", "price": 14000, "aliases": ["sierra picante","sierra"]},
          {"id": "p_002", "name": "Gaseosa 400ml", "price": 4000, "aliases": ["gaseosa","refresco"]}
        ]
    Devuelve un JSON con la forma especificada en el prompt.
    """

    client = OpenAI()  # instancia del cliente
    # Construimos el prompt que recibir√° gpt-4o
    prompt = f"""
Eres un asistente encargado de mapear pedidos (extra√≠dos por un clasificador) a un MEN√ö estructurado.
Debes RESPONDER √öNICA Y EXCLUSIVAMENTE con un JSON v√°lido (sin texto adicional) con esta estructura:

{{
  "order_complete": true|false,           // true si TODOS los items fueron encontrados
  "items": [
    {{
      "requested": {{ "producto": "...", "modalidad": "...", "especificaciones": [ ... ] }},
      "status": "found" | "not_found" | "multiple_matches",
      "matched": {{ "name": "...", "id": "...", "price": number }}  // si status == found
      "candidates": [ {{ "name":"...", "id":"...", "price": number }}, ... ], // si status == multiple_matches
      "modifiers_applied": [ ... ],   // incluir especificaciones tal como aparecen en requested si se aplican
      "note": "texto corto si es necesario"  // ej. "producto exacto no hallado, se devolvieron candidatos"
    }}
  ],
  "total_price": number  // suma de los precios de matched (ignorar cambios de precio por modificadores a menos que el menu indique un modificador con precio)
}}

REGLAS CLAVE:
1) Usa exactamente el NOMBRE del producto como aparece en el campo 'name' del MEN√ö cuando haya coincidencia.
2) Haz matching case-insensitive y considera 'aliases' si est√°n disponibles en el MEN√ö.
3) Si hay coincidencia exacta (nombre o alias) ‚Üí status = "found" y devuelve name/id/price desde el men√∫.
4) Si hay m√°s de una coincidencia plausible y no hay forma de decidir exactamente ‚Üí status = "multiple_matches" y devuelve up to 3 candidates (name,id,price).
5) Si no encuentras ninguna coincidencia ‚Üí status = "not_found". En ese caso coloca matched = {{}}, agrega note = "producto no encontrado" y AL FINAL del JSON setea "order_complete": false.
6) Si cualquier item tiene status "not_found" ‚Üí order_complete = false; si todos est√°n "found" ‚Üí order_complete = true.
7) Si el men√∫ incluye objetos 'modifiers' o precios por especificaci√≥n, apl√≠calos; si no, incl√∫yelos en 'modifiers_applied' pero NO cambies el price base (a menos que el men√∫ indique expl√≠citamente el costo del modificador).
8) Devuelve siempre n√∫meros (no strings) para los precios y para total_price.
9) No incluyas explicaciones, solo el JSON.

A continuaci√≥n se incluyen el MENU y la entrada del CLASIFICADOR (ambos en JSON). Usa esa informaci√≥n para mapear.

MENU:
{json.dumps(menu_items, ensure_ascii=False)}

CLASIFICADOR:
{json.dumps(contenido_clasificador, ensure_ascii=False)}

Ejemplo (para orientaci√≥n ‚Äî NO lo copies como salida, la salida debe seguir la estructura anterior):
Si el clasificador pide "sierra picante" con especificaci√≥n ["extra aj√≠"] y el men√∫ tiene "Sierra Picante" con id "p_001" y price 14000 ‚Üí status found y matched.name = "Sierra Picante", matched.id = "p_001", matched.price = 14000, modifiers_applied = ["extra aj√≠"].

DEVUELVE SOLO EL JSON.
"""

    try:
        response = client.responses.create(
            model=model,
            input=prompt,
            temperature=0
        )

        # Extraer texto (ajusta seg√∫n la forma en que tu SDK devuelve el output)
        text_output = response.output[0].content[0].text.strip()
        result = json.loads(text_output)
        return result

    except json.JSONDecodeError:
        logging.error("Error al parsear JSON desde el modelo. Output crudo:")
        logging.error(text_output if 'text_output' in locals() else 'no output')
        return {
            "order_complete": False,
            "items": [],
            "total_price": 0,
            "error": "parse_error",
            "raw_output": text_output if 'text_output' in locals() else None
        }
    except Exception as e:
        logging.exception("Error llamando al API")
        return {
            "order_complete": False,
            "items": [],
            "total_price": 0,
            "error": str(e)
        }
    
def sin_intencion_respuesta_variable(contenido_usuario: str, nombre_cliente: str) -> str:
    try:
        log_message('Iniciando funci√≥n <sin_intencion>.', 'INFO')
        PROMPT_SIN_INTENCION = (
            "Eres el asistente oficial de Sierra Nevada, La Cima del Sabor.\n"
            "Tu objetivo es responder cuando el cliente env√≠a algo que no tiene sentido, "
            "como una palabra suelta, emojis sin contexto, n√∫meros o s√≠mbolos.\n\n"

            "TONO DE MARCA:\n"
            "- C√°lido, cercano y respetuoso.\n"
            "- Puedes usar un toque juguet√≥n o ligero, pero sin sarcasmo ni iron√≠a.\n"
            "- Lenguaje natural, claro y amable, como un buen anfitri√≥n bogotano.\n"
            "- Puedes usar 1 emoji suave si queda natural.\n"
            "- Nunca suenes burl√≥n, defensivo o exagerado.\n\n"

            "REGLAS:\n"
            "- Si el usuario env√≠a algo aleatorio como 'a', 'su', emojis o s√≠mbolos, "
            "responde con amabilidad y un gui√±o ligero, manteniendo calidez.\n"
            "- Si env√≠a banderas, puedes decir algo como: "
            "\"No estoy seguro c√≥mo se relaciona {contenido}, pero aqu√≠ estoy para ayudarte\".\n"
            "- Termina SIEMPRE con un llamado a la acci√≥n invitando al cliente a contarte "
            "qu√© desea pedir o consultar.\n"
            "- Incluye el nombre del cliente: {nombre_cliente}.\n"
            "- M√°ximo 1 o 2 frases.\n"
            "- No inventes productos.\n\n"

            "Contenido del usuario: \"{contenido}\"\n"
            "Nombre del cliente: \"{nombre_cliente}\"\n\n"
            "Responde aqu√≠:"
        )
        client = OpenAI()
        prompt = PROMPT_SIN_INTENCION.format(
            contenido=contenido_usuario,
            nombre_cliente=nombre_cliente
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un asistente de un restaurante que responde con humor amable y ligero sarcasmo."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=80,
            temperature=0.9
        )
        mensaje = response.choices[0].message.content
        log_message('Finalizando funci√≥n <sin_intencion>.', 'INFO')
        return mensaje.strip()
    except Exception as e:
        log_message(f'Error en funci√≥n <sin_intencion>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <sin_intencion>: {e}")
        return "Lo siento, no entend√≠ tu mensaje. ¬øPodr√≠as repetirlo de otra forma?"

def saludo_dynamic(mensaje_usuario: str, nombre: str, nombre_local: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <saludo_dynamic>.', 'INFO')
        PROMPT_SALUDO_DYNAMIC = """
            Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
            Tu tarea es generar un saludo personalizado seg√∫n el tono que use el cliente.

            El cliente escribi√≥: "{mensaje_usuario}"

            PAUTAS DE TONO:
            1. Si el cliente usa expresiones informales como:
            "q hubo", "quiubo", "k hubo", "que m√°s", "que mas", "q mas",
            "hey", "holi", "epa", "epaaa", "hoola", "hola parce",
            entonces:
                - Usa un tono cercano, relajado y natural, sin jerga excesiva.
                - Puedes usar 1 emoji suave si fluye bien.
                - Mant√©n calidez y sensaci√≥n de bienvenida al estilo Sierra Nevada.

            2. Si el cliente usa expresiones formales como:
            "buenas tardes", "buenos d√≠as", "buen dia",
            "cordial saludo", "mucho gusto", "estimados",
            entonces:
                - Usa un tono respetuoso, profesional y sereno.
                - No uses emojis.
                - Mant√©n claridad, amabilidad y un toque c√°lido sin exagerar.

            3. En cualquier otro caso:
                - Usa un tono cordial est√°ndar: amable, natural y con sabor.
                - Puedes usar un emoji suave si queda org√°nico.

            REGLAS DE ESTILO SIERRA NEVADA:
            - Habla como un buen anfitri√≥n: c√°lido, claro y con energ√≠a positiva.
            - Evita expresiones barriales, sarcasmo o exageraciones.
            - Mant√©n un lenguaje cotidiano y respetuoso.
            - No inventes productos ni detalles.
            - Puedes mencionar solamente: ‚Äúmen√∫‚Äù, ‚Äúpromociones‚Äù, ‚Äúburgers‚Äù, ‚Äúrecomendaciones‚Äù.
            - Incluye siempre el nombre del cliente: {nombre_cliente}
            - Incluye siempre el nombre del local: {nombre_local}
            - Responde en m√°ximo 1 o 2 frases.
            - Escoge UNA intenci√≥n entre:
                - "consulta_menu"
                - "consulta_promociones"

            FORMATO:
            Debes responder en un JSON v√°lido:

            {
                "mensaje": "texto aqu√≠",
                "intencion": "consulta_menu"
            }

            No incluyas texto adicional fuera del JSON.
            """
        client = OpenAI()
        prompt = PROMPT_SALUDO_DYNAMIC.format(
            nombre_cliente=nombre,
            nombre_local=nombre_local,
            mensaje_usuario=mensaje_usuario.lower()
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un generador de saludos que adapta su tono al del cliente."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=150,
            temperature=0.85
        )
        raw = response.choices[0].message.content.strip()
        try:
            data = json.loads(raw)
        except:
            data = {
                "mensaje": f"¬°Hola {nombre}! Bienvenido a {nombre_local}. ¬øQuieres que te muestre el men√∫?",
                "intencion": "consulta_menu"
            }
        log_message('Finalizando funci√≥n <saludo_dynamic>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <saludo_dynamic>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <saludo_dynamic>: {e}")
        return {
            "mensaje": f"¬°Hola {nombre}! Bienvenido a {nombre_local}. ¬øQuieres que te muestre el men√∫?",
            "intencion": "consulta_menu"
        }
    
def respuesta_quejas_ia(mensaje_usuario: str, nombre: str, nombre_local: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <respuesta_quejas>.', 'INFO')
        PROMPT_QUEJA_LEVE = """
            Eres el asistente oficial de servicio al cliente de Sierra Nevada, La Cima del Sabor.

            Tu tarea es responder una queja leve con el tono y personalidad de la marca:
            - C√°lido, cercano y respetuoso.
            - Natural, humano, sin excesos.
            - Con un toque de sabor y buena energ√≠a, sin sonar exagerado.
            - Orgullosamente colombiano, pero sin clich√©s.
            - Hablas como un buen anfitri√≥n bogotano: amable, claro y sin jerga popular.

            El cliente llamado {nombre} escribi√≥ lo siguiente: "{mensaje_usuario}"

            OBJETIVO:
            - Tranquilizar al cliente.
            - Validar su experiencia sin culpas ni defensividad.
            - Incluir SIEMPRE una acci√≥n concreta para mostrar que est√°s atendiendo el caso 
            (por ejemplo: ‚Äúle cuento al equipo‚Äù, ‚Äúreviso con cocina‚Äù, ‚Äúlo paso al encargado del punto‚Äù).
            - Mostrar disposici√≥n a ayudar SIN escalar el caso a un agente humano.
            - Mantener un tono amable y con toque emocional de Sierra Nevada.
            - Usar m√°ximo 1 emoji suave si fluye de manera natural.
            - Responder en m√°ximo 2 frases.

            REGLAS DE TONO:
            - No uses sarcasmo, iron√≠as ni expresiones barriales.
            - No suenes rob√≥tico ni impersonal.
            - No inventes informaci√≥n.
            - Mant√©n una sensaci√≥n de servicio, calidez y sabor.
            - Evita anglicismos y tecnicismos.
            - Puedes mencionar solo: equipo, servicio, experiencia, tiempo de entrega, sabor, atenci√≥n.

            CONTENIDO:
            Debes generar:
            1. "respuesta_cordial": un mensaje amable y emp√°tico que tranquilice al cliente, 
            incluyendo una acci√≥n concreta como ‚Äúreviso con cocina‚Äù, ‚Äúle cuento al equipo del punto‚Äù 
            o ‚Äúdejo la nota para mejorar tu pr√≥xima experiencia‚Äù.
            2. "resumen_queja": una frase corta que resuma la queja sin inventar detalles.
            3. "intencion": siempre "queja_leve".

            FORMATO DE RESPUESTA:
            La respuesta DEBE ser un JSON v√°lido:
            {
                "respuesta_cordial": "texto aqu√≠",
                "resumen_queja": "texto aqu√≠",
                "intencion": "queja_leve"
            }

            Genera solo el JSON sin texto adicional.
            """
        client = OpenAI()
        prompt = PROMPT_QUEJA_LEVE.format(
            mensaje_usuario=mensaje_usuario,
            nombre=nombre
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "Eres un generador de respuestas amables para quejas leves de clientes."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=180,
            temperature=0.6
        )
        raw = response.choices[0].message.content.strip()
        # Intentar parsear JSON
        try:
            data = json.loads(raw)
        except:
            data = {
                "respuesta_cordial": f"{nombre}, gracias por escribirnos. Lamentamos que tu experiencia en {nombre_local} no haya sido perfecta; estamos aqu√≠ para ayudarte üòä",
                "resumen_queja": "Queja leve del cliente sobre su experiencia.",
                "intencion": "quejas"
            }
        log_message('Finalizando funci√≥n <respuesta_quejas>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <respuesta_quejas>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <respuesta_quejas>: {e}")
        return {
            "respuesta_cordial": f"{nombre}, gracias por avisarnos. Estamos atentos para que tu experiencia en {nombre_local} sea mejor cada vez.",
            "resumen_queja": "Queja leve del cliente.",
            "intencion": "quejas"
        }

def respuesta_quejas_graves_ia(mensaje_usuario: str, nombre: str, nombre_local: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <respuesta_quejas_graves_ia>.', 'INFO')
        PROMPT_QUEJA_GRAVE = """
            Eres el asistente oficial de servicio al cliente de Sierra Nevada, La Cima del Sabor.

            Esta vez atender√°s *quejas graves*, donde puede que el pedido NO haya llegado,
            haya habido un error fuerte, mala manipulaci√≥n o tiempo excesivo.

            ***OBJETIVO GENERAL***
            - Calmar al cliente.
            - Asumir responsabilidad sin culpas excesivas.
            - Dar una ACCI√ìN clara y concreta que el asistente realizar√°.
            - Preparar un resumen ejecutivo para un administrador humano.
            - NO escalar directamente en el mensaje al cliente (solo en el resumen interno).
            - M√°ximo 2 frases, tono c√°lido, humano, cercano, estilo Sierra Nevada, colombiano neutro.

            ***DEBES ENTREGAR ESTOS CAMPOS***
            1. "respuesta_cordial": Mensaje calmado, emp√°tico y con acci√≥n concreta 
            (ej: ‚Äúreviso ya mismo con cocina y log√≠stica‚Äù, ‚Äúactivo seguimiento con el punto‚Äù).
            2. "resumen_queja": Descripci√≥n breve de lo que reclama el cliente.
            3. "accion_recomendada": Acci√≥n clara que el sistema/administrador debe hacer 
            (ej: verificar estado del pedido, contactar punto, revisar domiciliario).
            4. "resumen_ejecutivo": Resumen para administrador (breve, objetivo, sin adornos).
            5. "intencion": Siempre "queja_grave".

            ***TONO***
            - C√°lido y responsable.
            - Sin tecnicismos ni sarcasmo.
            - Evita respuestas rob√≥ticas.
            - M√°ximo un emoji, si fluye natural.

            Cliente llamado {nombre} escribi√≥:
            "{mensaje_usuario}"

            ***FORMATO OBLIGATORIO***
            Devuelve SOLO un JSON v√°lido:
            {{
                "respuesta_cordial": "",
                "resumen_queja": "",
                "accion_recomendada": "",
                "resumen_ejecutivo": "",
                "intencion": "queja_grave"
            }}
        """
        client = OpenAI()
        prompt = PROMPT_QUEJA_GRAVE.format(
            mensaje_usuario=mensaje_usuario,
            nombre=nombre
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un generador de respuestas para quejas graves de clientes."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=220,
            temperature=0.6
        )
        raw = response.choices[0].message.content.strip()
        # Intentar parsear JSON
        try:
            data = json.loads(raw)
        except:
            data = {
                "respuesta_cordial": f"{nombre}, ya reviso lo ocurrido con tu experiencia en {nombre_local} y activo el seguimiento de inmediato.",
                "resumen_queja": "Queja grave del cliente sobre servicio o pedido.",
                "accion_recomendada": "Revisi√≥n urgente con el punto y estado del pedido.",
                "resumen_ejecutivo": "Cliente reporta una queja grave; requiere revisi√≥n del punto y log√≠stica.",
                "intencion": "queja_grave"
            }
        log_message('Finalizando funci√≥n <respuesta_quejas_graves_ia>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <respuesta_quejas_graves_ia>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <respuesta_quejas_graves_ia>: {e}")
        return {
            "respuesta_cordial": f"{nombre}, reviso de inmediato lo que pas√≥ con tu experiencia en {nombre_local}.",
            "resumen_queja": "Queja grave del cliente.",
            "accion_recomendada": "Verificar con el punto y log√≠stica.",
            "resumen_ejecutivo": "Error en el proceso autom√°tico, requiere revisi√≥n manual.",
            "intencion": "queja_grave"
        }