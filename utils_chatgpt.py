# utils_chatgpt.py
# Last modified: 2025-11-05 by Andr√©s Berm√∫dez

from openai import OpenAI
import logging
from typing import Any, Optional, Tuple, Dict
import os
import json
from utils import send_text_response, limpiar_respuesta_json, log_message

def get_openai_key() -> str:
    try:
        """Obtiene la clave API de OpenAI desde variables de entorno."""
        log_message('Iniciando funci√≥n <GetOpenAIKey>.', 'INFO')
        logging.info('Obteniendo clave de OpenAI')
        api_key: Optional[str] = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("No se encontr√≥ la clave OPENAI_API_KEY en las variables de entorno.")
        logging.info('Clave de OpenAI obtenida')
        log_message('Finalizando funci√≥n <GetOpenAIKey>.', 'INFO')
        return api_key
    except Exception as e:
        log_message(f"Error al obtener la clave de OpenAI: {e}", 'ERROR')
        logging.error(f"Error al obtener la clave de OpenAI: {e}")
        raise
    
def get_classifier(msj: str, sender: str) -> Tuple[Optional[str], Optional[str], Dict[str, Any]]:
    try:
        """Clasifica un mensaje de WhatsApp usando un modelo fine-tuned de OpenAI."""
        log_message('Iniciando funci√≥n <GetClassifier>.', 'INFO')
        logging.info('Clasificando mensaje')
        classification_prompt: str = """
        Eres un clasificador de mensajes para un asistente de WhatsApp de un restaurante.
        Tu tarea es identificar la **intenci√≥n (intent)**, el **tipo de mensaje (type)** y cualquier **entidad relevante (entities)**.
        Debes responder **√∫nicamente** en formato JSON v√°lido con la siguiente estructura:
        {
          "intent": "<una de las intenciones permitidas>",
          "type": "<tipo de mensaje>",
          "entities": { }
        }
        Lista de intenciones posibles:
        - confirmacion_general
        - consulta_menu
        - consulta_pedido
        - consulta_promociones
        - continuacion_pedido
        - direccion
        - info_personal
        - mas_datos_direccion
        - modificar_pedido
        - negacion_general
        - preguntas_generales
        - quejas (quejas de menor nivel: retraso en la entrega, mal servicio del domiciliario, problemas con la app, cocci√≥n desfasada solamente)
        - saludo
        - sin_intencion
        - solicitud_pedido
        - transferencia (quejas de mayor nivel: no entrega de domicilio, pedido equivocado, mal estado del pedido solamente)
        - validacion_pago

        Instrucciones importantes:
        - No incluyas texto fuera del JSON.
        - No uses comentarios, explicaciones o saltos de l√≠nea innecesarios.
        - Si no puedes determinar la intenci√≥n, usa "sin_intencion".
        """
        messages = [
            {"role": "system", "content": classification_prompt},
            {"role": "user", "content": msj}
        ]
        client: OpenAI = OpenAI(api_key=get_openai_key())
        respuesta: Any = client.chat.completions.create(
            model="ft:gpt-3.5-turbo-0125:net-applications:domicilios:CaSlaPnG",
            messages=messages,
            max_tokens=500,
            temperature=0
        )
        raw_response: str = respuesta.choices[0].message.content.strip()
        logging.info(f"[Clasificador RAW] {raw_response!r}")
        json_str: str = limpiar_respuesta_json(raw_response)
        result: Dict[str, Any] = json.loads(json_str)
        intent: Optional[str] = result.get("intent")
        type_: Optional[str] = result.get("type")
        entities: Dict[str, Any] = result.get("entities", {})
        if not intent or not type_:
            raise ValueError(f"Respuesta inv√°lida, faltan claves: {result}")
        logging.info(f"Respuesta del clasificador: {result}")
        logging.info(f"Intent: {intent}, Type: {type_}, Entities: {entities}")
        log_message('Finalizando funci√≥n <GetClassifier>.', 'INFO')
        return intent, type_, entities
    except Exception as e:
        log_message(f'Error al hacer uso de funci√≥n <GetClassifier>: {e}.', 'ERROR')
        logging.error(f"Error al clasificar el mensaje: {e}")
        send_text_response(sender, "Lo siento, hubo un error al procesar tu mensaje. ¬øPodr√≠as repetirlo?")
        return None, None, {}

def clasificar_pregunta_menu_chatgpt(pregunta_usuario: str, model: str = "gpt-3.5-turbo") -> dict:
    """
    Clasifica si una pregunta del usuario est√° relacionada con el men√∫ o con servicios
    del negocio (hamburgueser√≠a) usando un modelo de lenguaje (ChatGPT).
    """

    log_message('Iniciando funci√≥n <ClasificarPreguntaMenuChatGPT>.', 'INFO')
    client: OpenAI = OpenAI()

    prompt: str = f"""
    Eres un asistente que clasifica preguntas de clientes de una hamburgueser√≠a.

    Debes responder con un JSON EXACTO con la siguiente forma:
    {{
        "clasificacion": "relacionada" o "no_relacionada"
    }}

    Instrucciones:
    - Si la pregunta se refiere a comidas, hamburguesas, bebidas, malteadas, ingredientes, precios, combos,
      opciones vegetarianas o cualquier cosa del men√∫ ‚Üí "relacionada".
    - Tambi√©n clasifica como "relacionada" si el cliente pregunta sobre:
        ‚Ä¢ formas de pago (Nequi, Daviplata, efectivo, tarjetas, etc.)
        ‚Ä¢ si hacen domicilios o env√≠os
        ‚Ä¢ horarios de atenci√≥n
        ‚Ä¢ direcci√≥n o ubicaci√≥n del local
        ‚Ä¢ contacto, pedidos o reservas
        ‚Ä¢ promociones o descuentos
    - Si la pregunta es sobre temas generales, ajenos al restaurante (por ejemplo: Bogot√°, clima, pel√≠culas, tecnolog√≠a, etc.) ‚Üí "no_relacionada".

    Ejemplos:
    1Ô∏è‚É£ "qu√© hamburguesas tienen?" ‚Üí {{"clasificacion": "relacionada"}}
    2Ô∏è‚É£ "hay hamburguesas de pollo?" ‚Üí {{"clasificacion": "relacionada"}}
    3Ô∏è‚É£ "qu√© malteadas tienen?" ‚Üí {{"clasificacion": "relacionada"}}
    4Ô∏è‚É£ "tienen opciones vegetarianas?" ‚Üí {{"clasificacion": "relacionada"}}
    5Ô∏è‚É£ "aceptan pagos por nequi?" ‚Üí {{"clasificacion": "relacionada"}}
    6Ô∏è‚É£ "hacen env√≠os a suba?" ‚Üí {{"clasificacion": "relacionada"}}
    7Ô∏è‚É£ "cu√°l es su horario?" ‚Üí {{"clasificacion": "relacionada"}}
    8Ô∏è‚É£ "d√≥nde est√°n ubicados?" ‚Üí {{"clasificacion": "relacionada"}}
    9Ô∏è‚É£ "d√≥nde queda Bogot√°?" ‚Üí {{"clasificacion": "no_relacionada"}}
    üîü "qu√© es Python?" ‚Üí {{"clasificacion": "no_relacionada"}}

    Ahora clasifica la siguiente pregunta del usuario:
    "{pregunta_usuario}"

    Devuelve SOLO el JSON, sin explicaci√≥n adicional.
    """

    try:
        response = client.responses.create(
            model=model,
            input=prompt,
            temperature=0
        )
        text_output = response.output[0].content[0].text.strip()
        result = json.loads(text_output)
        log_message('Finalizando funci√≥n <ClasificarPreguntaMenuChatGPT>.', 'INFO')
        return result

    except json.JSONDecodeError:
        logging.error(f"Error al parsear JSON: {text_output}")
        log_message(f'Error al parsear JSON en <ClasificarPreguntaMenuChatGPT>: {text_output}', 'ERROR')
        return {"clasificacion": "no_relacionada"}
    except Exception as e:
        logging.error(f"Error en <ClasificarPreguntaMenuChatGPT>: {e}")
        log_message(f'Error en <ClasificarPreguntaMenuChatGPT>: {e}.', 'ERROR')
        return {"clasificacion": "no_relacionada"}

def _clean_model_output(raw: str) -> str:
    """
    Limpia output que pueda venir en triple-backticks o con '```json' al inicio.
    Devuelve el string JSON limpio (o el raw si no hab√≠a marcas).
    """
    if not raw:
        return ""
    s = raw.strip()

    # Si el modelo devolvi√≥ bloque con ```json ... ```
    if s.startswith("```"):
        # eliminar backticks al inicio y final
        s = s.strip("`").strip()
        # si a√∫n tiene prefijo 'json' eliminarlo
        if s.lower().startswith("json"):
            s = s[len("json"):].lstrip("\r\n ").strip()

    return s

def _extract_text_from_response(response) -> str:
    """
    Extrae texto del objeto devuelto por client.responses.create de forma robusta.
    Prioriza response.output_text, luego response.output[*].content[*].text, 
    luego intenta concatenar todo lo que encuentre.
    """
    # 1) output_text (forma simple)
    try:
        output_text = getattr(response, "output_text", None)
        if output_text:
            return str(output_text).strip()
    except Exception:
        pass

    # 2) response.output -> content
    try:
        if hasattr(response, "output") and response.output:
            parts = []
            for out in response.output:
                # cada out puede tener 'content' que es lista de dicts
                content = getattr(out, "content", None) or out.get("content", None) if isinstance(out, dict) else None
                if content:
                    for c in content:
                        # c puede ser dict con 'text' u 'type' y 'content'
                        if isinstance(c, dict):
                            if "text" in c and c["text"]:
                                parts.append(c["text"])
                            elif "type" in c and c["type"] == "output_text" and "text" in c:
                                parts.append(c["text"])
                            else:
                                # intentar stringify
                                parts.append(json.dumps(c, ensure_ascii=False))
                        else:
                            parts.append(str(c))
            if parts:
                return "\n".join(parts).strip()
    except Exception:
        pass

    # 3) fallback: str(response)
    try:
        return str(response).strip()
    except Exception:
        return ""

def responder_pregunta_menu_chatgpt(pregunta_usuario: str, items, model: str = "gpt-4o") -> dict:
    """
    Responde preguntas del usuario sobre el men√∫ o servicios del restaurante Sierra Nevada üçî.
    Incluye informaci√≥n sobre horarios, sedes y medios de pago.
    Devuelve: (result: dict, prompt: str)
    """
    log_message('Iniciando funci√≥n <ResponderPreguntaMenuChatGPT>.', 'INFO')

    # Prompt unificado
    prompt = f"""
    Eres un asistente amable y directo de la hamburgueser√≠a "Sierra Nevada" en Bogot√° üçî.
    Tu tarea es responder preguntas de clientes sobre el men√∫ o servicios del negocio.

    Informaci√≥n del restaurante:
    üïê Horario: Todos los d√≠as de 12:00 p.m. a 7:00 p.m.
    üìç Sedes:
       - Galer√≠as: Calle 53 # 27-16
       - Centro Mayor: Centro Comercial Centro Mayor, local 3-019
       - Centro Internacional: Calle 32 # 07-10
       - Chic√≥ 2.0: Calle 100 # 9A - 45 local 7A
       - Virrey: Carrera 15 # 88-67
    üí≥ Medios de pago: Nequi, Daviplata, tarjeta d√©bito, cr√©dito y efectivo.
    üöö Hacen env√≠os y domicilios desde su agente de inteligencia artificial en WhatsApp llamado PAKO.

    El cliente pregunt√≥: "{pregunta_usuario}"

    Este es el men√∫ completo:
    {json.dumps(items, ensure_ascii=False)}

    Instrucciones:
    - Usa solo los productos listados en el men√∫.
    - Si la pregunta es sobre horarios, sedes, medios de pago o env√≠os, responde usando la informaci√≥n de arriba.
    - Si el cliente pide algo que s√≠ est√° en el men√∫, descr√≠belo o conf√≠rmalo.
    - Si pide algo que NO aparece en el men√∫, di amablemente que no lo tenemos y sugiere hasta 2 opciones similares.
    - Si pregunta por categor√≠as (picante, vegetariano, de pollo, bebidas, postres, etc.), responde seg√∫n el men√∫.
    - S√© breve, natural y amable, como si fuera WhatsApp.
    - Devuelve SOLO un objeto JSON con el siguiente formato EXACTO:
    {{
        "respuesta": "texto amigable para el cliente",
        "recomendacion": true o false,
        "productos": ["nombre1", "nombre2"]
    }}
    Ejemplo:
    Usuario: "¬øTienen opciones picantes?"
    -> {{
        "respuesta": "S√≠ üî•, tenemos la Sierra Picante y la Sierra BBQ que tiene un toque fuerte.",
        "recomendacion": false,
        "productos": ["Sierra Picante", "Sierra BBQ"]
    }}
    """

    try:
        client = OpenAI()
        response = client.responses.create(
            model=model,
            input=prompt
        )

        raw_text = _extract_text_from_response(response)
        raw_text = _clean_model_output(raw_text)
        logging.info(f"[DEBUG] Texto crudo del modelo: {raw_text!r}")

        if not raw_text:
            raise ValueError("Respuesta vac√≠a del modelo")

        try:
            result = json.loads(raw_text)
        except json.JSONDecodeError:
            import re
            m = re.search(r"(\{[\s\S]*\})", raw_text)
            if m:
                result = json.loads(m.group(1))
            else:
                result = {"respuesta": raw_text, "recomendacion": False, "productos": []}

        if "productos" in result and isinstance(result["productos"], list):
            result["productos"] = [p.replace('\u00a0', ' ').strip() for p in result["productos"]]

        pregunta_lower = pregunta_usuario.lower()
        if any(token in pregunta_lower for token in ["?", "tienen", "hay", "venden", "cu√°les", "qu√© opciones", "me recomiendas", "qu√© hay"]):
            respuesta_txt = str(result.get("respuesta", "")).strip()
            if respuesta_txt and not respuesta_txt.endswith(("?", ".", "!", "üòã", "üòâ", "üòé")):
                result["respuesta"] = respuesta_txt + " ¬øQuieres probarla? üòã"

        result.setdefault("productos", [])
        result.setdefault("recomendacion", False)

        log_message('Finalizando funci√≥n <ResponderPreguntaMenuChatGPT>.', 'INFO')
        return result

    except Exception as e:
        logging.error(f"Error en <ResponderPreguntaMenuChatGPT>: {e}")
        log_message(f'Error en <ResponderPreguntaMenuChatGPT>: {e}', 'ERROR')
        return {
            "respuesta": "Lo siento üòî, tuve un problema para responder tu pregunta.",
            "recomendacion": False,
            "productos": []
        }

def mapear_pedido_al_menu(contenido_clasificador: dict, menu_items: list, model: str = "gpt-4o") -> dict:
    """
    Mapear los items provenientes del clasificador al men√∫ usando gpt-4o.
    - contenido_clasificador: dict con la salida del clasificador (ver ejemplo en tu mensaje).
    - menu_items: lista de dicts con cada producto del men√∫, por ejemplo:
        [
          {"id": "p_001", "name": "Sierra Picante", "price": 14000, "aliases": ["sierra picante","sierra"]},
          {"id": "p_002", "name": "Gaseosa 400ml", "price": 4000, "aliases": ["gaseosa","refresco"]}
        ]
    Devuelve un JSON con la forma especificada en el prompt.
    """

    client = OpenAI()  # instancia del cliente
    # Construimos el prompt que recibir√° gpt-4o
    prompt = f"""
Eres un asistente encargado de mapear pedidos (extra√≠dos por un clasificador) a un MEN√ö estructurado.
Debes RESPONDER √öNICA Y EXCLUSIVAMENTE con un JSON v√°lido (sin texto adicional) con esta estructura:

{{
  "order_complete": true|false,           // true si TODOS los items fueron encontrados
  "items": [
    {{
      "requested": {{ "producto": "...", "modalidad": "...", "especificaciones": [ ... ] }},
      "status": "found" | "not_found" | "multiple_matches",
      "matched": {{ "name": "...", "id": "...", "price": number }}  // si status == found
      "candidates": [ {{ "name":"...", "id":"...", "price": number }}, ... ], // si status == multiple_matches
      "modifiers_applied": [ ... ],   // incluir especificaciones tal como aparecen en requested si se aplican
      "note": "texto corto si es necesario"  // ej. "producto exacto no hallado, se devolvieron candidatos"
    }}
  ],
  "total_price": number  // suma de los precios de matched (ignorar cambios de precio por modificadores a menos que el menu indique un modificador con precio)
}}

REGLAS CLAVE:
1) Usa exactamente el NOMBRE del producto como aparece en el campo 'name' del MEN√ö cuando haya coincidencia.
2) Haz matching case-insensitive y considera 'aliases' si est√°n disponibles en el MEN√ö.
3) Si hay coincidencia exacta (nombre o alias) ‚Üí status = "found" y devuelve name/id/price desde el men√∫.
4) Si hay m√°s de una coincidencia plausible y no hay forma de decidir exactamente ‚Üí status = "multiple_matches" y devuelve up to 3 candidates (name,id,price).
5) Si no encuentras ninguna coincidencia ‚Üí status = "not_found". En ese caso coloca matched = {{}}, agrega note = "producto no encontrado" y AL FINAL del JSON setea "order_complete": false.
6) Si cualquier item tiene status "not_found" ‚Üí order_complete = false; si todos est√°n "found" ‚Üí order_complete = true.
7) Si el men√∫ incluye objetos 'modifiers' o precios por especificaci√≥n, apl√≠calos; si no, incl√∫yelos en 'modifiers_applied' pero NO cambies el price base (a menos que el men√∫ indique expl√≠citamente el costo del modificador).
8) Devuelve siempre n√∫meros (no strings) para los precios y para total_price.
9) No incluyas explicaciones, solo el JSON.

A continuaci√≥n se incluyen el MENU y la entrada del CLASIFICADOR (ambos en JSON). Usa esa informaci√≥n para mapear.

MENU:
{json.dumps(menu_items, ensure_ascii=False)}

CLASIFICADOR:
{json.dumps(contenido_clasificador, ensure_ascii=False)}

Ejemplo (para orientaci√≥n ‚Äî NO lo copies como salida, la salida debe seguir la estructura anterior):
Si el clasificador pide "sierra picante" con especificaci√≥n ["extra aj√≠"] y el men√∫ tiene "Sierra Picante" con id "p_001" y price 14000 ‚Üí status found y matched.name = "Sierra Picante", matched.id = "p_001", matched.price = 14000, modifiers_applied = ["extra aj√≠"].

DEVUELVE SOLO EL JSON.
"""

    try:
        response = client.responses.create(
            model=model,
            input=prompt,
            temperature=0
        )

        # Extraer texto (ajusta seg√∫n la forma en que tu SDK devuelve el output)
        text_output = response.output[0].content[0].text.strip()
        result = json.loads(text_output)
        return result

    except json.JSONDecodeError:
        logging.error("Error al parsear JSON desde el modelo. Output crudo:")
        logging.error(text_output if 'text_output' in locals() else 'no output')
        return {
            "order_complete": False,
            "items": [],
            "total_price": 0,
            "error": "parse_error",
            "raw_output": text_output if 'text_output' in locals() else None
        }
    except Exception as e:
        logging.exception("Error llamando al API")
        return {
            "order_complete": False,
            "items": [],
            "total_price": 0,
            "error": str(e)
        }
    
def sin_intencion_respuesta_variable(contenido_usuario: str, nombre_cliente: str) -> str:
    try:
        log_message('Iniciando funci√≥n <sin_intencion>.', 'INFO')
        PROMPT_SIN_INTENCION = (
            "Eres un asistente amable pero con un toque de sarcasmo ligero y divertido.\n"
            "Tu objetivo es responder cuando el usuario env√≠a algo que no tiene sentido, "
            "como una palabra suelta, emojis sin contexto, n√∫meros o s√≠mbolos.\n\n"
            "Reglas:\n"
            "- Siempre responde con AMABILIDAD + SARCASMO SUAVE.\n"
            "- Si el usuario manda algo random como 'a', 'su', emojis o banderas, "
            "haz un comentario ir√≥nico pero respetuoso.\n"
            "- Si manda banderas, puedes decir algo como: "
            "\"No s√© muy bien qu√© tiene que ver {contenido} con nuestro men√∫, pero...\".\n"
            "- Siempre termina con un call to action invitando a repetir la pregunta o pedido.\n"
            "- Usa el nombre del cliente si te lo paso como {nombre_cliente}.\n"
            "- M√°ximo 1 o 2 frases, no m√°s.\n"
            "- Nunca inventes informaci√≥n del men√∫.\n\n"
            "Contenido del usuario: \"{contenido}\"\n"
            "Nombre del cliente: \"{nombre_cliente}\"\n\n"
            "Responde de forma concisa y divertida aqu√≠:"
        )
        client = OpenAI()
        prompt = PROMPT_SIN_INTENCION.format(
            contenido=contenido_usuario,
            nombre_cliente=nombre_cliente
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un asistente de un restaurante que responde con humor amable y ligero sarcasmo."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=80,
            temperature=0.9
        )
        mensaje = response.choices[0].message.content
        log_message('Finalizando funci√≥n <sin_intencion>.', 'INFO')
        return mensaje.strip()
    except Exception as e:
        log_message(f'Error en funci√≥n <sin_intencion>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <sin_intencion>: {e}")
        return "Lo siento, no entend√≠ tu mensaje. ¬øPodr√≠as repetirlo de otra forma?"
