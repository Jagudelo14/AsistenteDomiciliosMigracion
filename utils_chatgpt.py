# utils_chatgpt.py
# Last modified: 2025-11-05 by Andr√©s Berm√∫dez

import re
from openai import OpenAI
import logging
from typing import Any, List, Optional, Tuple, Dict
import os
import json
import ast
from utils import REPLACE_PHRASES, obtener_pedido_por_codigo, send_text_response, limpiar_respuesta_json, log_message, _safe_parse_order, _merge_items, _price_of_item, convert_decimals, to_json_safe

def get_openai_key() -> str:
    try:
        """Obtiene la clave API de OpenAI desde variables de entorno."""
        log_message('Iniciando funci√≥n <GetOpenAIKey>.', 'INFO')
        logging.info('Obteniendo clave de OpenAI')
        api_key: Optional[str] = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("No se encontr√≥ la clave OPENAI_API_KEY en las variables de entorno.")
        logging.info('Clave de OpenAI obtenida')
        log_message('Finalizando funci√≥n <GetOpenAIKey>.', 'INFO')
        return api_key
    except Exception as e:
        log_message(f"Error al obtener la clave de OpenAI: {e}", 'ERROR')
        logging.error(f"Error al obtener la clave de OpenAI: {e}")
        raise
    
def get_classifier(msj: str, sender: str) -> Tuple[Optional[str], Optional[str], Dict[str, Any]]:
    try:
        """Clasifica un mensaje de WhatsApp usando un modelo fine-tuned de OpenAI."""
        log_message('Iniciando funci√≥n <GetClassifier>.', 'INFO')
        logging.info('Clasificando mensaje')
        classification_prompt: str = """
            Eres un clasificador de mensajes para un asistente de WhatsApp de un restaurante.
            Tu tarea es identificar la **intenci√≥n (intent)**, el **tipo de mensaje (type)** y cualquier **entidad relevante (entities)**.

            A continuaci√≥n tienes un ejemplo de c√≥mo debes estructurar las entidades cuando el usuario pide varios productos:

            EJEMPLO DE ENTRADA:
            "me das una sierra picante con extra picante y una malteada de chocolate"

            EJEMPLO DE SALIDA:
            {
            "intent": "solicitud_pedido",
            "type": "pedido",
            "entities": {
                "items": [
                {
                    "producto": "sierra picante",
                    "especificaciones": ["extra picante"]
                },
                {
                    "producto": "malteada de chocolate",
                    "especificaciones": []
                }
                ]
            }
            }
            EJEMPLO DE ENTRADA:
            "me das una sierra picante con extra picante y una malteada de chocolate"

            EJEMPLO DE SALIDA:
            {
            "intent": "solicitud_pedido",
            "type": "pedido",
            "entities": {
                "items": [
                {
                    "producto": "sierra picante",
                    "especificaciones": ["extra picante"]
                },
                {
                    "producto": "malteada de chocolate",
                    "especificaciones": []
                }
                ]
            }
            }
            Debes responder √∫nicamente en formato JSON v√°lido con la siguiente estructura:
            {
            "intent": "<una de las intenciones permitidas>",
            "type": "<tipo de mensaje>",
            "entities": { }
            }

            Lista de intenciones posibles:
            - confirmacion_general (puede ser en otros idiomas: yes, oui, ja, etc.)
            - consulta_menu
            - consulta_pedido
            - consulta_promociones
            - continuacion_pedido (puede ser en otros idiomas: yes, oui, ja, etc.)
            - direccion
            - info_personal
            - mas_datos_direccion
            - modificar_pedido (puede ser con palabras clave como cambiar, quitar, agregar, modificar, tambi√©n, etc.)
            Ejemplo: "quiero agregar una malteada de vainilla", "quiero que la hamburguesa no traiga lechuga", "cambia mi pedido por favor por...", "quitar la malteada", "tambi√©n quiero una gaseosa coca cola¬†original", "dame tambi√©n una malteada de chocolate", etc.
            - negacion_general (puede ser en otros idiomas: no, non, nein, etc.)
            - preguntas_generales
            - quejas (quejas de menor nivel)
            - saludo
            - sin_intencion
            - solicitud_pedido (pedidos de comida o bebida)
            - transferencia (quejas de mayor nivel)
            - validacion_pago (breb, nequi, daviplata, tarjeta, efectivo)
            - recoger_restaurante   (NUEVA intenci√≥n: cuando el usuario dice que pasar√° a recoger, ir√° al restaurante o lo recoge en tienda)
            - domicilio             (NUEVA intenci√≥n: cuando el usuario pide entrega a domicilio, "tr√°elo", "env√≠amelo", "a mi casa", etc.)

            Instrucciones importantes:
            - No incluyas texto fuera del JSON.
            - No uses comentarios, explicaciones o saltos de l√≠nea innecesarios.
            - Si no puedes determinar la intenci√≥n, usa "sin_intencion".
            """

        messages = [
            {"role": "system", "content": classification_prompt},
            {"role": "user", "content": msj}
        ]
        client: OpenAI = OpenAI(api_key=get_openai_key())
        respuesta: Any = client.chat.completions.create(
            model="ft:gpt-3.5-turbo-0125:net-applications:domicilios:CaSlaPnG",
            messages=messages,
            max_tokens=700,
            temperature=0
        )
        raw_response: str = respuesta.choices[0].message.content.strip()
        logging.info(f"[Clasificador RAW] {raw_response!r}")
        json_str: str = limpiar_respuesta_json(raw_response)
        result: Dict[str, Any] = json.loads(json_str)
        intent: Optional[str] = result.get("intent")
        type_: Optional[str] = result.get("type")
        entities: Dict[str, Any] = result.get("entities", {})
        if not intent or not type_:
            raise ValueError(f"Respuesta inv√°lida, faltan claves: {result}")
        logging.info(f"Respuesta del clasificador: {result}")
        logging.info(f"Intent: {intent}, Type: {type_}, Entities: {entities}")
        log_message('Finalizando funci√≥n <GetClassifier>.', 'INFO')
        return intent, type_, entities
    except Exception as e:
        log_message(f'Error al hacer uso de funci√≥n <GetClassifier>: {e}.', 'ERROR')
        logging.error(f"Error al clasificar el mensaje: {e}")
        send_text_response(sender, "Lo siento, hubo un error al procesar tu mensaje. ¬øPodr√≠as repetirlo?")
        return None, None, {}

def clasificar_pregunta_menu_chatgpt(pregunta_usuario: str, model: str = "gpt-3.5-turbo") -> dict:
    """
    Clasifica si una pregunta del usuario est√° relacionada con el men√∫ o con servicios
    del negocio (hamburgueser√≠a) usando un modelo de lenguaje (ChatGPT).
    """

    log_message('Iniciando funci√≥n <ClasificarPreguntaMenuChatGPT>.', 'INFO')
    client: OpenAI = OpenAI()

    prompt: str = f"""
    Eres un asistente que clasifica preguntas de clientes de una hamburgueser√≠a.

    Debes responder con un JSON EXACTO con la siguiente forma:
    {{
        "clasificacion": "relacionada" o "no_relacionada"
    }}

    Instrucciones:
    - Si la pregunta se refiere a comidas, hamburguesas, bebidas, malteadas, ingredientes, precios, combos,
      opciones vegetarianas o cualquier cosa del men√∫ ‚Üí "relacionada".
    - Tambi√©n clasifica como "relacionada" si el cliente pregunta sobre:
        ‚Ä¢ formas de pago (Nequi, Daviplata, efectivo, tarjetas, etc.)
        ‚Ä¢ si hacen domicilios o env√≠os
        ‚Ä¢ horarios de atenci√≥n
        ‚Ä¢ direcci√≥n o ubicaci√≥n del local
        ‚Ä¢ contacto, pedidos o reservas
        ‚Ä¢ promociones o descuentos
    - Si la pregunta es sobre temas generales, ajenos al restaurante (por ejemplo: Bogot√°, clima, pel√≠culas, tecnolog√≠a, etc.) ‚Üí "no_relacionada".

    Ejemplos:
    1Ô∏è‚É£ "qu√© hamburguesas tienen?" ‚Üí {{"clasificacion": "relacionada"}}
    2Ô∏è‚É£ "hay hamburguesas de pollo?" ‚Üí {{"clasificacion": "relacionada"}}
    3Ô∏è‚É£ "qu√© malteadas tienen?" ‚Üí {{"clasificacion": "relacionada"}}
    4Ô∏è‚É£ "tienen opciones vegetarianas?" ‚Üí {{"clasificacion": "relacionada"}}
    5Ô∏è‚É£ "aceptan pagos por nequi?" ‚Üí {{"clasificacion": "relacionada"}}
    6Ô∏è‚É£ "hacen env√≠os a suba?" ‚Üí {{"clasificacion": "relacionada"}}
    7Ô∏è‚É£ "cu√°l es su horario?" ‚Üí {{"clasificacion": "relacionada"}}
    8Ô∏è‚É£ "d√≥nde est√°n ubicados?" ‚Üí {{"clasificacion": "relacionada"}}
    9Ô∏è‚É£ "d√≥nde queda Bogot√°?" ‚Üí {{"clasificacion": "no_relacionada"}}
    üîü "qu√© es Python?" ‚Üí {{"clasificacion": "no_relacionada"}}

    Ahora clasifica la siguiente pregunta del usuario:
    "{pregunta_usuario}"

    Devuelve SOLO el JSON, sin explicaci√≥n adicional.
    """

    try:
        response = client.responses.create(
            model=model,
            input=prompt,
            temperature=0
        )
        text_output = response.output[0].content[0].text.strip()
        result = json.loads(text_output)
        log_message('Finalizando funci√≥n <ClasificarPreguntaMenuChatGPT>.', 'INFO')
        return result

    except json.JSONDecodeError:
        logging.error(f"Error al parsear JSON: {text_output}")
        log_message(f'Error al parsear JSON en <ClasificarPreguntaMenuChatGPT>: {text_output}', 'ERROR')
        return {"clasificacion": "no_relacionada"}
    except Exception as e:
        logging.error(f"Error en <ClasificarPreguntaMenuChatGPT>: {e}")
        log_message(f'Error en <ClasificarPreguntaMenuChatGPT>: {e}.', 'ERROR')
        return {"clasificacion": "no_relacionada"}

def _clean_model_output(raw: str) -> str:
    """
    Limpia output que pueda venir en triple-backticks o con '```json' al inicio.
    Devuelve el string JSON limpio (o el raw si no hab√≠a marcas).
    """
    if not raw:
        return ""
    s = raw.strip()

    # Si el modelo devolvi√≥ bloque con ```json ... ```
    if s.startswith("```"):
        # eliminar backticks al inicio y final
        s = s.strip("`").strip()
        # si a√∫n tiene prefijo 'json' eliminarlo
        if s.lower().startswith("json"):
            s = s[len("json"):].lstrip("\r\n ").strip()

    return s

def _extract_text_from_response(response) -> str:
    """
    Extrae texto del objeto devuelto por client.responses.create de forma robusta.
    Prioriza response.output_text, luego response.output[*].content[*].text, 
    luego intenta concatenar todo lo que encuentre.
    """
    # 1) output_text (forma simple)
    try:
        output_text = getattr(response, "output_text", None)
        if output_text:
            return str(output_text).strip()
    except Exception:
        pass

    # 2) response.output -> content
    try:
        if hasattr(response, "output") and response.output:
            parts = []
            for out in response.output:
                # cada out puede tener 'content' que es lista de dicts
                content = getattr(out, "content", None) or out.get("content", None) if isinstance(out, dict) else None
                if content:
                    for c in content:
                        # c puede ser dict con 'text' u 'type' y 'content'
                        if isinstance(c, dict):
                            if "text" in c and c["text"]:
                                parts.append(c["text"])
                            elif "type" in c and c["type"] == "output_text" and "text" in c:
                                parts.append(c["text"])
                            else:
                                # intentar stringify
                                parts.append(json.dumps(c, ensure_ascii=False))
                        else:
                            parts.append(str(c))
            if parts:
                return "\n".join(parts).strip()
    except Exception:
        pass

    # 3) fallback: str(response)
    try:
        return str(response).strip()
    except Exception:
        return ""

def responder_pregunta_menu_chatgpt(pregunta_usuario: str, items, model: str = "gpt-4o") -> dict:
    """
    Responde preguntas del usuario sobre el men√∫ o servicios del restaurante Sierra Nevada üçî.
    Incluye informaci√≥n sobre horarios, sedes y medios de pago.
    Devuelve: (result: dict, prompt: str)
    """
    log_message('Iniciando funci√≥n <ResponderPreguntaMenuChatGPT>.', 'INFO')

    # Prompt unificado
    prompt = f"""
        Eres PAKO, el asistente c√°lido y cercano de Sierra Nevada, La Cima del Sabor üèîÔ∏èüçî.
        Tu tarea es ayudar al cliente con informaci√≥n sobre el men√∫, horarios, sedes y servicios,
        siempre con el tono oficial de la marca: amable, natural y con un toque sabroso, sin exagerar.

        Informaci√≥n del restaurante:
        üïê Horario: Todos los d√≠as de 12:00 p.m. a 7:00 p.m.
        üìç Sedes:
        - Galer√≠as: Calle 53 #27-16
        - Centro Mayor: CC Centro Mayor, local 3-019
        - Centro Internacional: Calle 32 #07-10
        - Chic√≥ 2.0: Calle 100 #9A-45, local 7A
        - Virrey: Carrera 15 #88-67
        üí≥ Medios de pago: Nequi, Daviplata, tarjeta d√©bito, cr√©dito y efectivo.

        El cliente pregunt√≥: "{pregunta_usuario}"

        Este es el men√∫ completo:
        {json.dumps(items, ensure_ascii=False)}

        PAUTAS DE TONO (OBLIGATORIAS):
        - Habla como un buen anfitri√≥n bogotano: c√°lido, natural y claro.
        - Siempre cordial, sin sarcasmo, sin iron√≠a y sin jerga barrial.
        - Puedes usar m√°ximo 1 emoji suave si queda natural.
        - No inventes productos, ingredientes ni sedes.
        - S√© breve y humano, como si hablaras por WhatsApp.
        - Mant√©n un toque emocional o visual de sabor cuando sea apropiado.

        INSTRUCCIONES DE RESPUESTA:
        - Si la pregunta es sobre horarios, sedes, medios de pago o env√≠os, responde con la informaci√≥n dada.
        - Si el cliente pide algo que s√≠ aparece en el men√∫, descr√≠belo brevemente o conf√≠rmalo.
        - Si pide algo que NO est√° en el men√∫, ind√≠calo con amabilidad y sugiere m√°ximo 2 opciones similares.
        - Si pregunta por categor√≠as (picante, vegetariano, pollo, bebidas, postres, etc.), responde seg√∫n el men√∫.
        - Si pregunta por algo ambiguo, aclara con amabilidad.
        - Evita frases impersonales (ej. ‚Äúsu solicitud ha sido procesada‚Äù).
        - Evita exageraciones o tono juvenil extremo.
        - Mant√©n la respuesta en m√°ximo 2 frases si es posible.

        FORMATO OBLIGATORIO DE SALIDA:
        Devuelve SOLO un JSON v√°lido con esta estructura EXACTA:

        {{
            "respuesta": "texto amigable para el cliente",
            "recomendacion": true o false,
            "productos": ["nombre1", "nombre2"]
        }}

        Ejemplo:
        Usuario: "¬øTienen opciones picantes?"
        -> {{
            "respuesta": "Claro üëç Tenemos opciones con car√°cter como la Sierra Picante y la Sierra BBQ, ambas con un toque fuerte.",
            "recomendacion": false,
            "productos": ["Sierra Picante", "Sierra BBQ"]
        }}
        """
    try:
        client = OpenAI()
        response = client.responses.create(
            model=model,
            input=prompt
        )

        raw_text = _extract_text_from_response(response)
        raw_text = _clean_model_output(raw_text)
        logging.info(f"[DEBUG] Texto crudo del modelo: {raw_text!r}")

        if not raw_text:
            raise ValueError("Respuesta vac√≠a del modelo")

        try:
            result = json.loads(raw_text)
        except json.JSONDecodeError:
            import re
            m = re.search(r"(\{[\s\S]*\})", raw_text)
            if m:
                result = json.loads(m.group(1))
            else:
                result = {"respuesta": raw_text, "recomendacion": False, "productos": []}

        if "productos" in result and isinstance(result["productos"], list):
            result["productos"] = [p.replace('\u00a0', ' ').strip() for p in result["productos"]]

        pregunta_lower = pregunta_usuario.lower()
        if any(token in pregunta_lower for token in ["?", "tienen", "hay", "venden", "cu√°les", "qu√© opciones", "me recomiendas", "qu√© hay"]):
            respuesta_txt = str(result.get("respuesta", "")).strip()
            if respuesta_txt and not respuesta_txt.endswith(("?", ".", "!", "üòã", "üòâ", "üòé")):
                result["respuesta"] = respuesta_txt + " ¬øQuieres probarla? üòã"

        result.setdefault("productos", [])
        result.setdefault("recomendacion", False)

        log_message('Finalizando funci√≥n <ResponderPreguntaMenuChatGPT>.', 'INFO')
        return result

    except Exception as e:
        logging.error(f"Error en <ResponderPreguntaMenuChatGPT>: {e}")
        log_message(f'Error en <ResponderPreguntaMenuChatGPT>: {e}', 'ERROR')
        return {
            "respuesta": "Lo siento üòî, tuve un problema para responder tu pregunta.",
            "recomendacion": False,
            "productos": []
        }

def mapear_pedido_al_menu(contenido_clasificador: dict, menu_items: list, model: str = "gpt-5.1") -> dict:
    """
    Mapear los items provenientes del clasificador AL MEN√ö usando GPT.
    """
    client = OpenAI()

    prompt = f"""
        Eres un asistente encargado de mapear pedidos (extra√≠dos por un clasificador) a un MEN√ö estructurado.
        Debes RESPONDER √öNICA Y EXCLUSIVAMENTE con un JSON v√°lido (sin texto adicional) con esta estructura:
        {{
            "order_complete": true|false,
            "items": [
                {{
                    "requested": {{ "producto": "...", "modalidad": "...", "especificaciones": [ ... ] }},
                    "status": "found" | "not_found" | "multiple_matches",
                    "matched": {{ "name": "...", "id": "...", "price": number }},
                    "candidates": [ {{ "name":"...", "id":"...", "price": number }}, ... ],
                    "modifiers_applied": [ ... ],
                    "note": ""
                }}
            ],
            "total_price": number
        }}

        ======================================================
        = COMPORTAMIENTO GLOBAL DEL MODELO =
        ======================================================
        Debes identificar los productos del men√∫ incluso cuando est√©n:
        - mal escritos,
        - abreviados,
        - rotos en s√≠labas,
        - fusionados,
        - con espacios de m√°s o de menos,
        - escritos fon√©ticamente,
        - mezclados con palabras irrelevantes,
        - con diminutivos o versiones coloquiales,
        - con apodos informales,
        - usando solo parte del nombre (ej: ‚Äúinsaciable‚Äù, ‚Äúcl√°sica‚Äù, ‚Äúqueso‚Äù, ‚Äúmulata‚Äù, ‚Äúcoste√±a‚Äù, ‚Äúmalte vaini‚Äù, ‚Äúroman 400‚Äù, ‚Äúperro toci‚Äù, etc.).

        DEBES RECONOCER *CUALQUIER* producto del men√∫ mediante:
        - normalizaci√≥n,
        - sinonimia,
        - fuzzy matching,
        - similitud sem√°ntica,
        - heur√≠sticas inteligentes.

        ======================================================
        = NORMALIZACI√ìN EXTREMA (APLICAR A TODA ENTRADA) =
        ======================================================
        Antes de buscar coincidencias debes:
        - pasar todo a min√∫sculas,
        - quitar acentos,
        - corregir repeticiones (‚Äúqueeesssooo‚Äù ‚Üí ‚Äúqueso‚Äù),
        - eliminar palabras vac√≠as (un, una, de, porfa, porfaaa, ml, tama√±o, etc.),
        - corregir deformaciones fon√©ticas:
            * ‚Äúquesuo‚Äù, ‚Äúkezo‚Äù, ‚Äúkeeso‚Äù ‚Üí ‚Äúqueso‚Äù
            * ‚Äúvete‚Äù, ‚Äúvegui‚Äù, ‚Äúbegui‚Äù ‚Üí ‚Äúveggie‚Äù
            * ‚Äúancasiable‚Äù, ‚Äúinsasiable‚Äù ‚Üí ‚Äúinsaciable‚Äù
            * ‚Äúmelaoo‚Äù, ‚Äúmelaon‚Äù, ‚Äúmelado‚Äù ‚Üí ‚Äúmelao‚Äù
            * ‚Äúpaguer‚Äù, ‚Äúpower‚Äù, ‚Äúpauer‚Äù ‚Üí ‚Äúpag√ºer‚Äù
            * ‚Äúmulate‚Äù, ‚Äúmulatta‚Äù, ‚Äúmulada‚Äù ‚Üí ‚Äúmulata‚Äù
            * ‚Äúcosteno‚Äù, ‚Äúcostenio‚Äù ‚Üí ‚Äúcoste√±o‚Äù
            * ‚Äúsuper pero‚Äù, ‚Äúsupe perro‚Äù, ‚Äúsuperperro‚Äù ‚Üí ‚Äúsuper perro‚Äù
            * ‚Äútocino‚Äù, ‚Äútocineta‚Äù, ‚Äútocinita‚Äù ‚Üí ‚Äútocineta‚Äù
            * ‚Äúfuse‚Äù, ‚Äúfuzetea‚Äù ‚Üí ‚Äúfuze tea‚Äù
        - convertir palabras con n√∫mero ‚Üí posibles tama√±os (ej: 400 ‚Üí 400 ml)
        - eliminar texto irrelevante (‚Äúporfa‚Äù, ‚Äúquiero‚Äù, ‚Äúdame‚Äù, ‚Äúser√≠a‚Äù, ‚Äúde pronto‚Äù, etc.)

        ======================================================
        = SINONIMIA SEM√ÅNTICA (PARA TODO EL MEN√ö) =
        ======================================================
        Debes asumir que los clientes pueden decir:
        - solo una parte del nombre (‚Äúinsaciable‚Äù, ‚Äúqueso‚Äù, ‚Äúpaguer‚Äù, ‚Äúperro toci‚Äù)
        - apodos: 
            * ‚Äúclasica‚Äù ‚Üí ‚ÄúSierra Clasica‚Äù
            * ‚Äúmelao‚Äù ‚Üí ‚ÄúSierra Melao‚Äù
            * ‚Äúpicante‚Äù ‚Üí ‚ÄúSierra Picante‚Äù
            * ‚Äúcoste√±a‚Äù ‚Üí ‚ÄúSierra Coste√±a‚Äù
            * ‚Äúbomba‚Äù ‚Üí ‚ÄúSierra Bomba‚Äù
            * ‚Äúmulata‚Äù ‚Üí ‚ÄúSierra Mulata‚Äù
            * "doble carne" ‚Üí "Doble Carne"
        - equivalencias:
            * ‚Äúhamburguesa‚Äù, ‚Äúburgesa‚Äù, ‚Äúburguer‚Äù, ‚Äúhambur‚Äù ‚Üí categor√≠a hamburguesas
            * ‚Äúperro‚Äù, ‚Äúhotdog‚Äù, ‚Äúdog‚Äù, ‚Äúhot dog‚Äù ‚Üí perros calientes
            * ‚Äúpapa‚Äù, ‚Äúpapitas‚Äù, ‚Äúfritas‚Äù ‚Üí papas / acompa√±amientos
            * ‚Äúadicion‚Äù, ‚Äúagregado‚Äù, ‚Äúextra‚Äù, ‚Äúsumale‚Äù ‚Üí adicionales
            * ‚Äúsalsita‚Äù, ‚Äúsauce‚Äù, ‚Äúaderezo‚Äù ‚Üí salsas

        ======================================================
        = TOLERANCIA TOTAL A ERRORES (FUZZY MATCHING) =
        ======================================================
        Un producto cuenta como posible match si:
        - distancia Levenshtein < 35%
        - similitud sem√°ntica razonable
        - palabra base suena similar (matching fon√©tico)
        - comparte palabras clave del nombre real

        Ejemplo:
        - ‚Äúvegui queso‚Äù ‚Üí ‚ÄúVeggie Queso‚Äù
        - ‚Äúperro toci‚Äù ‚Üí ‚ÄúPerro Tocineta‚Äù
        - ‚Äúinsasiable‚Äù ‚Üí ‚ÄúLa Insaciable‚Äù
        - ‚Äúpaguer‚Äù ‚Üí ‚ÄúSierra Pag√ºer‚Äù
        - ‚Äúqueso sierra‚Äù ‚Üí ‚ÄúSierra Queso‚Äù

        ======================================================
        = PRIORIDAD DE MATCHING =
        ======================================================
        A) Coincidencia exacta ‚Üí FOUND.
        B) Coincidencia por alias ‚Üí FOUND.
        C) Coincidencia parcial fuerte ‚Üí FOUND.
        D) Coincidencia sem√°ntica ‚Üí FOUND.
        E) Fuzzy match ‚Üí FOUND si solo coincide uno.
        F) Si 2+ coinciden ‚Üí MULTIPLE_MATCHES.
        G) Si 0 coinciden:
            ‚Üí NOT_FOUND
            ‚Üí sugerir m√°ximo 3 alternativas de la misma categor√≠a.

        ======================================================
        = REGLAS FINALES =
        ======================================================
        - Usa exactamente el nombre del men√∫ en el campo matched.name.
        - Si un √≠tem es not_found ‚Üí order_complete = false.
        - total_price = suma de precios.
        - Respuesta SIEMPRE debe ser solamente el JSON.

        MEN√ö COMPLETO:
        {json.dumps(menu_items, ensure_ascii=False)}

        CLASIFICADOR:
        {json.dumps(contenido_clasificador, ensure_ascii=False)}

        DEVUELVE SOLO EL JSON.
        """
    try:
        log_message('Iniciando funci√≥n <MapearPedidoAlMenu>.', 'INFO')

        response = client.responses.create(
            model=model,
            input=prompt,
            max_completion_tokens = 500,
            temperature=0
        )

        text_output = response.output[0].content[0].text.strip()
        log_message(f'Output crudo de modelo en <MapearPedidoAlMenu>: {text_output}', 'DEBUG')

        clean = text_output.strip()
        clean = re.sub(r'^```json', '', clean, flags=re.IGNORECASE).strip()
        clean = re.sub(r'^```', '', clean).strip()
        clean = re.sub(r'^json', '', clean, flags=re.IGNORECASE).strip()
        clean = re.sub(r'```$', '', clean).strip()

        result = json.loads(clean)

        log_message('Finalizando funci√≥n <MapearPedidoAlMenu>.', 'INFO')
        return result

    except json.JSONDecodeError:
        logging.error("Error al parsear JSON desde el modelo.")
        logging.error(text_output if 'text_output' in locals() else 'no output')
        log_message(f'Error al parsear JSON en <MapearPedidoAlMenu>: {text_output}', 'ERROR')

        return {
            "order_complete": False,
            "items": [],
            "total_price": 0,
            "error": "parse_error",
            "raw_output": text_output if 'text_output' in locals() else None
        }

    except Exception as e:
        logging.exception("Error llamando al API")
        log_message(f'Error en <MapearPedidoAlMenu>: {e}', 'ERROR')

        return {
            "order_complete": False,
            "items": [],
            "total_price": 0,
            "error": str(e)
        }

    
def sin_intencion_respuesta_variable(contenido_usuario: str, nombre_cliente: str) -> str:
    try:
        log_message('Iniciando funci√≥n <sin_intencion>.', 'INFO')
        PROMPT_SIN_INTENCION = (
            "Eres el asistente oficial de Sierra Nevada, La Cima del Sabor.\n"
            "Tu objetivo es responder cuando el cliente env√≠a algo que no tiene sentido, "
            "como una palabra suelta, emojis sin contexto, n√∫meros o s√≠mbolos.\n\n"

            "TONO DE MARCA:\n"
            "- C√°lido, cercano y respetuoso.\n"
            "- Puedes usar un toque juguet√≥n o ligero, pero sin sarcasmo ni iron√≠a.\n"
            "- Lenguaje natural, claro y amable, como un buen anfitri√≥n bogotano.\n"
            "- Puedes usar 1 emoji suave si queda natural.\n"
            "- Nunca suenes burl√≥n, defensivo o exagerado.\n\n"

            "REGLAS:\n"
            "- Si el usuario env√≠a algo aleatorio como 'a', 'su', emojis o s√≠mbolos, "
            "responde con amabilidad y un gui√±o ligero, manteniendo calidez.\n"
            "- Si env√≠a banderas, puedes decir algo como: "
            "\"No estoy seguro c√≥mo se relaciona {contenido}, pero aqu√≠ estoy para ayudarte\".\n"
            "- Termina SIEMPRE con un llamado a la acci√≥n invitando al cliente a contarte "
            "qu√© desea pedir o consultar.\n"
            "- Incluye el nombre del cliente: {nombre_cliente}.\n"
            "- M√°ximo 1 o 2 frases.\n"
            "- No inventes productos.\n\n"

            "Contenido del usuario: \"{contenido}\"\n"
            "Nombre del cliente: \"{nombre_cliente}\"\n\n"
            "Responde aqu√≠:"
        )
        client = OpenAI()
        prompt = PROMPT_SIN_INTENCION.format(
            contenido=contenido_usuario,
            nombre_cliente=nombre_cliente
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un asistente de un restaurante que responde con humor amable y ligero sarcasmo."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=80,
            temperature=0.9
        )
        mensaje = response.choices[0].message.content
        log_message('Finalizando funci√≥n <sin_intencion>.', 'INFO')
        return mensaje.strip()
    except Exception as e:
        log_message(f'Error en funci√≥n <sin_intencion>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <sin_intencion>: {e}")
        return "Lo siento, no entend√≠ tu mensaje. ¬øPodr√≠as repetirlo de otra forma?"

def saludo_dynamic(mensaje_usuario: str, nombre: str, nombre_local: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <saludo_dynamic>.', 'INFO')
        PROMPT_SALUDO_DYNAMIC = """
            Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
            Tu tarea es generar un saludo personalizado seg√∫n el tono que use el cliente.

            El cliente escribi√≥: "{mensaje_usuario}"

            PAUTAS DE TONO:
            1. Si el cliente usa expresiones informales como:
            "q hubo", "quiubo", "k hubo", "que m√°s", "que mas", "q mas",
            "hey", "holi", "epa", "epaaa", "hoola", "hola parce",
            entonces:
                - Usa un tono cercano, relajado y natural, sin jerga excesiva.
                - Puedes usar 1 emoji suave si fluye bien.
                - Mant√©n calidez y sensaci√≥n de bienvenida al estilo Sierra Nevada.

            2. Si el cliente usa expresiones formales como:
            "buenas tardes", "buenos d√≠as", "buen dia",
            "cordial saludo", "mucho gusto", "estimados",
            entonces:
                - Usa un tono respetuoso, profesional y sereno.
                - No uses emojis.
                - Mant√©n claridad, amabilidad y un toque c√°lido sin exagerar.

            3. En cualquier otro caso:
                - Usa un tono cordial est√°ndar: amable, natural y con sabor.
                - Puedes usar un emoji suave si queda org√°nico.

            REGLAS DE ESTILO SIERRA NEVADA:
            - Habla como un buen anfitri√≥n: c√°lido, claro y con energ√≠a positiva.
            - Evita expresiones barriales, sarcasmo o exageraciones.
            - Mant√©n un lenguaje cotidiano y respetuoso.
            - No inventes productos ni detalles.
            - Puedes mencionar solamente: ‚Äúmen√∫‚Äù, ‚Äúpromociones‚Äù, ‚Äúburgers‚Äù, ‚Äúrecomendaciones‚Äù.
            - Incluye siempre el nombre del cliente: {nombre}
            - Incluye siempre el nombre del local: {nombre_local}
            - Responde en m√°ximo 1 o 2 frases.
            - Escoge UNA intenci√≥n entre:
                - "consulta_menu"
                - "consulta_promociones"
            FORMATO:
            Debes responder en un JSON v√°lido:
            {{
                "mensaje": "texto aqu√≠",
                "intencion": "consulta_menu"
            }}
            No incluyas texto adicional fuera del JSON.
            """
        client = OpenAI()
        prompt = PROMPT_SALUDO_DYNAMIC.format(
            nombre=nombre,
            nombre_local=nombre_local,
            mensaje_usuario=mensaje_usuario.lower()
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un generador de saludos que adapta su tono al del cliente."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=150,
            temperature=0.85
        )
        raw = response.choices[0].message.content.strip()
        try:
            data = json.loads(raw)
        except:
            data = {
                "mensaje": f"¬°Hola {nombre}! Bienvenido a {nombre_local}. ¬øQuieres que te muestre el men√∫?",
                "intencion": "consulta_menu"
            }
        log_message('Finalizando funci√≥n <saludo_dynamic>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <saludo_dynamic>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <saludo_dynamic>: {e}")
        return {
            "mensaje": f"¬°Hola {nombre}! Bienvenido a {nombre_local}. ¬øQuieres que te muestre el men√∫?",
            "intencion": "consulta_menu"
        }
    
def respuesta_quejas_ia(mensaje_usuario: str, nombre: str, nombre_local: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <respuesta_quejas>.', 'INFO')
        PROMPT_QUEJA_LEVE = """
            Eres el asistente oficial de servicio al cliente de Sierra Nevada, La Cima del Sabor.

            Tu tarea es responder una queja leve con el tono y personalidad de la marca:
            - C√°lido, cercano y respetuoso.
            - Natural, humano, sin excesos.
            - Con un toque de sabor y buena energ√≠a, sin sonar exagerado.
            - Orgullosamente colombiano, pero sin clich√©s.
            - Hablas como un buen anfitri√≥n bogotano: amable, claro y sin jerga popular.
            El cliente llamado {nombre} escribi√≥ lo siguiente: "{mensaje_usuario}"
            OBJETIVO:
            - Tranquilizar al cliente.
            - Validar su experiencia sin culpas ni defensividad.
            - Incluir SIEMPRE una acci√≥n concreta para mostrar que est√°s atendiendo el caso 
            (por ejemplo: ‚Äúle cuento al equipo‚Äù, ‚Äúreviso con cocina‚Äù, ‚Äúlo paso al encargado del punto‚Äù).
            - Mostrar disposici√≥n a ayudar SIN escalar el caso a un agente humano.
            - Mantener un tono amable y con toque emocional de Sierra Nevada.
            - Usar m√°ximo 1 emoji suave si fluye de manera natural.
            - Responder en m√°ximo 2 frases.

            REGLAS DE TONO:
            - No uses sarcasmo, iron√≠as ni expresiones barriales.
            - No suenes rob√≥tico ni impersonal.
            - No inventes informaci√≥n.
            - Mant√©n una sensaci√≥n de servicio, calidez y sabor.
            - Evita anglicismos y tecnicismos.
            - Puedes mencionar solo: equipo, servicio, experiencia, tiempo de entrega, sabor, atenci√≥n.

            CONTENIDO:
            Debes generar:
            1. "respuesta_cordial": un mensaje amable y emp√°tico que tranquilice al cliente, 
            incluyendo una acci√≥n concreta como ‚Äúreviso con cocina‚Äù, ‚Äúle cuento al equipo del punto‚Äù 
            o ‚Äúdejo la nota para mejorar tu pr√≥xima experiencia‚Äù.
            2. "resumen_queja": una frase corta que resuma la queja sin inventar detalles.
            3. "intencion": siempre "queja_leve".

            FORMATO DE RESPUESTA:
            La respuesta DEBE ser un JSON v√°lido:
            {
                "respuesta_cordial": "texto aqu√≠",
                "resumen_queja": "texto aqu√≠",
                "intencion": "queja_leve"
            }
            Genera solo el JSON sin texto adicional.
            """
        client = OpenAI()
        prompt = PROMPT_QUEJA_LEVE.format(
            mensaje_usuario=mensaje_usuario,
            nombre=nombre
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "Eres un generador de respuestas amables para quejas leves de clientes."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=180,
            temperature=0.6
        )
        raw = response.choices[0].message.content.strip()
        try:
            data = json.loads(raw)
        except:
            data = {
                "respuesta_cordial": f"{nombre}, gracias por escribirnos. Lamentamos que tu experiencia en {nombre_local} no haya sido perfecta; estamos aqu√≠ para ayudarte üòä",
                "resumen_queja": "Queja leve del cliente sobre su experiencia.",
                "intencion": "quejas"
            }
        log_message('Finalizando funci√≥n <respuesta_quejas>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <respuesta_quejas>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <respuesta_quejas>: {e}")
        return {
            "respuesta_cordial": f"{nombre}, gracias por avisarnos. Estamos atentos para que tu experiencia en {nombre_local} sea mejor cada vez.",
            "resumen_queja": "Queja leve del cliente.",
            "intencion": "quejas"
        }

def respuesta_quejas_graves_ia(mensaje_usuario: str, nombre: str, nombre_local: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <respuesta_quejas_graves_ia>.', 'INFO')
        PROMPT_QUEJA_GRAVE = """
            Eres el asistente oficial de servicio al cliente de Sierra Nevada, La Cima del Sabor.
            Esta vez atender√°s *quejas graves*, donde puede que el pedido NO haya llegado,
            haya habido un error fuerte, mala manipulaci√≥n o tiempo excesivo.
            ***OBJETIVO GENERAL***
            - Calmar al cliente.
            - Asumir responsabilidad sin culpas excesivas.
            - Dar una ACCI√ìN clara y concreta que el asistente realizar√°.
            - Preparar un resumen ejecutivo para un administrador humano.
            - NO escalar directamente en el mensaje al cliente (solo en el resumen interno).
            - M√°ximo 2 frases, tono c√°lido, humano, cercano, estilo Sierra Nevada, colombiano neutro.
            ***DEBES ENTREGAR ESTOS CAMPOS***
            1. "respuesta_cordial": Mensaje calmado, emp√°tico y con acci√≥n concreta 
            (ej: ‚Äúreviso ya mismo con cocina y log√≠stica‚Äù, ‚Äúactivo seguimiento con el punto‚Äù).
            2. "resumen_queja": Descripci√≥n breve de lo que reclama el cliente.
            3. "accion_recomendada": Acci√≥n clara que el sistema/administrador debe hacer 
            (ej: verificar estado del pedido, contactar punto, revisar domiciliario).
            4. "resumen_ejecutivo": Resumen para administrador (breve, objetivo, sin adornos).
            5. "intencion": Siempre "queja_grave".
            ***TONO***
            - C√°lido y responsable.
            - Sin tecnicismos ni sarcasmo.
            - Evita respuestas rob√≥ticas.
            - M√°ximo un emoji, si fluye natural.

            Cliente llamado {nombre} escribi√≥:
            "{mensaje_usuario}"
            ***FORMATO OBLIGATORIO***
            Devuelve SOLO un JSON v√°lido:
            {{
                "respuesta_cordial": "",
                "resumen_queja": "",
                "accion_recomendada": "",
                "resumen_ejecutivo": "",
                "intencion": "queja_grave"
            }}
        """
        client = OpenAI()
        prompt = PROMPT_QUEJA_GRAVE.format(
            mensaje_usuario=mensaje_usuario,
            nombre=nombre
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un generador de respuestas para quejas graves de clientes."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=220,
            temperature=0.6
        )
        raw = response.choices[0].message.content.strip()
        try:
            data = json.loads(raw)
        except:
            data = {
                "respuesta_cordial": f"{nombre}, ya reviso lo ocurrido con tu experiencia en {nombre_local} y activo el seguimiento de inmediato.",
                "resumen_queja": "Queja grave del cliente sobre servicio o pedido.",
                "accion_recomendada": "Revisi√≥n urgente con el punto y estado del pedido.",
                "resumen_ejecutivo": "Cliente reporta una queja grave; requiere revisi√≥n del punto y log√≠stica.",
                "intencion": "queja_grave"
            }
        log_message('Finalizando funci√≥n <respuesta_quejas_graves_ia>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <respuesta_quejas_graves_ia>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <respuesta_quejas_graves_ia>: {e}")
        return {
            "respuesta_cordial": f"{nombre}, reviso de inmediato lo que pas√≥ con tu experiencia en {nombre_local}.",
            "resumen_queja": "Queja grave del cliente.",
            "accion_recomendada": "Verificar con el punto y log√≠stica.",
            "resumen_ejecutivo": "Error en el proceso autom√°tico, requiere revisi√≥n manual.",
            "intencion": "queja_grave"
        }

def pedido_incompleto_dynamic(mensaje_usuario: str, menu: list, json_pedido: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <pedido_incompleto_dynamic>.', 'INFO')
        PROMPT_PEDIDO_INCOMPLETO = """
            Eres la voz oficial de Sierra Nevada, La Cima del Sabor. Te llamas PAKO.
            El cliente escribi√≥: "{mensaje_usuario}"
            El gestor de pedidos detect√≥ que el pedido est√° INCOMPLETO o POCO CLARO:
            {json_pedido}
            Tu tarea:
            - Responder SOLO con un JSON v√°lido.
            - NO inventar productos. NO mencionar nada que NO est√© en el men√∫.
            - Si el cliente pide algo que NO existe en el men√∫ (ej: "lasa√±a", "lasagna"), debes:
                * Indicar amablemente que ese producto no est√° disponible.
                * Sugerir 1 a 3 opciones REALES y relacionadas del men√∫.
            - Si el cliente pide algo MUY GENERAL (ej: "una hamburguesa", "una bebida"), debes:
                * Dar 1 a 3 recomendaciones REALES del men√∫ que s√≠ coincidan.
            - SIEMPRE pedir que el cliente vuelva a escribir TODO su pedido claramente.
            Responde SOLO en este formato exacto:
            {{
                "mensaje": "texto aqu√≠",
                "recomendaciones": ["Opci√≥n 1", "Opci√≥n 2"],
                "intencion": "consulta_menu"
            }}
            Reglas estrictas:
            - No inventes productos. Usa √öNICAMENTE nombres EXACTOS del men√∫.
            - Si el cliente menciona algo NO presente en el men√∫, dilo expl√≠citamente.
            - No respondas como asistente conversacional. Solo JSON.
            - No agregues explicaciones fuera del JSON.
            Aqu√≠ est√° el men√∫ disponible:
            {menu_str}
            LAS HAMBURGESAS SE LLAMAN:
            "Veggie Queso"
            "La Insaciable"
            "Sierra Bomba"
            "Sierra Mulata"
            "Sierra Pag√ºer"
            "Sierra Picante"
            "Sierra Coste√±a"
            "Sierra Melao"
            "Sierra Clasica"
            "Camino a la cima"
            "Sierra Queso"
        HAY PERROS CALIENTES LLAMADOS:
            "Super Perro"
            "Super Chanchita"
            "Perro Tocineta"
        CUANDO PIDAN UN ADICIONAL EN CUALQUIER PRODUCTO, SOLO PUEDE SER:
        	"Carne de res 120g"
            "Cebollas caramelizadas"
            "Cebollas caramelizadas picantes"
            "Pepinillos agridulces"
            "Pl√°tano maduro frito"
            "Suero coste√±o"
            "Chicharr√≥n"
            "Tocineta"
            "Queso coste√±o frito"
            "Queso cheddar"
        CUANDO PIDAN SALSAS, SOLO PUEDE SER:
            "Salsa de tomate"
            "Salsa mostaza"
            "Salsa bbq"
            "Salsa mayonesa"
        CUANDO PIDAN BEBIDAS, SOLO PUEDE SER:
            "Malteada de Vainilla"
            "Malteada de Mil0"
            "Malteada de Frutos Rojos"
            "Malteada de Chocolate y avellanas"
            "Malteada de Arequipe"
            "Malteada Oblea"
            "Malteada Galleta"
            "Fuze tea de manzana 400 ml"
            "Fuze tea de lim√≥n 400 ml"
            "Fuze tea de durazno 400 ml"
            "Kola Roman 400 ml"
            "Quatro 400 ml"
            "Sprite 400ml"
            "Coca Cola Sin Az√∫car 400 ml"
            "Coca Cola Original 400 ml"
            "Agua normal 600 ml"
            "Agua con gas 600ml"
            "Limonada de panela org√°nica 350Ml"
        CUANDO PIDAN ACOMPA√ëAMIENTOS, SOLO PUEDE SER:
            "Platanitos maduros"
            "Papas Coste√±as (francesas medianas + 4 deditos de queso coste√±o)"
            "Coste√±itos fritos + Suero Coste√±o"
            "Anillos de Cebolla"
            "Papas francesas"
            """
        menu_str = "\n".join([f"- {item['nombre']}" for item in menu])

        prompt = PROMPT_PEDIDO_INCOMPLETO.format(
            mensaje_usuario=mensaje_usuario.lower(),
            menu_str=menu_str,
            json_pedido=json_pedido
        )
        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-5.1",
            messages=[
                {"role": "system", "content": "Eres un asistente que ayuda al cliente a consultar el men√∫ y elegir su pedido."},
                {"role": "user", "content": prompt}
            ],
#este modelo no limita los tokens            max_tokens=450,
            temperature=0.2
        )
        raw = response.choices[0].message.content
        try:
            data = json.loads(raw)
        except Exception:
            recomendaciones_backup = [i["nombre"] for i in menu[:2]]
            data = {
                "mensaje": "Puedo mostrarte el men√∫ completo si deseas. ¬øQuieres que te comparta las opciones?",
                "recomendaciones": recomendaciones_backup,
                "intencion": "consulta_menu"
            }
        log_message('Finalizando funci√≥n <pedido_incompleto_dynamic>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <pedido_incompleto_dynamic>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <pedido_incompleto_dynamic>: {e}")
        recomendaciones_backup = [i["nombre"] for i in menu[:2]] if menu else []
        return {
            "mensaje": "Si quieres, puedo mostrarte el men√∫ para que elijas mejor.",
            "recomendaciones": recomendaciones_backup,
            "intencion": "consulta_menu"
        }
    
def actualizar_pedido_con_mensaje(
        pedido_actual: Any,
        mensaje_usuario: str,
        menu_items: List[Dict],
        mensaje_chatbot_previo: str = "",
        mensaje_usuario_previo: str = "",
        model: str = "gpt-5.1"
        ) -> Dict:
    """
    Funci√≥n robusta para actualizar pedidos con l√≥gica de fallback y limpieza.
    """
    try:
        log_message('Iniciando funci√≥n <actualizar_pedido_con_mensaje>.', 'INFO')
        logging.info("Iniciando actualizar_pedido_con_mensaje.")
        pedido_actual = _safe_parse_order(pedido_actual)
        text_for_replace_check = " ".join([str(mensaje_usuario or ""), str(mensaje_chatbot_previo or ""), str(mensaje_usuario_previo or "")]).lower()
        replace_all = any(phrase in text_for_replace_check for phrase in REPLACE_PHRASES)
        pedido_actual_limpio = {
            **pedido_actual,
            "items": [
                it for it in (pedido_actual.get("items") or [])
                if it and it.get("status") != "not_found"
            ]
        }
        pedido_para_modelo = {
            **pedido_actual_limpio,
            "items": [] if replace_all else pedido_actual_limpio.get("items", [])
        }
        prompt = f"""
        Eres un asistente experto actualizando pedidos de comida.
        TIENES QUE PROCESAR TODOS los productos que el cliente menciona.
        Devuelve un JSON solo con la estructura: {{ "order_complete": bool, "items":[...], "total_price": number }}
        === MENSAJE DEL USUARIO ===
        {mensaje_usuario}
        === PEDIDO ACTUAL LIMPIO ===
        {json.dumps(pedido_para_modelo, ensure_ascii=False)}
        === MEN√ö ===
        {json.dumps(menu_items, ensure_ascii=False)}
        LAS HAMBURGESAS SE LLAMAN:
            "Veggie Queso"
            "La Insaciable"
            "Sierra Bomba"
            "Sierra Mulata"
            "Sierra Pag√ºer"
            "Sierra Picante"
            "Sierra Coste√±a"
            "Sierra Melao"
            "Sierra Clasica"
            "Camino a la cima"
            "Sierra Queso"
        HAY PERROS CALIENTES LLAMADOS:
            "Super Perro"
            "Super Chanchita"
            "Perro Tocineta"
        CUANDO PIDAN UN ADICIONAL EN CUALQUIER PRODUCTO, SOLO PUEDE SER:
        	"Carne de res 120g"
            "Cebollas caramelizadas"
            "Cebollas caramelizadas picantes"
            "Pepinillos agridulces"
            "Pl√°tano maduro frito"
            "Suero coste√±o"
            "Chicharr√≥n"
            "Tocineta"
            "Queso coste√±o frito"
            "Queso cheddar"
        CUANDO PIDAN SALSAS, SOLO PUEDE SER:
            "Salsa de tomate"
            "Salsa mostaza"
            "Salsa bbq"
            "Salsa mayonesa"
        CUANDO PIDAN BEBIDAS, SOLO PUEDE SER:
            "Malteada de Vainilla"
            "Malteada de Mil0"
            "Malteada de Frutos Rojos"
            "Malteada de Chocolate y avellanas"
            "Malteada de Arequipe"
            "Malteada Oblea"
            "Malteada Galleta"
            "Fuze tea de manzana 400 ml"
            "Fuze tea de lim√≥n 400 ml"
            "Fuze tea de durazno 400 ml"
            "Kola Roman 400 ml"
            "Quatro 400 ml"
            "Sprite 400ml"
            "Coca Cola Sin Az√∫car 400 ml"
            "Coca Cola Original 400 ml"
            "Agua normal 600 ml"
            "Agua con gas 600ml"
            "Limonada de panela org√°nica 350Ml"
        CUANDO PIDAN ACOMPA√ëAMIENTOS, SOLO PUEDE SER:
            "Platanitos maduros"
            "Papas Coste√±as (francesas medianas + 4 deditos de queso coste√±o)"
            "Coste√±itos fritos + Suero Coste√±o"
            "Anillos de Cebolla"
            "Papas francesas"
        """
        client = OpenAI()
        response = client.responses.create(model=model, input=prompt, temperature=0)
        raw = ""
        try:
            raw = response.output[0].content[0].text.strip()
        except Exception:
            raw = ""
        clean = raw
        clean = re.sub(r'^```json', '', clean, flags=re.I).strip()
        clean = re.sub(r'^```', '', clean).strip()
        clean = re.sub(r'```$', '', clean).strip()
        parsed = None
        parse_debug = {"method": None, "raw_excerpt": clean[:1000]}
        try:
            parsed = json.loads(clean)
            parse_debug["method"] = "json.loads"
        except Exception:
            try:
                parsed = ast.literal_eval(clean)
                parse_debug["method"] = "ast.literal_eval"
            except Exception as e:
                try:
                    candidate = re.search(r'(\{.*\})', clean, flags=re.DOTALL)
                    if candidate:
                        parsed = json.loads(candidate.group(1))
                        parse_debug["method"] = "regex_json_extract"
                except Exception:
                    parsed = None
                    parse_debug["error"] = str(e)
        if not isinstance(parsed, dict):
            items_final = pedido_para_modelo.get("items", [])
            total_price = sum(_price_of_item(it) for it in items_final)
            order_complete = bool(items_final) and all(it.get("status") == "found" for it in items_final)
            return {
                "order_complete": order_complete,
                "items": items_final,
                "total_price": round(total_price, 2),
                "debug": {"parse_ok": False, "raw_model": raw, **parse_debug}
            }
        model_items = parsed.get("items") or []
        if not isinstance(model_items, list):
            model_items = []
        model_items = [it for it in model_items if it and it.get("status") != "not_found"]
        final_items = _merge_items(pedido_para_modelo.get("items", []), model_items, replace_all=replace_all)
        total_price = sum(_price_of_item(it) for it in final_items)
        total_price = round(total_price, 2)
        order_complete = bool(final_items) and all(it.get("status") == "found" for it in final_items)
        result = {
            "order_complete": order_complete,
            "items": final_items,
            "total_price": total_price
        }
        if parsed.get("debug") or parsed.get("warnings"):
            result["debug_from_model"] = parsed.get("debug") or parsed.get("warnings")
        logging.info("Finalizando actualizar_pedido_con_mensaje.")
        log_message('Finalizando funci√≥n <actualizar_pedido_con_mensaje>.', 'INFO')
        return result
    except Exception as e:
        logging.exception("Error en actualizar_pedido_con_mensaje")
        return {
            "order_complete": False,
            "items": [],
            "total_price": 0,
            "error": str(e)
        }

def generar_mensaje_confirmacion_pedido(
        pedido_json: dict,
        promocion: bool = False,
        promociones_info: list = None,
        pedido_completo_promocion: dict = None,
        model: str = "gpt-5.1",
    ) -> dict:
    """
    Genera un mensaje de confirmaci√≥n de pedido.
    - Si promocion=False ‚Üí usa el prompt normal con pedido_json.
    - Si promocion=True ‚Üí usa un prompt especial basado en promociones_info y pedido_completo_promocion.
    """

    raw = ""  # para debug si falla

    try:
        client = OpenAI()

        # ------------------------------------------------------------------
        # PROMPT NORMAL (sin promoci√≥n)
        # ------------------------------------------------------------------
        if not promocion:
            prompt = f"""
                Eres un asistente de WhatsApp de un restaurante llamado Sierra Nevada, La Cima del Sabor.
                TU NOMBRE ES PAKO.
                RECIBES un JSON de pedido ya completo y validado:
                {json.dumps(pedido_json, ensure_ascii=False)}

                TU MISI√ìN:
                1. Generar un MENSAJE amable y claro para el cliente preguntando por la confirmaci√≥n de lo que pidi√≥.
                - Lista cada producto.
                - Incluye sus modificadores ("sin cebolla", etc.).
                - Muestra precios individuales.
                - Muestra el total.
                - No inventes productos ni precios.

                2. Devuelve un JSON V√ÅLIDO:
                {{
                    "mensaje": "mensaje natural preguntando por la confirmaci√≥n del pedido",
                    "intencion_siguiente": "confirmar_pedido"
                }}

                REGLAS:
                - No incluyas texto fuera del JSON.
                - No uses emojis.
                - Mensaje corto, conversacional, profesional.
                - Tono c√°lido y cercano, estilo Sierra Nevada.
                - Debes cerrar preguntando si desea confirmar: "¬øDesea confirmar su pedido?" o "¬øEs correcto su pedido?".
            """

        # ------------------------------------------------------------------
        # PROMPT ESPECIAL (promoci√≥n=True) - CORREGIDO
        # ------------------------------------------------------------------
        else:
            if promociones_info is None or pedido_completo_promocion is None:
                raise ValueError("Cuando promocion es True, promociones_info y pedido_completo_promocion son obligatorios.")

            # Incluimos tanto el pedido original (pedido_json) como el pedido con la promoci√≥n aplicada (pedido_completo_promocion)
            # IMPORTANTE: escapamos las llaves del JSON de formato con {{ }} donde corresponde.
            prompt = f"""
                Eres PAKO, asistente oficial del restaurante Sierra Nevada.

                RECIBES:
                1) Pedido original detectado (fuente de todos los productos):
                {json.dumps(pedido_json, ensure_ascii=False)}

                2) Resultado del an√°lisis de promoci√≥n (si existe), con precios finales aplicados:
                {json.dumps(pedido_completo_promocion, ensure_ascii=False)}

                3) Listado de promociones vigentes:
                {json.dumps(promociones_info, ensure_ascii=False)}

                TU MISI√ìN (PROMOCI√ìN):
                - Explicar al cliente en lenguaje natural qu√© incluye la promoci√≥n identificada.
                - Mostrar claramente QU√â productos de su pedido entraron en la promoci√≥n y cu√°les NO.
                - Para cada producto del pedido (tanto promocionado como no):
                  * indicar nombre,
                  * precio original,
                  * precio final que pagar√° (despu√©s de la promoci√≥n),
                  * marcar si la promoci√≥n fue aplicada.
                - Indicar el precio especial TOTAL de la promoci√≥n y el TOTAL FINAL del pedido (suma de todos los final_price).
                - No inventes nada: usa SOLO la informaci√≥n en los JSON arriba (pedido_json, pedido_completo_promocion, promociones_info).

                FORMATO OBLIGATORIO (JSON sin texto adicional). Usa exactamente estas claves:
                {{
                    "mensaje": "Mensaje en lenguaje natural, breve y c√°lido, explicando la promoci√≥n y listando los productos promocionados y no promocionados. Finalizar con pregunta de confirmaci√≥n.",
                    "intencion_siguiente": "confirmar_pedido"
                }}

                REGLAS ESTIL√çSTICAS:
                - Mensaje corto (1-3 frases principales + listado corto).
                - Tono: c√°lido, profesional y cercano.
                - No uses emojis.
                - No incluyas la "f√≥rmula interna" de c√°lculo (ej. no explicar c√≥mo se dividi√≥ el precio); s√≠ debes mostrar los precios finales por producto.
                - Final obligatorio: pregunta si desea confirmar la promoci√≥n/pedido, por ejemplo: "¬øDesea confirmar esta promoci√≥n y proceder con el pedido?".
            """

        # Enviar al modelo
        response = client.responses.create(
            model=model,
            input=prompt,
            temperature=0
        )

        raw = response.output[0].content[0].text.strip()

        # Limpieza de bloques ```json
        clean = raw
        clean = re.sub(r'^```json', '', clean, flags=re.I).strip()
        clean = re.sub(r'^```', '', clean).strip()
        clean = re.sub(r'```$', '', clean).strip()

        log_message('Finalizando funci√≥n <generar_mensaje_confirmacion_pedido>.', 'INFO')
        return json.loads(clean)

    except Exception as e:
        log_message(f'Error en funci√≥n <generar_mensaje_confirmacion_pedido>: {e}', 'ERROR')
        return {
            "mensaje": "Hubo un error generando el mensaje de confirmaci√≥n.",
            "intencion_siguiente": "confirmar_pedido",
            "raw_output": raw
        }

def generar_mensaje_cancelacion(
        sender: str,
        codigo_unico: str,
        nombre_cliente: str,
        model: str = "gpt-5.1",
    ) -> dict:
    """
    Genera un JSON con el mensaje de confirmaci√≥n de pedido.
    Formato de salida:
    {
        "mensaje": "...",
        "siguiente_intencion": "confirmar_pedido"
    }
    """
    try:
        log_message('Iniciando funci√≥n <generar_mensaje_cancelacion>.', 'INFO')
        dict_registro_temp: dict = obtener_pedido_por_codigo(sender, codigo_unico)
        producto = dict_registro_temp.get("producto", "N/A")
        total_productos = dict_registro_temp.get("total_productos", "N/A")
        client = OpenAI()
        prompt = f"""
        Eres un asistente de WhatsApp de un restaurante llamado Sierra Nevada, La Cima del Sabor.
        TU NOMBRE ES PAKO.
        RECIBES esta informaci√≥n del pedido que el cliente hab√≠a enviado, pero que no se pudo confirmar porque estaba incompleto, confuso o mal estructurado:
        - Producto(s): {producto}
        - Total estimado de productos: {total_productos}
        - Nombre cliente: {nombre_cliente}
        TU MISI√ìN:
        1. Generar un MENSAJE claro y amable explic√°ndole al cliente que su pedido no se pudo confirmar porque algo estaba mal.
        2. Preguntar exactamente: **‚Äú¬øQu√© parte del pedido est√° mal?‚Äù**
        3. Pedirle que vuelva a escribir su pedido de forma completa y clara.
        4. Debes sonar c√°lido, cercano y respetuoso, estilo Sierra Nevada.
        5. No uses emojis.
        6. No inventes productos, no supongas nada, no des confirmaciones.
        7. Devuelve un JSON **v√°lido**:
        {{
        "mensaje": "mensaje natural pidiendo al cliente que explique qu√© est√° mal y escriba de nuevo su pedido",
        "siguiente_intencion": "corregir_pedido"
        }}
        REGLAS:
        - No incluyas texto fuera del JSON.
        - El mensaje debe ser corto, profesional y conversacional.
        - Incluye el c√≥digo √∫nico del pedido en el mensaje.
        - No inventes informaci√≥n adicional.
        """
        response = client.responses.create(
            model=model,
            input=prompt,
            temperature=0
        )
        raw = response.output[0].content[0].text.strip()
        clean = raw
        clean = re.sub(r'^```json', '', clean, flags=re.I).strip()
        clean = re.sub(r'^```', '', clean).strip()
        clean = re.sub(r'```$', '', clean).strip()
        log_message('Finalizando funci√≥n <generar_mensaje_cancelacion>.', 'INFO')
        return json.loads(clean)
    except Exception as e:
        log_message(f'Error en funci√≥n <generar_mensaje_cancelacion>: {e}', 'ERROR')
        return {
            "mensaje": "Hubo un error generando el mensaje de cancelaci√≥n.",
            "siguiente_intencion": "confirmar_pedido",
            "raw_output": raw
        }

def solicitar_medio_pago(nombre: str, codigo_unico: str, nombre_local: str, pedido_str: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <solicitar_medio_pago>.', 'INFO')
        PROMPT_MEDIOS_PAGO = """
        Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
        Te llamas PAKO.
        El cliente {nombre} ya confirm√≥ su pedido con el c√≥digo √∫nico: {codigo_unico}.
        Este es el pedido que hizo:
        "{pedido_str}"
        TAREA:
        - Haz un comentario alegre, sabroso y un poquito divertido sobre el pedido.
        - Estilo: c√°lido, entusiasta, como ‚Äú¬°Wow qu√© delicia eso!‚Äù, ‚ÄúEse pedido est√° brutal‚Äù, etc.
        - No uses sarcasmo, groser√≠as ni exageres demasiado.
        - M√°ximo 1 o 2 frases.
        - Despu√©s del comentario, p√≠dele que elija su medio de pago.
        - Menciona el local: {nombre_local}
        - Menciona siempre todos los medios de pago disponibles.
        Debes listar estas opciones de pago:
        - Efectivo
        - Transferencia (Nequi, Daviplata, Bre-B)
        - Tarjeta d√©bito
        - Tarjeta cr√©dito
        FORMATO DE RESPUESTA (OBLIGATORIO):
        {{
            "mensaje": "texto aqu√≠"
        }}
        Nada fuera del JSON.
        """
        client = OpenAI()
        prompt = PROMPT_MEDIOS_PAGO.format(
            nombre=nombre,
            codigo_unico=codigo_unico,
            nombre_local=nombre_local,
            pedido_str=pedido_str
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres el generador oficial de mensajes alegres y de pago para Sierra Nevada."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=150,
            temperature=0.95
        )
        raw = response.choices[0].message.content.strip()
        try:
            data = json.loads(raw)
        except:
            data = {
                "mensaje": f"¬°{nombre}, ese pedido est√° para antojar a cualquiera! ü§§ Tu orden ({codigo_unico}) en {nombre_local} qued√≥ tremenda. ¬øQu√© medio de pago prefieres: efectivo, transferencia (Nequi/Daviplata/Bre-B), tarjeta d√©bito o tarjeta cr√©dito?"
            }
        log_message('Finalizando funci√≥n <solicitar_medio_pago>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <solicitar_medio_pago>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <solicitar_medio_pago>: {e}")
        return {
            "mensaje": f"¬°{nombre}, tu pedido ({codigo_unico}) qued√≥ delicioso! ¬øQu√© medio de pago deseas usar?"
        }

def enviar_menu_digital(nombre: str, nombre_local: str, menu) -> dict:
    try:
        log_message('Iniciando funci√≥n <solicitar_medio_pago>.', 'INFO')
        PROMPT = f"""
        Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
        El cliente {nombre} pidi√≥ el men√∫ digital.
        Este es el men√∫ que tienes disponible:
        {json.dumps(menu, ensure_ascii=False)}
        TAREA:
        - Haz un comentario alegre, sabroso y un poquito divertido sobre el men√∫.
        - Estilo: c√°lido, entusiasta, como ‚ÄúListo para pedir", vamos a consentirnos hoy y as√≠.
        - No uses sarcasmo, groser√≠as ni exageres demasiado.
        - M√°ximo 1 o 2 frases.
        - Despu√©s del comentario, recomienda que el cliente haga su pedido y 2 opciones del menu (hamburguesas o malteadas).
        - Menciona el local: {nombre_local}
        FORMATO DE RESPUESTA (OBLIGATORIO):
        {{
            "mensaje": "texto aqu√≠"
        }}
        Nada fuera del JSON.
        """
        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres el generador oficial de mensajes alegres y de pago para Sierra Nevada."},
                {"role": "user", "content": PROMPT}
            ],
            max_tokens=250,
            temperature=0.95
        )
        raw = response.choices[0].message.content.strip()
        try:
            data = json.loads(raw)
        except:
            data = {
                "mensaje": f"¬°{nombre}, el men√∫ de {nombre_local} est√° para chuparse los dedos! ü§§ ¬øQu√© esperas para pedir una de nuestras deliciosas hamburguesas como 'La Insaciable' o una refrescante malteada de 'Chocolate y avellanas'?"
            }
        log_message('Finalizando funci√≥n <solicitar_medio_pago>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <solicitar_medio_pago>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <solicitar_medio_pago>: {e}")
        return {
            "mensaje": f"¬°{nombre}, ¬øqu√© esperas para pedir del delicioso men√∫ de {nombre_local}? ¬°An√≠mate y cu√©ntame qu√© se te antoja hoy!"
        }

def responder_sobre_pedido(nombre: str, nombre_local: str, pedido_info: dict, pregunta_usuario: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <ResponderSobrePedido>.', 'INFO')
        pedido_info_serializable = convert_decimals(pedido_info)
        pedido_info_serializable = {
            k: to_json_safe(v)
            for k, v in pedido_info.items()
        }
        PROMPT = f"""
        Eres PAKO, la voz oficial y amigable de {nombre_local}.
        Informaci√≥n del pedido:
        {json.dumps(pedido_info_serializable, ensure_ascii=False)}
        PREGUNTA:
        {pregunta_usuario}
        REGLAS IMPORTANTES:
        - La respuesta debe basarse SOLO en la informaci√≥n contenida en pedido_info.
        - Si el usuario pregunta por algo que NO est√° en pedido_info, responde amablemente
          que no tienes ese dato exacto y ofrece revisar men√∫ o promociones.
        - Estilo: c√°lido, alegre, amable, un poquito divertido, sin sarcasmo y sin exagerar.
        - M√°ximo 2 frases.
        - Siempre incluir un llamado a la acci√≥n al final para "consultar men√∫" o "consultar promociones".
          Debe ser natural, como:
          "Si quieres, puedo mostrarte el men√∫ o contarte las promociones".
        - No inventes datos adicionales.
        - No mencionar que eres una IA.
        - Respuesta SIEMPRE en JSON.
        OPCIONES PARA futura_intencion:
        - "consulta_menu"
        - "consulta_promociones"
        FORMATO DE RESPUESTA OBLIGATORIO:
        {{
          "mensaje": "texto aqu√≠",
          "futura_intencion": "consulta_menu o consulta_promociones"
        }}
        Nada por fuera del JSON.
        REGLA CR√çTICA:
        NO puedes asumir el estado del pedido. NO puedes decir que est√° listo, procesado, en preparaci√≥n, entregado ni nada similar.
        Solo puedes repetir literalmente lo que aparezca en el campo "estado" dentro de pedido_info.
        Si "estado" no est√° presente en pedido_info:
        - debes responder que no tienes el estado exacto del pedido.
        - y ofrecer consultar men√∫ o promociones.
        PROHIBIDO:
        - Decir que el pedido est√° "listo", "procesado", "en camino", "confirmado" o cualquier estado NO presente literalmente en el dict.
        - Interpretar o adivinar datos.
        - Inventar palabras relacionadas al estado.
        INFORMACI√ìN PERMITIDA:
        Solo puedes usar lo que aparece literalmente en este diccionario:
        {json.dumps(pedido_info_serializable, ensure_ascii=False)}
        Si algo no est√° all√≠, responde "No tengo ese dato exacto".
        """
        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"Eres PAKO, representante alegre de {nombre_local}."},
                {"role": "user", "content": PROMPT}
            ],
            max_tokens=200,
            temperature=0.8
        )
        raw = response.choices[0].message.content.strip()
        try:
            data = json.loads(raw)
        except:
            data = {
                "mensaje": f"{nombre}, aqu√≠ en {nombre_local} estoy para ayudarte con tu pedido. "
                           f"Si quieres, puedo mostrarte el men√∫ o contarte nuestras promociones.",
                "futura_intencion": "consulta_menu"
            }
        log_message('Finalizando funci√≥n <ResponderSobrePedido>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <ResponderSobrePedido>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <ResponderSobrePedido>: {e}")
        return {
            "mensaje": f"{nombre}, tuve un problema procesando tu solicitud, pero si quieres puedo mostrarte el men√∫ o las promociones.",
            "futura_intencion": "consulta_menu"
        }
    
def responder_sobre_promociones(nombre: str, nombre_local: str, promociones_info: list, pregunta_usuario: str) -> dict:
    """
    Similar a responder_sobre_pedido, pero ahora responde √∫nicamente
    sobre promociones y nada m√°s. Basado SOLO en promociones_info.
    """
    try:
        log_message('Iniciando funci√≥n <ResponderSobrePromociones>.', 'INFO')

        # Convertir valores a JSON-safe (Decimal, datetime, etc.)
        promociones_serializables = []
        for promo in promociones_info:
            limpio = {k: to_json_safe(v) for k, v in promo.items()}
            promociones_serializables.append(limpio)

        PROMPT = f"""
        Eres PAKO, la voz oficial, alegre y amigable de {nombre_local}.
        Estas son las promociones disponibles hoy:
        {json.dumps(promociones_serializables, ensure_ascii=False)}

        PREGUNTA DEL USUARIO:
        "{pregunta_usuario}"

        REGLAS IMPORTANTES:
        - SOLO puedes responder bas√°ndote en las promociones dentro del JSON mostrado arriba.
        - Si el usuario pregunta algo que NO est√° en las promociones (precio, disponibilidad, fechas, condiciones, etc.)
          debes responder: "No tengo ese dato exacto", y ofrecer consultar men√∫ o ver m√°s promociones.
        - Estilo: c√°lido, amable, alegre, un poquito divertido, sin sarcasmo y sin exagerar.
        - M√°ximo 2 frases.
        - Siempre incluir un llamado a la acci√≥n para "consultar men√∫" o "consultar promociones".
        - No inventes datos adicionales.
        - No menciones que eres una IA.
        - NO inventar promociones nuevas, solo usar las listadas.
        - Siempre haz un llamado a la acci√≥n al final para hacer pedido con base a las promociones listadas.

        OPCIONES v√°lidas para futura_intencion:
        - "continuacion_promocion"

        FORMATO DE RESPUESTA OBLIGATORIO:
        {{
          "mensaje": "texto aqu√≠",
          "futura_intencion": "continuacion_promocion"
        }}

        NING√öN TEXTO por fuera del JSON.
        """

        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-5.1",
            messages=[
                {"role": "system", "content": f"Eres PAKO, representante alegre y amigable de {nombre_local}, experto en promociones."},
                {"role": "user", "content": PROMPT}
            ],
#            max_completion_tokens=350,
            temperature=0.85
        )

        raw = response.choices[0].message.content.strip()

        try:
            data = json.loads(raw)
        except:
            data = {
                "mensaje": f"{nombre}, aqu√≠ en {nombre_local} tengo varias promociones buen√≠simas. "
                           f"Si quieres, puedo mostrarte m√°s o llevarte al men√∫.",
                "futura_intencion": "continuacion_promocion"
            }

        log_message('Finalizando funci√≥n <ResponderSobrePromociones>.', 'INFO')
        return data

    except Exception as e:
        log_message(f'Error en funci√≥n <ResponderSobrePromociones>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <ResponderSobrePromociones>: {e}")
        return {
            "mensaje": f"{nombre}, tuve un problema procesando las promociones, pero si quieres puedo mostrarte el men√∫ o las promos disponibles.",
            "futura_intencion": "continuacion_promocion"
        }


def interpretar_eleccion_promocion(pregunta_usuario: str, info_promociones_str: str, respuesta_previa_promocion: str, pedido_dict: dict) -> dict:
    """
    info_promociones_str: viene como STR desde intencion_futura ‚Üí lo convertimos a lista
    pedido_dict: contiene items, total_price, etc.
    """
    log_message('Iniciando funci√≥n <interpretar_eleccion_promocion>.', 'INFO')
    prompt = f"""
        Eres un sistema experto en an√°lisis de promociones.
        ### Productos del pedido:
        {pedido_dict}
        ### Promociones disponibles:
        {info_promociones_str}
        ### Mensaje previo del chatbot:
        "{respuesta_previa_promocion}"
        ### Mensaje actual del usuario:
        "{pregunta_usuario}"
        Tu tarea:
        1. Detecta qu√© productos del pedido califican para cada promoci√≥n.
        2. Eval√∫a TODAS las promociones y determina la(s) que realmente aplican.
        3. Calcula el total_final correspondiente a la mejor promoci√≥n (mayor beneficio).
        4. Devuelve SOLO la mejor promoci√≥n aplicable.
        5. Si NO aplica ninguna promoci√≥n, responde con:
        - valida_promocion = false
        - total_final = total_original
        - idpromocion = ""

        ### Importante:
        - No inventes promociones, usa SOLO las del input.
        - Usa los precios reales en pedido_dict['items'][i]['matched']['price'].
        - Solo una promoci√≥n final debe seleccionarse.

        ### Salida OBLIGATORIA (JSON PURO):

        {{
        "valida_promocion": true/false,
        "idpromocion": "",
        "total_final": 0,
        "nombre_promocion": "",
        "motivo": "Explicaci√≥n clara"
        }}
        """
    client = OpenAI()
    response = client.responses.create(
        model="gpt-5.1",
        input=prompt,
#        max_output_tokens=500,
        temperature=0
    )
    try:
        raw = response.output_text   # ‚Üê ESTE ES EL CORRECTO
        data = json.loads(raw)
    except Exception as e:
        log_message(f"Error en <interpretar_eleccion_promocion>: {e}", "ERROR")
        data = {
            "valida_promocion": False,
            "idpromocion": "",
            "total_final": pedido_dict.get("total_price", 0),
            "nombre_promocion": "",
            "motivo": "Error interpretando la IA"
        }
    log_message('Finalizando funci√≥n <interpretar_eleccion_promocion>.', 'INFO')
    return data

def pedido_incompleto_dynamic_promocion(mensaje_usuario: str, promociones_lst: str, json_pedido: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <pedido_incompleto_dynamic_promocion>.', 'INFO')

        PROMPT_PEDIDO_INCOMPLETO = """
        Eres la voz oficial de Sierra Nevada, La Cima del Sabor. Te llamas PAKO.

        El cliente escribi√≥: "{mensaje_usuario}"
        El gestor de pedidos detect√≥ que el pedido est√° INCOMPLETO o POCO CLARO:
        {json_pedido}

        Tu tarea:
        - Responder SOLO con un JSON v√°lido.
        - NO inventar productos. NO mencionar nada que NO est√© en el men√∫.

        Otras reglas:
        - Si el cliente pide algo que NO existe en el men√∫, ind√≠calo y sugiere 1 a 3 opciones reales.
        - Si pide algo muy general (ej: ‚Äúuna hamburguesa‚Äù), sugiere opciones espec√≠ficas del men√∫.
        - SIEMPRE pedir que el cliente vuelva a escribir todo su pedido claramente,
          excepto cuando est√© mezclando cosas fuera de la promoci√≥n (ver regla nueva).

        Responde SOLO este formato exacto:
        {{
            "mensaje": "texto aqu√≠",
            "recomendaciones": ["op1", "op2"],
            "intencion": "consulta_menu"
        }}

        Reglas estrictas:
        - No inventes productos.
        - Usa √öNICAMENTE nombres EXACTOS del men√∫.

        Aqu√≠ est√° las promociones disponibles:
        {promociones_str}

        LAS HAMBURGESAS SE LLAMAN:
            "Veggie Queso"
            "La Insaciable"
            "Sierra Bomba"
            "Sierra Mulata"
            "Sierra Pag√ºer"
            "Sierra Picante"
            "Sierra Coste√±a"
            "Sierra Melao"
            "Sierra Clasica"
            "Camino a la cima"
            "Sierra Queso"

        HAY PERROS CALIENTES LLAMADOS:
            "Super Perro"
            "Super Chanchita"
            "Perro Tocineta"

        CUANDO PIDAN UN ADICIONAL EN CUALQUIER PRODUCTO, SOLO PUEDE SER:
            "Carne de res 120g"
            "Cebollas caramelizadas"
            "Cebollas caramelizadas picantes"
            "Pepinillos agridulces"
            "Pl√°tano maduro frito"
            "Suero coste√±o"
            "Chicharr√≥n"
            "Tocineta"
            "Queso coste√±o frito"
            "Queso cheddar"

        CUANDO PIDAN SALSAS, SOLO PUEDE SER:
            "Salsa de tomate"
            "Salsa mostaza"
            "Salsa bbq"
            "Salsa mayonesa"

        CUANDO PIDAN BEBIDAS, SOLO PUEDE SER:
            "Malteada de Vainilla"
            "Malteada de Mil0"
            "Malteada de Frutos Rojos"
            "Malteada de Chocolate y avellanas"
            "Malteada de Arequipe"
            "Malteada Oblea"
            "Malteada Galleta"
            "Fuze tea de manzana 400 ml"
            "Fuze tea de lim√≥n 400 ml"
            "Fuze tea de durazno 400 ml"
            "Kola Roman 400 ml"
            "Quatro 400 ml"
            "Sprite 400ml"
            "Coca Cola Sin Az√∫car 400 ml"
            "Coca Cola Original 400 ml"
            "Agua normal 600 ml"
            "Agua con gas 600ml"
            "Limonada de panela org√°nica 350Ml"

        CUANDO PIDAN ACOMPA√ëAMIENTOS, SOLO PUEDE SER:
            "Platanitos maduros"
            "Papas Coste√±as (francesas medianas + 4 deditos de queso coste√±o)"
            "Coste√±itos fritos + Suero Coste√±o"
            "Anillos de Cebolla"
            "Papas francesas"
        si el pedido es general, no espec√≠fico, sugiere opciones del men√∫. siempre con un call 2 action.
        """
        promociones_str = str(promociones_lst)
        prompt = PROMPT_PEDIDO_INCOMPLETO.format(
            mensaje_usuario=mensaje_usuario.lower(),
            promociones_str=promociones_str,
            json_pedido=json_pedido
        )
        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-5.1",
            messages=[
                {"role": "system", "content": "Eres PAKO, asistente oficial de Sierra Nevada."},
                {"role": "user", "content": prompt}
            ],
#            max_completion_tokens=200,
            temperature=0.8
        )
        raw = response.choices[0].message.content.strip()
        try:
            data = json.loads(raw)
        except Exception:
            data = {
                "mensaje": "Por favor elige solo los productos de la promoci√≥n o inicia un pedido desde cero escribiendo 'menu' u 'hola'.",
                "recomendaciones": [],
                "intencion": "consulta_menu"
            }
        log_message('Finalizando funci√≥n <pedido_incompleto_dynamic_promocion>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <pedido_incompleto_dynamic_promocion>: {e}', 'ERROR')
        return {
            "mensaje": "Por favor elige solo los productos de la promoci√≥n o inicia un pedido desde cero escribiendo 'menu' u 'hola'.",
            "recomendaciones": [],
            "intencion": "consulta_menu"
        }

def mapear_modo_pago(respuesta_usuario: str) -> str:
    try:
        """Mapea la respuesta del usuario al m√©todo de pago estandarizado."""
        log_message('Iniciando funci√≥n <mapear_modo_pago>.', 'INFO')
        client = OpenAI()
        PROMPT_MAPEO_PAGO = """
        Eres un clasificador experto en interpretar el m√©todo de pago que un cliente escribe en WhatsApp, incluso cuando lo escribe con errores, abreviaciones o de forma muy informal.

        Debes analizar el texto del usuario y responder exclusivamente uno de los siguientes valores:

        - "transferencia - nequi"
        - "transferencia - daviplata"
        - "transferencia - bre-b"
        - "transferencia - otro"
        - "efectivo"
        - "tarjeta"
        - "nfc"
        - "desconocido"

        Reglas:
        1. Aunque est√© mal escrito, identifica la intenci√≥n correcta.
        2. Si menciona:
        - nequi / neki / nekii / nequi bbva ‚Üí "transferencia - nequi"
        - daviplata / davi / dabiplya / daviplaya ‚Üí "transferencia - daviplata"
        - bre-b / breb ‚Üí "transferencia - bre-b"
        - ‚Äúmovil‚Äù, ‚Äútransfer‚Äù, ‚Äútransfe‚Äù, ‚Äúpse‚Äù, ‚Äúlo hago por el celu‚Äù, ‚Äúpaso por app‚Äù ‚Üí "transferencia - otro"
        3. tarjeta, tc, td, targta, tarjta, cr√©dito, d√©bito ‚Üí "tarjeta"
        4. nfc, acercar la tarjeta, contactless ‚Üí "nfc"
        5. efectivo, cash ‚Üí "efectivo"
        6. Si no puedes entenderlo ‚Üí "desconocido"

        Formato de salida OBLIGATORIO (JSON puro):
        {
            "metodo": "uno de los valores permitidos"
        }
        """
        if not respuesta_usuario:
            return "desconocido"

        prompt = PROMPT_MAPEO_PAGO + f'\n\nTexto del usuario: "{respuesta_usuario}"'
        response = client.responses.create(
            model="gpt-3.5-turbo",
            input=prompt,
            max_output_tokens=60,
            temperature=0
        )
        raw = response.output_text
        data = json.loads(raw)
        metodo = data.get("metodo", "desconocido")
        log_message('Finalizando funci√≥n <mapear_modo_pago>.', 'INFO')
        return metodo
    except Exception as e:
        log_message(f"Error mapeando m√©todo de pago: {e}", "ERROR")
        return "desconocido"

def solicitar_metodo_recogida(nombre: str, codigo_unico: str, nombre_local: str, pedido_str: str) -> dict:
    try:
        log_message('Iniciando funci√≥n <solicitar_metodo_recogida>.', 'INFO')
        PROMPT_METODOS_RECOGIDA = """
            Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
            Te llamas PAKO.
            El cliente {nombre} ya confirm√≥ su pedido con el c√≥digo √∫nico: {codigo_unico}.
            Este es el pedido que hizo:
            "{pedido_str}"

            TAREA:
            - Haz un comentario alegre, sabroso y un poquito divertido sobre el pedido.
            - Estilo: c√°lido, entusiasta, como ‚Äú¬°Wow qu√© delicia eso!‚Äù, ‚ÄúEse pedido est√° brutal!‚Äù, etc.
            - No uses sarcasmo, groser√≠as ni exageres demasiado.
            - M√°ximo 1 o 2 frases.

            Despu√©s del comentario:
            - Preg√∫ntale de forma amable y cercana d√≥nde quiere recibir su pedido.
            - Menciona el local: {nombre_local}.
            - Lista claramente las dos opciones de recogida que puede elegir:
                ‚Ä¢ Recoger en tienda:
                    Centro Mayor (Cc. Centro Mayor, local 3-019)
                    Galer√≠as (Calle 53 # 27-16)
                    Centro Internacional (Calle 32 # 07-10)
                    Chic√≥ 2.0 (Calle 100 # 9a - 45 local 7A)
                    Virrey (Carrera 15 # 88-67)
                ‚Ä¢ Env√≠o a domicilio (depende de la zona y tiene costo adicional).
            Haz que el cliente se sienta especial y bien atendido.
            Siempre envia el codigo unico del pedido en el mensaje.
            FORMATO DE RESPUESTA (OBLIGATORIO):
            {{
                "mensaje": "texto aqu√≠"
            }}
            Nada fuera del JSON.
        """
        client = OpenAI()
        prompt = PROMPT_METODOS_RECOGIDA.format(
            nombre=nombre,
            codigo_unico=codigo_unico,
            nombre_local=nombre_local,
            pedido_str=pedido_str
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres el generador oficial de mensajes alegres y de pago para Sierra Nevada."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=150,
            temperature=0.95
        )
        raw = response.choices[0].message.content.strip()
        try:
            data = json.loads(raw)
        except:
            data = {
                "mensaje": f"¬°{nombre}, ese pedido est√° para antojar a cualquiera! ü§§ Tu orden ({codigo_unico}) en {nombre_local} qued√≥ tremenda. ¬øVas a querer domicilio o prefieres recogerlo en el restaurante?"
            }
        log_message('Finalizando funci√≥n <solicitar_metodo_recogida>.', 'INFO')
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <solicitar_metodo_recogida>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <solicitar_metodo_recogida>: {e}")
        return {
            "mensaje": f"¬°{nombre}, tu pedido ({codigo_unico}) qued√≥ delicioso! ¬øVas a querer domicilio o prefieres recogerlo en el restaurante?"
        }
