# utils_chatgpt.py
# Last modified: 2025-21-12 Juan Agudelo

import re
from openai import OpenAI
import logging
from typing import Any,  Optional, Tuple, Dict
import os
import json
from utils import send_text_response, limpiar_respuesta_json, log_message, convert_decimals, to_json_safe,corregir_total_price_en_result
from utils_database import execute_query
from datetime import datetime, date

from utils_registration import validate_personal_data

def get_openai_key() -> str:
    try:
        """Obtiene la clave API de OpenAI desde variables de entorno."""
        logging.info('Obteniendo clave de OpenAI')
        api_key: Optional[str] = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("No se encontr√≥ la clave OPENAI_API_KEY en las variables de entorno.")
        logging.info('Clave de OpenAI obtenida')
        return api_key
    except Exception as e:
        log_message(f"Error al obtener la clave de OpenAI: {e}", 'ERROR')
        logging.error(f"Error al obtener la clave de OpenAI: {e}")
        raise
    
def get_classifier(msj: str, sender: str) -> Tuple[Optional[str], Optional[str], Dict[str, Any]]:
    try:
        """Clasifica un mensaje de WhatsApp usando un modelo fine-tuned de OpenAI."""
        logging.info('Clasificando mensaje')
        classification_prompt: str = """
            Eres un clasificador de mensajes para un asistente de WhatsApp de un restaurante.
            Tu tarea es identificar la **intenci√≥n (intent)**, el **tipo de mensaje (type)** y cualquier **entidad relevante (entities)**.

            Recibir√°s un JSON con un arreglo de mensajes que representan el historial de la conversaci√≥n.

            A continuaci√≥n tienes un ejemplo de c√≥mo debes estructurar las entidades cuando el usuario pide varios productos:

            TU REGLAS MAS IMPORTANTE ES CE√ëIRTE A ESTE PROMPT NUNCA DEBES SALIRTE DE EL ES UNA

            EJEMPLO DE ENTRADA:
            "me das una sierra picante con extra picante y una malteada de chocolate"

            EJEMPLO DE ENTRADA:

            { "rol": "usuario", "texto": "Buenas tardes" },
            { "rol": "asistente", "texto": "Aceptas tratamiento de datos..." },
            { "rol": "usuario", "texto": "Quiero una sierra picante con extra picante y una malteada de chocolate" }

            EJEMPLO DE SALIDA:
            {
            "intent": "solicitud_pedido",
            "type": "pedido",
            "entities": {
                "items": [
                {
                    "producto": "sierra picante",
                    "especificaciones": ["extra picante"]
                    "cantidad": 1
                },
                {
                    "producto": "malteada de chocolate",
                    "especificaciones": []
                    "cantidad": 1
                }
                ]
            }
            }
            Debes responder √∫nicamente en formato JSON v√°lido con la siguiente estructura:
            {
            "intent": "<una de las intenciones permitidas>",
            "type": "<tipo de mensaje>",
            "entities": { }
            }

            Lista de intenciones posibles:
            - confirmacion_general (puede ser en otros idiomas: yes, oui, ja, etc.)
            - consulta_menu ()
            - consulta_pedido
            - consulta_promociones
            - direccion (Cuando unicamente contiene una direccion o sobre modificaciones en direccion de envio)
            - negacion_general (puede ser en otros idiomas: no, non, nein, etc.)
            - preguntas_generales (estas categorias forman parte: formas de pago (Nequi, Daviplata, efectivo, tarjetas, etc.),si hacen domicilios o env√≠os, horarios de atenci√≥n, direcci√≥n o ubicaci√≥n del local,contacto, pedidos o reservas promociones o descuentos, preguntas sobre reservas-> son preguntas generales)
            - quejas (quejas de menor nivel)
            - sin_intencion (Si la pregunta es sobre temas generales, ajenos al restaurante (por ejemplo: Bogot√°, clima, pel√≠culas, tecnolog√≠a, etc.) ‚Üí "sin_intencion".)
            - solicitud_pedido (pedidos de comida o bebida) (por ejemplo no, ya se lo que quiero, una sierra picante y una limonada) o (quiero una malteada de frutos rojos y una sierra clasica) o (me gustaria una sierra clasica) (modificaciones a pedidos) (cambios a pedidos)(cuando cosas similares a estos pedidos clasificalas como solicitud pedido) (tambien cuando aclare un pedido como: no, son tantos productos o no, son 3 productos o no, es una malteada y una sierra queso)(cuando el cliente aclare cantidades o productos ya mencionados)
            Ejemplo: "quiero agregar una malteada de vainilla", "quiero que la hamburguesa no traiga lechuga", "cambia mi pedido por favor por...", "quitar la malteada", "tambi√©n quiero una gaseosa coca cola¬†original", "dame tambi√©n una malteada de chocolate", etc.
            - transferencia (quejas de mayor nivel)
            - validacion_pago (breb, nequi, daviplata, tarjeta, efectivo) (cuando el usuario envie sus datos de facturacion correo, documento y tipo de documento)
            - recoger_restaurante   (NUEVA intenci√≥n: cuando el usuario dice que pasar√° a recoger, ir√° al restaurante o lo recoge en tienda o en una de nuestras sedes: Caobos)
            - domicilio             (NUEVA intenci√≥n: cuando el usuario pide entrega a domicilio, "tr√°elo", "env√≠amelo", "a mi casa", etc.)
            - saludo (hola, buenos dias, buenas tardes, buenas noches, saludos, etc.)
            - despedida (adios, hasta luego, nos vemos, gracias, etc.) (cuando notes que se da la informacion final al usuario y agradece o se despide)
            - Tiempo_de_recogida (Cuando el usuario menciona en cuanto tiempo pasar√° por su pedido)

            Instrucciones importantes:
            - No incluyas texto fuera del JSON.
            - No uses comentarios, explicaciones o saltos de l√≠nea innecesarios.
            - Si no puedes determinar la intenci√≥n, usa "sin_intencion".
            - TE ACLARO QUE UN PRODUCTO EN COMBO SE TRATA DIFERENTE A UN PRODUCTO SOLO POR EJEMPLO UNA SIERRA QUESO ES DIFERENTE DE UNA SIERRA QUESO EN COMBO
            - SI TE DICEN UN PRODUCTO EN COMBO TRATALO COMO UN PRODUCTO DIFERENTE A SU HOMONIMO SOLO
            - Si el usuario menciona detalles adicionales que modifican un producto ya mencionado (por ejemplo ‚Äúque la bebida sea‚Ä¶‚Äù, ‚Äúsin tomate‚Äù, ‚Äúpero la salsa aparte‚Äù), debes agregar esas especificaciones al MISMO item.
            - No debes crear un nuevo item cuando la frase solo aclara o modifica el producto anterior.
            - SI EL CLIENTE TE PIDE UN PRODUCTO EN COMBO NUNCA DEBES A√ëADIR SU VERSI√ìN SOLO COMO PARTE DEL PEDIDO A MENOS QUE LO EXIJA EXPLICITAMENTE EL MENSAJE (POR EJEMPLO: "UNA SIERRA QUESO Y UNA SIERRA QUESO EN COMBO" SI DEBES A√ëADIR AMBOS PRODUCTOS AL PEDIDO EJEMPLO 2: "UNA SIERRA QUESO EN COMBO" NO DEBES A√ëADIR SIERRA QUESO SOLO)
            - Si el usuario indica una cantidad expl√≠cita (ej. "2", "4", "dos", "cuatro"), debes representarla usando el campo "cantidad" y no duplicar items iguales.
            - Las reservas las clasificas como preguntas generales y todo lo relacionado con reservas va en esa categor√≠a.
            - Si te preguntan que me recomiendas se refiere a preguntas generales, en general las recomendaciones relacionalas con el menu y preguntas generales.
            - Si el usuario solo dice "s√≠" o "no" sin contexto, clasif√≠calo como confirmaci√≥n_general o negaci√≥n_general respectivamente.
            - Si el usuario pide hablar con un asesor, persona, humano, gerente, administrador, supervisor, encargado, responsable, operador, agente, representante o similar, clasif√≠calo como transferencia.
            - Si el usuario pide ayuda o soporte, clasif√≠calo como transferencia.
            - Si hay informaci√≥n personal antes de clasificarlo revisa el contexto de los mensajes anteriores si es el correo el documento y el numero del documento es si o si validaci√≥n_pago
            - Si dentro del contexto ya existe un pedido y te estan pidiendo mas productos es una modificacion pedido y no una solicitud de pedido
            - Si la bebida es agua  se refiere a una Agua normal 600 ml
            - Si la bebida es agua con gas se refiere a una Agua con gas 600 ml
            - Las adiciones debes clasificarlas en el producto que se indica y tambien como un producto aparte a la vez
            - LAS ADICIONES SIEMPRE DEBES CLASIFICARLAS COMO UN PRODUCTO UNICO CON SU PRECIO Y SU CANTIDAD

            Reglas IMPORTANTES:
            - DEBES analizar y clasificar el √öLTIMO mensaje enviado por el USUARIO.
            - Todos los mensajes anteriores son SOLO CONTEXTO y NO deben usarse para inferir intenci√≥n.
            - Nunca clasifiques mensajes del asistente pero si es contexto importante para la decisi√≥n final.
            """

        messages = [
            {"role": "system", "content": classification_prompt},
            {"role": "user", "content": msj}
        ]
        client: OpenAI = OpenAI(api_key=get_openai_key())
        respuesta: Any = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=messages,
            max_tokens=700,
            temperature=0
        )
        tokens_used = _extract_total_tokens(respuesta)
        if tokens_used is not None:
            log_message(f"[OpenAI] get_classifier tokens_used={tokens_used}", "DEBUG")
        raw_response: str = respuesta.choices[0].message.content.strip()
        logging.info(f"[Clasificador RAW] {raw_response!r}")
        json_str: str = limpiar_respuesta_json(raw_response)
        result: Dict[str, Any] = json.loads(json_str)
        intent: Optional[str] = result.get("intent")
        type_: Optional[str] = result.get("type")
        entities: Dict[str, Any] = result.get("entities", {})
        if not intent or not type_:
            raise ValueError(f"Respuesta inv√°lida, faltan claves: {result}")
        logging.info(f"Respuesta del clasificador: {result}")
        logging.info(f"Intent: {intent}, Type: {type_}, Entities: {entities}")
        log_message(f'Respuesta del clasificador: {result}', 'INFO')
        return intent, type_, entities
    except Exception as e:
        log_message(f'Error al hacer uso de funci√≥n <GetClassifier>: {e}.', 'ERROR')
        logging.error(f"Error al clasificar el mensaje: {e}")
        send_text_response(sender, "Lo siento, hubo un error al procesar tu mensaje. ¬øPodr√≠as repetirlo?")
        return None, None, {}

def clasificar_pregunta_menu_chatgpt(pregunta_usuario: str, items, model: str = "gpt-4o") -> dict:
    """
    Clasifica si una pregunta del usuario est√° relacionada con el men√∫ o con servicios
    del negocio (hamburgueser√≠a) usando un modelo de lenguaje (ChatGPT).
    """

    client: OpenAI = OpenAI()

    prompt: str = f"""
    Eres un asistente que clasifica preguntas de clientes de una hamburgueser√≠a.

    Debes responder con un JSON EXACTO con la siguiente forma:
    {{
        "clasificacion": "relacionada" o "no_relacionada"
        "intencion": "informacion_menu" o "informacion_servicios" o "informacion_pedido"
    }}
    Intenciones:
    - informacion_menu: preguntas sobre comidas, bebidas, ingredientes, precios, opciones vegetarianas o cualquier cosa del men√∫.
    - informacion_servicios: preguntas sobre formas de pago, domicilios, horarios, ubicaci√≥n, contacto, promociones.
    - informacion_pedido: preguntas relacionadas con el estado, costo o seguimiento de un pedido.
    Instrucciones:
    - Si la pregunta se refiere a comidas, hamburguesas, bebidas, malteadas, ingredientes, precios,
      opciones vegetarianas o cualquier cosa del men√∫ ‚Üí "relacionada".
    - Tambi√©n clasifica como "relacionada" si el cliente pregunta sobre:
        ‚Ä¢ formas de pago (Nequi, Daviplata, efectivo, tarjetas, etc.)
        ‚Ä¢ si hacen domicilios o env√≠os
        ‚Ä¢ horarios de atenci√≥n
        ‚Ä¢ direcci√≥n o ubicaci√≥n del local
        ‚Ä¢ contacto, pedidos o reservas
        ‚Ä¢ promociones o descuentos
        ‚Ä¢ preguntas sobre productos (hamburguesas, malteadas, perros, gaseosas)
    - Si la pregunta es sobre temas generales, ajenos al restaurante (por ejemplo: Bogot√°, clima, pel√≠culas, tecnolog√≠a, etc.) ‚Üí "no_relacionada".
    - Responde SOLO con el JSON, sin explicaciones ni texto adicional.
    Ejemplos:
    1Ô∏è‚É£ "qu√© hamburguesas tienen?" ‚Üí {{"clasificacion": "relacionada"}}
    2Ô∏è‚É£ "hay hamburguesas de pollo?" ‚Üí {{"clasificacion": "relacionada"}}
    3Ô∏è‚É£ "qu√© malteadas tienen?" ‚Üí {{"clasificacion": "relacionada"}}
    4Ô∏è‚É£ "tienen opciones vegetarianas?" ‚Üí {{"clasificacion": "relacionada"}}
    5Ô∏è‚É£ "aceptan pagos por nequi?" ‚Üí {{"clasificacion": "relacionada"}}
    6Ô∏è‚É£ "hacen env√≠os a suba?" ‚Üí {{"clasificacion": "relacionada"}}
    7Ô∏è‚É£ "cu√°l es su horario?" ‚Üí {{"clasificacion": "relacionada"}}
    8Ô∏è‚É£ "d√≥nde est√°n ubicados?" ‚Üí {{"clasificacion": "relacionada"}}
    9Ô∏è‚É£ "d√≥nde queda Bogot√°?" ‚Üí {{"clasificacion": "no_relacionada"}}
    üîü "qu√© es Python?" ‚Üí {{"clasificacion": "no_relacionada"}}

    Este es el men√∫ completo si la pregunta incluye un producto del menu o se refiere a comidas o bebidas es relacionada:
    {json.dumps(items, ensure_ascii=False)}
    
    Ahora clasifica la siguiente pregunta del usuario:
    "{pregunta_usuario}"

    Devuelve SOLO el JSON, sin explicaci√≥n adicional.
    """

    try:
        response = client.responses.create(
            model=model,
            input=prompt,
            temperature=0
        )
        text_output = response.output[0].content[0].text.strip()
        # limpiar posibles fences/triple-backticks u otros prefijos
        try:
            text_output = _clean_model_output(text_output)
        except Exception:
            pass
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] clasificar_pregunta_menu_chatgpt tokens_used={tokens_used}", "DEBUG")
        # Extraer JSON dentro de fences ```json ... ``` o buscar primer objeto JSON
        clean = text_output or ""
        m = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", clean, flags=re.IGNORECASE)
        if m:
            clean = m.group(1).strip()
        else:
            clean = clean.strip()
        if not clean.startswith('{'):
            m2 = re.search(r"(\{[\s\S]*\})", clean)
            if m2:
                clean = m2.group(1)

        try:
            result = json.loads(clean)
            return result
        except json.JSONDecodeError:
            logging.error(f"Error al parsear JSON en clasificar_pregunta_menu_chatgpt: {clean!r}")
            log_message(f'Error al parsear JSON en <ClasificarPreguntaMenuChatGPT>: {clean}', 'ERROR')
            return {"clasificacion": "no_relacionada"}

    except json.JSONDecodeError:
        logging.error(f"Error al parsear JSON: {text_output}")
        log_message(f'Error al parsear JSON en <ClasificarPreguntaMenuChatGPT>: {text_output}', 'ERROR')
        return {"clasificacion": "no_relacionada"}
    except Exception as e:
        logging.error(f"Error en <ClasificarPreguntaMenuChatGPT>: {e}")
        log_message(f'Error en <ClasificarPreguntaMenuChatGPT>: {e}.', 'ERROR')
        return {"clasificacion": "no_relacionada"}

def _clean_model_output(raw: str) -> str:
    """
    Limpia output que pueda venir en triple-backticks o con '```json' al inicio.
    Devuelve el string JSON limpio (o el raw si no hab√≠a marcas).
    """
    if not raw:
        return ""
    s = raw.strip()

    # Si el modelo devolvi√≥ bloque con ```json ... ```
    if s.startswith("```"):
        # eliminar backticks al inicio y final
        s = s.strip("`").strip()
        # si a√∫n tiene prefijo 'json' eliminarlo
        if s.lower().startswith("json"):
            s = s[len("json"):].lstrip("\r\n ").strip()

    return s

def _extract_text_from_response(response) -> str:
    """
    Extrae texto del objeto devuelto por client.responses.create de forma robusta.
    Prioriza response.output_text, luego response.output[*].content[*].text, 
    luego intenta concatenar todo lo que encuentre.
    """
    # 1) output_text (forma simple)
    try:
        output_text = getattr(response, "output_text", None)
        if output_text:
            return str(output_text).strip()
    except Exception:
        pass

    # 2) response.output -> content
    try:
        if hasattr(response, "output") and response.output:
            parts = []
            for out in response.output:
                # cada out puede tener 'content' que es lista de dicts
                content = getattr(out, "content", None) or out.get("content", None) if isinstance(out, dict) else None
                if content:
                    for c in content:
                        # c puede ser dict con 'text' u 'type' y 'content'
                        if isinstance(c, dict):
                            if "text" in c and c["text"]:
                                parts.append(c["text"])
                            elif "type" in c and c["type"] == "output_text" and "text" in c:
                                parts.append(c["text"])
                            else:
                                # intentar stringify
                                parts.append(json.dumps(c, ensure_ascii=False))
                        else:
                            parts.append(str(c))
            if parts:
                return "\n".join(parts).strip()
    except Exception:
        pass

    # 3) fallback: str(response)
    try:
        return str(response).strip()
    except Exception:
        return ""

def responder_pregunta_menu_chatgpt(pregunta_usuario: str, items, model: str = "gpt-4o") -> dict:
    """
    Responde preguntas del usuario sobre el men√∫ o servicios del restaurante Sierra Nevada üçî.
    Incluye informaci√≥n sobre horarios, sedes y medios de pago.
    Devuelve: (result: dict, prompt: str)
    """

    # Prompt unificado
    prompt = f"""
        Eres PAKO, el asistente c√°lido y cercano de Sierra Nevada, La Cima del Sabor üèîÔ∏èüçî.
        Tu tarea es ayudar al cliente con informaci√≥n sobre el men√∫, horarios, sedes y servicios,
        siempre con el tono oficial de la marca: amable, natural y con un toque sabroso, sin exagerar.

        Informaci√≥n del restaurante:
        üïê Horario: Todos los d√≠as de 12:00 p.m. a 7:00 p.m.
        üìç Sedes:
        - Caobos Cl 147 #17- 95 local 55, Usaqu√©n, Bogot√°, Cundinamarca
        üí≥ Medios de pago: solo contraentrega efectivo y datafono.

        El cliente pregunt√≥: "{pregunta_usuario}"

        Este es el men√∫ completo:
        {json.dumps(items, ensure_ascii=False)}

        PAUTAS DE TONO (OBLIGATORIAS):
        - Habla como un buen anfitri√≥n bogotano: c√°lido, natural y claro.
        - Siempre cordial, sin sarcasmo, sin iron√≠a y sin jerga barrial.
        - Puedes usar m√°ximo 1 emoji suave si queda natural.
        - No inventes productos, ingredientes ni sedes.
        - S√© breve y humano, como si hablaras por WhatsApp.
        - Mant√©n un toque emocional o visual de sabor cuando sea apropiado.

        INSTRUCCIONES DE RESPUESTA:
        - Si la pregunta es sobre horarios, sedes, medios de pago o env√≠os, responde con la informaci√≥n dada.
        - Si el cliente pide algo que s√≠ aparece en el men√∫, descr√≠belo brevemente o conf√≠rmalo.
        - Si pide algo que NO est√° en el men√∫, ind√≠calo con amabilidad y sugiere m√°ximo 2 opciones similares.
        - Si pregunta por categor√≠as (picante, vegetariano, pollo, bebidas, postres, etc.), responde seg√∫n el men√∫.
        - Si pregunta por algo ambiguo, aclara con amabilidad.
        - Evita frases impersonales (ej. ‚Äúsu solicitud ha sido procesada‚Äù).
        - Evita exageraciones o tono juvenil extremo.
        - Mant√©n la respuesta en m√°ximo 2 frases si es posible.
        - En este momento no manejamos reservas
        - Si la pregunta es sobre costo de domicilio recuerdale que actualmente dentro del area de cobertura es gratis
        FORMATO OBLIGATORIO DE SALIDA:
        Devuelve SOLO un JSON v√°lido con esta estructura EXACTA:

        {{
            "respuesta": "texto amigable para el cliente",
            "recomendacion": true o false,
            "productos": ["nombre1", "nombre2"]
        }}

        Ejemplo:
        Usuario: "¬øTienen opciones picantes?"
        -> {{
            "respuesta": "Claro üëç Tenemos opciones con car√°cter como la Sierra Picante y la Sierra BBQ, ambas con un toque fuerte.",
            "recomendacion": false,
            "productos": ["Sierra Picante", "Sierra BBQ"]
        }}
        """
    try:
        client = OpenAI()
        response = client.responses.create(
            model=model,
            input=prompt
        )
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] responder_pregunta_menu_chatgpt tokens_used={tokens_used}", "DEBUG")
        raw_text = _extract_text_from_response(response)
        raw_text = _clean_model_output(raw_text)
        logging.info(f"[DEBUG] Texto crudo del modelo: {raw_text!r}")

        if not raw_text:
            raise ValueError("Respuesta vac√≠a del modelo")

        try:
            result = json.loads(raw_text)
        except json.JSONDecodeError:
            import re
            m = re.search(r"(\{[\s\S]*\})", raw_text)
            if m:
                result = json.loads(m.group(1))
            else:
                result = {"respuesta": raw_text, "recomendacion": False, "productos": []}

        if "productos" in result and isinstance(result["productos"], list):
            result["productos"] = [p.replace('\u00a0', ' ').strip() for p in result["productos"]]

        pregunta_lower = pregunta_usuario.lower()
        if any(token in pregunta_lower for token in ["?", "tienen", "hay", "venden", "cu√°les", "qu√© opciones", "me recomiendas", "qu√© hay"]):
            respuesta_txt = str(result.get("respuesta", "")).strip()
            if respuesta_txt and not respuesta_txt.endswith(("?", ".", "!", "üòã", "üòâ", "üòé")):
                result["respuesta"] = respuesta_txt + " ¬øQuieres probarla? üòã"

        result.setdefault("productos", [])
        result.setdefault("recomendacion", False)
        log_message(f"Respuesta generada: {result}", "INFO")
        return result

    except Exception as e:
        logging.error(f"Error en <ResponderPreguntaMenuChatGPT>: {e}")
        log_message(f'Error en <ResponderPreguntaMenuChatGPT>: {e}', 'ERROR')
        return {
            "respuesta": "Lo siento üòî, tuve un problema para responder tu pregunta.",
            "recomendacion": False,
            "productos": []
        }

def mapear_pedido_al_menu(contenido_clasificador: dict, menu_items: list, model: str = "gpt-5.1") -> dict:
    """
    Mapear los items provenientes del clasificador AL MEN√ö usando GPT.
    """
    client = OpenAI()

    prompt = f"""
        Eres un asistente encargado de interpretar mensajes de clientes para la toma y modificaci√≥n de pedidos de domicilios.
        Tu funci√≥n es:
        1) Clasificar la INTENCI√ìN del mensaje del usuario.
        2) Mapear los productos solicitados al MEN√ö estructurado.
        3) Identificar los productos afectados cuando el pedido es una modificaci√≥n.
        4) Devolver √öNICAMENTE un JSON v√°lido, sin ning√∫n texto adicional.

        ======================================================
        = ESTRUCTURA DE RESPUESTA (OBLIGATORIA) =
        ======================================================
        Debes responder √öNICA Y EXCLUSIVAMENTE con un JSON v√°lido con esta estructura exacta:

        {{
            "intent": "ADD_ITEM | REMOVE_ITEM | REPLACE_ITEM",
            "intent_confidence": number,
            "target_items": [
                {{
                    "producto": "...",
                    "especificaciones": [ ... ]
                }}
            ],
            "order_complete": true|false,
            "items": [
                {{
                    "requested": {{ "producto": "...", "especificaciones": [ ... ] }},
                    "status": "found" | "not_found" | "multiple_matches",
                    "matched": {{ "name": "...", "id": "...", "price": number }},
                    "candidates": [ {{ "name":"...", "id":"...", "price": number }}, ... ],
                    "modifiers_applied": [ ... ],
                    "cantidad": number,
                    "note": ""
                }}
            ]
        }}

        ======================================================
        = CLASIFICACI√ìN DE INTENCI√ìN =
        ======================================================
        ANTES de mapear los productos debes identificar la INTENCI√ìN del mensaje.
 
        INTENCIONES DISPONIBLES:
        - ADD_ITEM: el usuario agrega productos al pedido actual ejemplo (Agregar, a√±adir, poner, sumar, traer, pedir, incluir,Tambi√©n, adem√°s, extra, otro, otra, uno m√°s.).
        - REMOVE_ITEM: El usuario elimina un producto completo.
            REGLA CR√çTICA: Si el usuario dice "SIN [PRODUCTO]" (ej. sin las aguas, sin la soda), y ese producto existe de forma independiente en el men√∫, es REMOVE_ITEM.
            REGLA CR√çTICA 2: Si el usuario menciona un producto general en su mensaje puedes buscar el producto especifico en el contexto comparandolo con el menu por ejemplo el mensaje del agente puede mencionar a que producto se refiere el cliente.
        - UPDATE_ITEM: El usuario modifica un ingrediente o cantidad de un √≠tem que SE QUEDA en el pedido, si el usuario pide ajuste en el pedido (solo es una bebida) si los items siguen siendo los mismos luego de la modificacion es UPDATE_ITEM si pide solo x producto pero ya estaba en el pedido es UPDATE_ITEM.
            REGLA CR√çTICA: Si el usuario dice "SIN [INGREDIENTE]" (ej. sin salsas, sin cebolla), y el ingrediente NO es un producto vendible por s√≠ solo, es UPDATE_ITEM.
        - REPLACE_ITEM: el usuario quiere cambiar un peoducto por otro ejemplo(Cambiar, sustituir, reemplazar, permutar,X por Y", "en vez de X quiero Y", "mejor c√°mbiame...).
        - ACLARACION: el mensaje del usuario no permite identificar de forma clara una acci√≥n sobre el pedido, o es ambiguo con dos o mas iintenciones en el pedido, incompleto o confuso.
 
        REGLAS ABSOLUTAS:
        - Si la intenci√≥n es REMOVE_ITEM, el campo "note" dentro del array "items" DEBE contener exactamente el string "delete"
        - Es OBLIGATORIO usar REMOVE_ITEM cuando el usuario cancela un producto principal usando la palabra "todas", "sin", "ya no", o "quita".
        - Ejemplo: "Sin las aguas" -> intent: REMOVE_ITEM, note: "delete"
        - Si el mensaje contiene palabras de ajuste como "mejor", "solo", "en vez de", o especificaciones de ingredientes ("sin salsas", "con queso"), la intenci√≥n debe ser UPDATE_ITEM o REPLACE_ITEM, nunca ADD_ITEM.
        - Solo puede existir UNA intenci√≥n por mensaje.
        - Si la intenci√≥n NO es NEW_ORDER, debes identificar los productos afectados en target_items.
        - intent_confidence debe ser un valor entre 0 y 1 seg√∫n claridad del mensaje.
        - Si la intenci√≥n detectada es REPLACE_ITEM, debes asignar obligatoriamente el campo note de la siguiente manera:
            -Para el producto que ingresa al pedido, establece el valor exacto: "Producto de reemplazo".
            -Para el producto que sale del pedido, establece el valor exacto: "Producto a reemplazar".
            -Esta regla es estricta y debe cumplirse siempre que la intenci√≥n sea REPLACE_ITEM, sin excepciones.
        - Nunca clasificar como REPLACE_ITEM si no existen dos productos claramente identificables en el mensaje en cambio clasificalo como ACLARACION.
        - Cuando el cliente pide "platanitos" "platanos" o "pl√°tanos" se refiere a los platanitos maduros el ACOMPA√ëAMIENTO DE 7900 a menos que explicitamente mencione sea la adicion en ese caso son los platanos maduros de 2900 el adicional
        
        ======================================================
        = COMPORTAMIENTO GLOBAL DEL MODELO =
        ======================================================
        Debes identificar los productos del men√∫ incluso cuando est√©n:
        - mal escritos, abreviados, rotos en s√≠labas, fusionados,
        - con espacios de m√°s o de menos,
        - escritos fon√©ticamente,
        - mezclados con palabras irrelevantes,
        - con diminutivos, coloquialismos o apodos.

        Debes reconocer CUALQUIER producto del men√∫ mediante:
        - normalizaci√≥n,
        - sinonimia,
        - fuzzy matching,
        - similitud sem√°ntica,
        - heur√≠sticas inteligentes.

        ======================================================
        = NORMALIZACI√ìN EXTREMA =
        ======================================================
        Antes de buscar coincidencias debes:
        - pasar todo a min√∫sculas,
        - quitar acentos,
        - corregir repeticiones,
        - eliminar palabras vac√≠as (‚Äúquiero‚Äù, ‚Äúdame‚Äù, ‚Äúporfa‚Äù, etc.),
        - corregir deformaciones fon√©ticas conocidas,
        - convertir n√∫meros a posibles tama√±os,
        - eliminar texto irrelevante.

        ======================================================
        = SINONIMIA SEM√ÅNTICA =
        ======================================================
        Asume que los clientes pueden usar:
        - partes del nombre,
        - apodos informales,
        - equivalencias de categor√≠a,
        - nombres fon√©ticos o deformados.

        ======================================================
        = TOLERANCIA TOTAL A ERRORES =
        ======================================================
        Un producto es match v√°lido si:
        - la similitud sem√°ntica es razonable,
        - comparte palabras clave,
        - suena similar fon√©ticamente,
        - fuzzy match aceptable.

        ======================================================
        = PRIORIDAD DE MATCHING =
        ======================================================
        A) Exacta ‚Üí FOUND  
        B) Alias ‚Üí FOUND  
        C) Parcial fuerte ‚Üí FOUND  
        D) Sem√°ntica ‚Üí FOUND  
        E) Fuzzy √∫nico ‚Üí FOUND  
        F) 2+ ‚Üí MULTIPLE_MATCHES  
        G) 0 ‚Üí NOT_FOUND (m√°x. 3 sugerencias)

        ======================================================
        = REGLAS FINALES ABSOLUTAS =
        ======================================================
        - Usa EXACTAMENTE el nombre del men√∫ en matched.name.
        - Si alg√∫n √≠tem es NOT_FOUND ‚Üí order_complete = false.
        - Si todos son FOUND ‚Üí order_complete = true.
        - matched.price SIEMPRE es el precio UNITARIO.
        - NO multipliques matched.price por cantidad.
        - total_price es el √öNICO lugar donde se multiplica por cantidad.
        - La cantidad NO modifica matched.price.
        - La respuesta debe ser SOLO el JSON.
        - Las adiciones deben ser mapeadas como un modificador del pedido respectivo y como un producto aparte para la suma del precio
        - Cuando el usuario mencione combos, recuerdale que no manejamos combos actualmente pero podemos armarlo a su gusto con los acompa√±amientos y bebidas del menu
        ======================================================
        Tono de la conversacion:
        -Directo,formal,cercano y amable
        MEN√ö COMPLETO:
        {json.dumps(menu_items, ensure_ascii=False)}

        CLASIFICADOR:
        {json.dumps(contenido_clasificador, ensure_ascii=False)}

        DEVUELVE SOLO EL JSON.
        """

    try:
        log_message(f'Prompt generado en <MapearPedidoAlMenu>: {prompt}', 'DEBUG')
        response = client.responses.create(
            model=model,
            input=prompt,
 #           max_completion_tokens = 500,
            temperature=0
        )

        text_output = response.output[0].content[0].text.strip()
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] mapear_pedido tokens_used={tokens_used}", "DEBUG")
        log_message(f'Output crudo de modelo en <MapearPedidoAlMenu>: {text_output}', 'DEBUG')
        ##### Validacion costo
    
        clean = text_output.strip()
        clean = re.sub(r'^```json', '', clean, flags=re.IGNORECASE).strip()
        clean = re.sub(r'^```', '', clean).strip()
        clean = re.sub(r'^json', '', clean, flags=re.IGNORECASE).strip()
        clean = re.sub(r'```$', '', clean).strip()

        result = json.loads(clean)

        log_message(f'Resultado parseado en <MapearPedidoAlMenu>: {result}', 'DEBUG')
        result = corregir_total_price_en_result(result)
        return result

    except json.JSONDecodeError:
        logging.error("Error al parsear JSON desde el modelo.")
        logging.error(text_output if 'text_output' in locals() else 'no output')
        log_message(f'Error al parsear JSON en <MapearPedidoAlMenu>: {text_output}', 'ERROR')

        return {
            "order_complete": False,
            "items": [],
            "total_price": 0,
            "error": "parse_error",
            "raw_output": text_output if 'text_output' in locals() else None
        }

    except Exception as e:
        logging.exception("Error llamando al API")
        log_message(f'Error en <MapearPedidoAlMenu>: {e}', 'ERROR')

        return {
            "order_complete": False,
            "items": [],
            "total_price": 0,
            "error": str(e)
        }

def saludo_dynamic(mensaje_usuario: str, nombre: str, nombre_local: str) -> dict:
    try:


        PROMPT_SALUDO_DYNAMIC = """
Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
Tu tarea es generar un saludo personalizado seg√∫n el tono que use el cliente.

El cliente escribi√≥: "{mensaje_usuario}"

PAUTAS DE TONO:
1. Si el cliente usa expresiones informales como:
"q hubo", "quiubo", "k hubo", "que m√°s", "que mas", "q mas",
"hey", "holi", "epa", "epaaa", "hoola", "hola parce",
entonces:
    - Usa un tono cercano, relajado y natural, sin jerga excesiva.
    - Puedes usar 1 emoji suave si fluye bien.
    - Mant√©n calidez y sensaci√≥n de bienvenida al estilo Sierra Nevada.

2. Si el cliente usa expresiones formales como:
"buenas tardes", "buenos d√≠as", "buen dia",
"cordial saludo", "mucho gusto", "estimados",
entonces:
    - Usa un tono respetuoso, profesional y sereno.
    - No uses emojis.
    - Mant√©n claridad, amabilidad y un toque c√°lido sin exagerar.

3. En cualquier otro caso:
    - Usa un tono cordial est√°ndar: amable, natural y con sabor.
    - Puedes usar un emoji suave si queda org√°nico.

= MENSAJE INICIAL PREVENTIVO =

- La recomendaci√≥n debe ser un RECORDATORIO de comportamiento.
- Usa verbos como: "recuerda", "ten en cuenta", "procura", "trata de".
- NO lo formules como una pregunta.
- El objetivo es que el cliente cuando conteste lo haga en un unico mensaje
IMPORTANTE:
- La recomendaci√≥n debe ser ATEMPORAL, no ligada al siguiente mensaje.
- NO hagas referencia a "ahora", "en este mensaje", "al responder".
- Debe entenderse como una regla general para toda la conversaci√≥n.
- Evita frases como:
  "para ayudarte m√°s r√°pido",
  "cuando me respondas",
  "en tu siguiente mensaje".

REGLAS DE ESTILO SIERRA NEVADA:
- Habla como un buen anfitri√≥n: c√°lido, claro y con energ√≠a positiva.
- Evita expresiones barriales, sarcasmo o exageraciones.
- Mant√©n un lenguaje cotidiano y respetuoso.
- No inventes productos ni detalles.
- Incluye siempre el nombre del cliente: {nombre}
- Incluye siempre el nombre del local: {nombre_local}
- Responde en m√°ximo 1 o 2 frases.
- Escoge UNA intenci√≥n entre:
    - "consulta_menu"
    - "consulta_promociones"

TIPS PARA UNA MEJOR EXPERIENCIA (OBLIGATORIO INCLUIRLOS EN EL JSON):
Incluye SIEMPRE un campo "tips" con una lista de 3 a 5 tips breves.
Los tips deben sonar amables, √∫tiles y positivos.
Ejemplos:
- S√© claro y espec√≠fico con lo que necesitas.
- Env√≠a un mensaje a la vez.
- Sigue los pasos que te indique el bot.
- Espera mi respuesta antes de enviar otro mensaje.
- Esto ayuda a procesar tu pedido sin errores.

FORMATO:
Debes responder en un JSON v√°lido:
{{
    "mensaje": "texto aqu√≠",
    "intencion": "consulta_menu",
    "tips": ["tip1", "tip2", "tip3"]
}}
No incluyas texto adicional fuera del JSON.
"""

        client = OpenAI()
        prompt = PROMPT_SALUDO_DYNAMIC.format(
            nombre=nombre,
            nombre_local=nombre_local,
            mensaje_usuario=mensaje_usuario.lower()
        )
        
        response = client.chat.completions.create(
            model="gpt-5.1",
            messages=[
                {"role": "system", "content": "Eres un generador de saludos que adapta su tono al del cliente."},
                {"role": "user", "content": prompt}
            ],
#            max_tokens=350,
            temperature=0.85
        )

        raw = response.choices[0].message.content.strip()
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] saludo_dynamic tokens_used={tokens_used}", "DEBUG")
        try:
            data = json.loads(raw)
        except:  # noqa: E722
            # fallback con tips incluidos
            data = {
                "mensaje": f"¬°Hola {nombre}! Bienvenido a {nombre_local}. ¬øTe muestro el men√∫ o las promociones?",
                "intencion": "consulta_menu",
                "tips": [
                    "Escribe mensajes claros y espec√≠ficos",
                    "Env√≠a un mensaje a la vez",
                    "Sigue los pasos que te comparta el bot",
                    "Espera mi respuesta antes de enviar otro mensaje",
                ]
            }

        return data

    except Exception as e:
        log_message(f'Error en funci√≥n <saludo_dynamic>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <saludo_dynamic>: {e}")
        return {
            "mensaje": f"¬°Hola {nombre}! Bienvenido a {nombre_local}. ¬øQuieres ver el men√∫?",
            "intencion": "consulta_menu",
            "tips": [
                "Escribe mensajes claros y espec√≠ficos",
                "Env√≠a un mensaje a la vez",
                "Sigue los pasos que te comparta el bot",
                "Espera mi respuesta antes de enviar otro mensaje",
            ]
        }
    
def respuesta_quejas_ia(mensaje_usuario: str, nombre: str, nombre_local: str) -> dict:
    try:
        PROMPT_QUEJA_LEVE = """
            Eres el asistente oficial de servicio al cliente de Sierra Nevada, La Cima del Sabor.

            Tu tarea es responder una queja leve con el tono y personalidad de la marca:
            - C√°lido, cercano y respetuoso.
            - Natural, humano, sin excesos.
            - Con un toque de sabor y buena energ√≠a, sin sonar exagerado.
            - Orgullosamente colombiano, pero sin clich√©s.
            - Hablas como un buen anfitri√≥n bogotano: amable, claro y sin jerga popular.
            El cliente llamado {nombre} escribi√≥ lo siguiente: "{mensaje_usuario}"
            OBJETIVO:
            - Tranquilizar al cliente.
            - Validar su experiencia sin culpas ni defensividad.
            - Incluir SIEMPRE una acci√≥n concreta para mostrar que est√°s atendiendo el caso 
            (por ejemplo: ‚Äúle cuento al equipo‚Äù, ‚Äúreviso con cocina‚Äù, ‚Äúlo paso al encargado del punto‚Äù).
            - Mostrar disposici√≥n a ayudar SIN escalar el caso a un agente humano.
            - Mantener un tono amable y con toque emocional de Sierra Nevada.
            - Usar m√°ximo 1 emoji suave si fluye de manera natural.
            - Responder en m√°ximo 2 frases.

            REGLAS DE TONO:
            - No uses sarcasmo, iron√≠as ni expresiones barriales.
            - No suenes rob√≥tico ni impersonal.
            - No inventes informaci√≥n.
            - Mant√©n una sensaci√≥n de servicio, calidez y sabor.
            - Evita anglicismos y tecnicismos.
            - Puedes mencionar solo: equipo, servicio, experiencia, tiempo de entrega, sabor, atenci√≥n.

            CONTENIDO:
            Debes generar:
            1. "respuesta_cordial": un mensaje amable y emp√°tico que tranquilice al cliente, 
            incluyendo una acci√≥n concreta como ‚Äúreviso con cocina‚Äù, ‚Äúle cuento al equipo del punto‚Äù 
            o ‚Äúdejo la nota para mejorar tu pr√≥xima experiencia‚Äù.
            2. "resumen_queja": una frase corta que resuma la queja sin inventar detalles.
            3. "intencion": siempre "queja_leve".

            FORMATO DE RESPUESTA:
            La respuesta DEBE ser un JSON v√°lido:
            {
                "respuesta_cordial": "texto aqu√≠",
                "resumen_queja": "texto aqu√≠",
                "intencion": "queja_leve"
            }
            Genera solo el JSON sin texto adicional.
            """
        client = OpenAI()
        prompt = PROMPT_QUEJA_LEVE.format(
            mensaje_usuario=mensaje_usuario,
            nombre=nombre
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "Eres un generador de respuestas amables para quejas leves de clientes."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=180,
            temperature=0.6
        )
        raw = response.choices[0].message.content.strip()
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] respuesta_quejas tokens_used={tokens_used}", "DEBUG")
        try:
            data = json.loads(raw)
        except:  # noqa: E722
            data = {
                "respuesta_cordial": f"{nombre}, gracias por escribirnos. Lamentamos que tu experiencia en {nombre_local} no haya sido perfecta; estamos aqu√≠ para ayudarte üòä",
                "resumen_queja": "Queja leve del cliente sobre su experiencia.",
                "intencion": "quejas"
            }
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <respuesta_quejas>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <respuesta_quejas>: {e}")
        return {
            "respuesta_cordial": f"{nombre}, gracias por avisarnos. Estamos atentos para que tu experiencia en {nombre_local} sea mejor cada vez.",
            "resumen_queja": "Queja leve del cliente.",
            "intencion": "quejas"
        }

def respuesta_quejas_graves_ia(mensaje_usuario: str, nombre: str, nombre_local: str) -> dict:
    try:
        PROMPT_QUEJA_GRAVE = """
            Eres el asistente oficial de servicio al cliente de Sierra Nevada, La Cima del Sabor.
            Esta vez atender√°s *quejas graves*, donde puede que el pedido NO haya llegado,
            haya habido un error fuerte, mala manipulaci√≥n o tiempo excesivo.
            ***OBJETIVO GENERAL***
            - Calmar al cliente.
            - Asumir responsabilidad sin culpas excesivas.
            - Dar una ACCI√ìN clara y concreta que el asistente realizar√°.
            - Preparar un resumen ejecutivo para un administrador humano.
            - NO escalar directamente en el mensaje al cliente (solo en el resumen interno).
            - M√°ximo 2 frases, tono c√°lido, humano, cercano, estilo Sierra Nevada, colombiano neutro.
            - La respuesta_cordial DEBE incluir expl√≠citamente la frase:
            "Ya escal√© el caso con un administrador y se comunicar√° contigo muy pronto."
            - Si la frase no aparece, la respuesta es inv√°lida.
            ***DEBES ENTREGAR ESTOS CAMPOS***
            1. "respuesta_cordial": Mensaje calmado, emp√°tico y con acci√≥n concreta 
            (ej: ‚Äúreviso ya mismo con cocina y log√≠stica‚Äù, ‚Äúactivo seguimiento con el punto‚Äù).
            2. "resumen_queja": Descripci√≥n breve de lo que reclama el cliente.
            3. "accion_recomendada": Acci√≥n clara que el sistema/administrador debe hacer 
            (ej: verificar estado del pedido, contactar punto, revisar domiciliario).
            4. "resumen_ejecutivo": Resumen para administrador (breve, objetivo, sin adornos).
            5. "intencion": Siempre "queja_grave".
            ***TONO***
            - C√°lido y responsable.
            - Sin tecnicismos ni sarcasmo.
            - Evita respuestas rob√≥ticas.
            - M√°ximo un emoji, si fluye natural.

            Cliente llamado {nombre} escribi√≥:
            "{mensaje_usuario}"
            ***FORMATO OBLIGATORIO***
            Devuelve SOLO un JSON v√°lido:
            {{
                "respuesta_cordial": "",
                "resumen_queja": "",
                "accion_recomendada": "",
                "resumen_ejecutivo": "",
                "intencion": "queja_grave"
            }}
        """
        client = OpenAI()
        prompt = PROMPT_QUEJA_GRAVE.format(
            mensaje_usuario=mensaje_usuario,
            nombre=nombre
        )
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un generador de respuestas para quejas graves de clientes."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=220,
            temperature=0.6
        )
        raw = response.choices[0].message.content.strip()
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] respuesta_quejas_graves_ia tokens_used={tokens_used}", "DEBUG")
        try:
            data = json.loads(raw)
        except:  # noqa: E722
            data = {
                "respuesta_cordial": f"{nombre}, ya reviso lo ocurrido con tu experiencia en {nombre_local} y activo el seguimiento de inmediato.",
                "resumen_queja": "Queja grave del cliente sobre servicio o pedido.",
                "accion_recomendada": "Revisi√≥n urgente con el punto y estado del pedido.",
                "resumen_ejecutivo": "Cliente reporta una queja grave; requiere revisi√≥n del punto y log√≠stica.",
                "intencion": "queja_grave"
            }
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <respuesta_quejas_graves_ia>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <respuesta_quejas_graves_ia>: {e}")
        return {
            "respuesta_cordial": f"{nombre}, reviso de inmediato lo que pas√≥ con tu experiencia en {nombre_local}.",
            "resumen_queja": "Queja grave del cliente.",
            "accion_recomendada": "Verificar con el punto y log√≠stica.",
            "resumen_ejecutivo": "Error en el proceso autom√°tico, requiere revisi√≥n manual.",
            "intencion": "queja_grave"
        }

def pedido_incompleto_dynamic(mensaje_usuario: str, menu: list, json_pedido: str) -> dict:
    try:
        menu_str = "\n".join([f"- {item['nombre']}" for item in menu])
        PROMPT_PEDIDO_INCOMPLETO = """
            Eres la voz oficial de Sierra Nevada, La Cima del Sabor. Te llamas PAKO.
            El cliente escribi√≥: "{mensaje_usuario}"
            El gestor de pedidos detect√≥ que el pedido est√° INCOMPLETO o POCO CLARO:
            {json_pedido}
            Tu tarea:
            - Responder SOLO con un JSON v√°lido.
            - NO inventar productos. NO mencionar nada que NO est√© en el men√∫.
            - Si el cliente pide algo que NO existe en el men√∫ (ej: "lasa√±a", "lasagna"), debes:
                * Indicar amablemente que ese producto no est√° disponible.
                * Sugerir 1 a 3 opciones REALES y relacionadas del men√∫.
            - Si el cliente pide algo MUY GENERAL (ej: "una hamburguesa", "una bebida"), debes:
                * Dar 1 a 3 recomendaciones REALES del men√∫ que s√≠ coincidan.
            - Pedir que el cliente aclare el producto que falta
            -Si el cliente pide algo v√°lido pero con nombre aproximado
                * Acepta coincidencias parciales SOLO si es OBVIO que se refiere a un producto real.
                * Nunca adivines si hay m√°s de una opci√≥n posible.
            Responde SOLO en este formato exacto:
            {{
                "mensaje": "texto aqu√≠",
                "recomendaciones": ["Opci√≥n 1", "Opci√≥n 2"],
                "intencion": "consulta_menu"
            }}
            Reglas estrictas:
            - No inventes productos. Usa √öNICAMENTE nombres EXACTOS del men√∫.
            - Si el cliente menciona algo NO presente en el men√∫, dilo expl√≠citamente.
            - No respondas como asistente conversacional. Solo JSON.
            - No agregues explicaciones fuera del JSON.
            Aqu√≠ est√° el men√∫ disponible:
            {menu_str}
            
        TEN EN CUENTA PUEDES USAR COINCIDENCIAS PARCIALES SOLO SI ES UNA VARIANTE CLARA PERO NO INVENTAR NI REEMPLAZAR SABORES.    
            """
        
        log_message(f'Prompt generado en <pedido_incompleto_dynamic>: {PROMPT_PEDIDO_INCOMPLETO}', 'DEBUG')
        prompt = PROMPT_PEDIDO_INCOMPLETO.format(
            mensaje_usuario=mensaje_usuario.lower(),
            menu_str=menu_str,
            json_pedido=json_pedido
        )
        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-5.1",
            messages=[
                {"role": "system", "content": "Eres un asistente que ayuda al cliente a consultar el men√∫ y elegir su pedido."},
                {"role": "user", "content": prompt}
            ],
#este modelo no limita los tokens            max_tokens=450,
            temperature=0.2
        )
        raw = response.choices[0].message.content
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] pedido_incompleto_dynamic tokens_used={tokens_used}", "DEBUG")
        try:
            data = json.loads(raw)
        except Exception:
            recomendaciones_backup = [i["nombre"] for i in menu[:2]]
            data = {
                "mensaje": "Puedo mostrarte el men√∫ completo si deseas. ¬øQuieres que te comparta las opciones?",
                "recomendaciones": recomendaciones_backup,
                "intencion": "consulta_menu"
            }
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <pedido_incompleto_dynamic>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <pedido_incompleto_dynamic>: {e}")
        recomendaciones_backup = [i["nombre"] for i in menu[:2]] if menu else []
        return {
            "mensaje": "Si quieres, puedo mostrarte el men√∫ para que elijas mejor.",
            "recomendaciones": recomendaciones_backup,
            "intencion": "consulta_menu"
        }

def solicitar_medio_pago(nombre: str, codigo_unico: str, nombre_local: str, pedido_str: str,sender: str) -> dict:
    try:

#         PROMPT_MEDIOS_PAGO = f"""
# Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
# Te llamas PAKO.

# El cliente {nombre} ya confirm√≥ su pedido con el c√≥digo √∫nico: {codigo_unico}.
# Este es el pedido que hizo:
# "{pedido_str}"

# TAREA:
# - Haz un comentario alegre y sabroso sobre el pedido.
# - Estilo: c√°lido, entusiasta.
# - 1 o 2 frases m√°ximo.
# - Luego p√≠dele elegir medio de pago.
# - Menciona el local: {nombre_local}
# - Lista opciones disponibles:
#   * Efectivo
#   * Tarjeta d√©bito
#   * Tarjeta cr√©dito

# Debe responder estrictamente un JSON con el campo:
# {{
#    "mensaje": "texto aqu√≠"
# }}
# """
        if not validate_personal_data(sender,os.environ.get("ID_RESTAURANTE", "5")):
            PROMPT_MEDIOS_PAGO = f"""
Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
Tu nombre es PAKO.

El cliente {nombre} ya confirm√≥ su pedido con el c√≥digo √∫nico: {codigo_unico}.
Pedido realizado:
"{pedido_str}"

OBJETIVO:
Generar un √öNICO mensaje breve, c√°lido y entusiasta.

INSTRUCCIONES OBLIGATORIAS:
- Haz un comentario alegre y sabroso sobre el pedido.
- Pide al cliente que elija un m√©todo de pago.
- Menciona √∫nicamente estas opciones de pago:
  * Efectivo
  * Dat√°fono
- Solicita los datos personales listados abajo.
- La solicitud de datos DEBE tener EXACTAMENTE esta estructura y este orden,
  sin agregar texto intermedio ni variaciones:

-Metodo de pago
-Documento
-Tipo de documento
-Correo electronico

FORMATO DE RESPUESTA:
- Responde √öNICA Y EXCLUSIVAMENTE con un JSON v√°lido.
- No agregues texto antes ni despu√©s del JSON.

Estructura final:
{{
  "mensaje": "texto aqu√≠"
}}
"""
        else:
            PROMPT_MEDIOS_PAGO = f"""            
Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
Tu nombre es PAKO.

El cliente {nombre} ya confirm√≥ su pedido con el c√≥digo √∫nico: {codigo_unico}.
Pedido realizado:
"{pedido_str}"

OBJETIVO:
Generar un √öNICO mensaje breve, c√°lido y entusiasta.

INSTRUCCIONES OBLIGATORIAS:
- Haz un comentario alegre y sabroso sobre el pedido.
- Pide al cliente que elija un m√©todo de pago.
- Menciona √∫nicamente estas opciones de pago:
  * Efectivo
  * Dat√°fono

FORMATO DE RESPUESTA:
- Responde √öNICA Y EXCLUSIVAMENTE con un JSON v√°lido.
- No agregues texto antes ni despu√©s del JSON.

Estructura final:
{{
  "mensaje": "texto aqu√≠"
}}
"""
        client = OpenAI()

        response = client.chat.completions.create(
            model="gpt-4o-mini",   # O gpt-4o / gpt-5 / gpt-5.1
            messages=[
                {"role": "system", "content": "Eres PAKO y respondes siempre en JSON limpio."},
                {"role": "user", "content": PROMPT_MEDIOS_PAGO}
            ]
        )
    
        raw_text = response.choices[0].message.content
        log_message(f"Respuesta cruda:{raw_text}","INFO")
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] solicitar_medio_pago tokens_used={tokens_used}", "DEBUG")
        try:
            # Limpieza de escapes innecesarios que pueden romper el JSON
            clean_text = raw_text.replace('\\$', '$')
            data = json.loads(clean_text)
        except json.JSONDecodeError:
            # Fallback si GPT no devuelve JSON v√°lido
            data = {
                "mensaje": f"¬°{nombre}, ese pedido est√° para antojar a cualquiera! ü§§ Tu orden ({codigo_unico}) en {nombre_local} qued√≥ tremenda. ¬øQu√© medio de pago prefieres: efectivo o datafono ambos son contraentrega"
            }

        return data

    except Exception as e:
        log_message(f'Error en funci√≥n <solicitar_medio_pago>: {e}', 'ERROR')
        return {
            "mensaje": f"¬°{nombre}, ese pedido est√° para antojar a cualquiera! ü§§ Tu orden ({codigo_unico}) en {nombre_local} qued√≥ tremenda. ¬øQu√© medio de pago prefieres: efectivo, transferencia (Nequi/Daviplata/Bre-B), tarjeta d√©bito o tarjeta cr√©dito?"
        }

def enviar_menu_digital(nombre: str, nombre_local: str, menu, promociones_list: list | None) -> dict:
    try:
        if promociones_list:
            hoy = date.today()
            promociones_con_vigencia = []
            for p in promociones_list:
                try:
                    fecha_fin_raw = p.get("fecha_fin")
                    if isinstance(fecha_fin_raw, str):
                        fecha_fin = datetime.fromisoformat(fecha_fin_raw).date()
                    elif isinstance(fecha_fin_raw, datetime):
                        fecha_fin = fecha_fin_raw.date()
                    else:
                        fecha_fin = fecha_fin_raw  # por si ya es date
                    dias_restantes = (fecha_fin - hoy).days
                    if dias_restantes == 0:
                        vence_texto = "La promo vence **hoy**."
                    elif dias_restantes == 1:
                        vence_texto = "La promo vence **ma√±ana**."
                    elif dias_restantes > 1:
                        vence_texto = f"Vence en {dias_restantes} d√≠as."
                    else:
                        vence_texto = "La promo ya no est√° vigente."
                    p_mod = p.copy()
                    p_mod["vence_en"] = dias_restantes
                    p_mod["vence_texto"] = vence_texto
                    promociones_con_vigencia.append(p_mod)
                except Exception:
                    p_mod = p.copy()
                    p_mod["vence_texto"] = "No se pudo calcular la vigencia."
                    promociones_con_vigencia.append(p_mod)
            promociones_json = json.dumps(promociones_con_vigencia, ensure_ascii=False)
            PROMPT = f"""
            Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
            El cliente {nombre} pidi√≥ ver las promociones activas.

            Estas son las promociones disponibles (JSON):
            {promociones_json}

            Cada promoci√≥n incluye un campo "vence_texto" que indica si la promo termina hoy, ma√±ana o en cu√°ntos d√≠as.

            TAREA:
            - Haz un mensaje alegre, sabroso y persuasivo resaltando las promociones.
            - En el mensaje, menciona la urgencia seg√∫n "vence_texto".
            - Recomienda 1 o 2 promociones espec√≠ficas.
            - Estilo: c√°lido, entusiasta, sin sarcasmo ni groser√≠as.
            - M√°ximo 1 o 2 frases.
            - No saludes, el usuario esta en medio de una conversaci√≥n

            FORMATO DE RESPUESTA (OBLIGATORIO):
            {{
                "mensaje": "texto aqu√≠"
            }}
            Nada fuera del JSON.
            """
        else:
            menu_json = json.dumps(menu, ensure_ascii=False)
            PROMPT = f"""
            Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
            El cliente {nombre} pidi√≥ el men√∫ digital.

            Este es el men√∫ disponible:
            {menu_json}

            TAREA:
            - Haz un comentario alegre y sabroso.
            - Recomienda 2 opciones del men√∫.
            - Estilo c√°lido y entusiasta.
            - M√°ximo 1 o 2 frases.
            - Menciona el local: {nombre_local}
            - No saludes, el usuario esta en medio de una conversaci√≥n

            FORMATO DE RESPUESTA (OBLIGATORIO):
            {{
                "mensaje": "texto aqu√≠"
            }}
            Nada fuera del JSON.
            """
        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "Eres el generador oficial de mensajes alegres y de pago para Sierra Nevada."},
                {"role": "user", "content": PROMPT}
            ],
            max_tokens=250,
            temperature=0.95
        )
        raw = response.choices[0].message.content.strip()
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] enviar_menu_digital tokens_used={tokens_used}", "DEBUG")
        try:
            data = json.loads(raw)
        except Exception:
            data = {
                "mensaje": f"¬°{nombre}, tenemos promociones activas en {nombre_local}! üòã ¬°Aprovecha y pide ya!"
            }

        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <enviar_menu_digital>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <enviar_menu_digital>: {e}")
        return {
            "mensaje": f"¬°{nombre}, ¬øqu√© esperas para pedir en {nombre_local}? ¬°Cu√©ntame qu√© se te antoja hoy!"
        }

def responder_sobre_pedido(nombre: str, nombre_local: str, pedido_info: tuple, pregunta_usuario: str) -> dict:
    try:
        pedido_info_serializable = convert_decimals(pedido_info)
        pedido_info_serializable = {
            k: to_json_safe(v)
            for k, v in pedido_info.items()
        }
        PROMPT = f"""
        Eres PAKO, la voz oficial y amigable de {nombre_local}.
        Informaci√≥n del pedido:
        {json.dumps(pedido_info_serializable, ensure_ascii=False)}
        PREGUNTA:
        {pregunta_usuario}
        REGLAS IMPORTANTES:
        - La respuesta debe basarse SOLO en la informaci√≥n contenida en pedido_info.
        - Si el usuario pregunta por algo que NO est√° en pedido_info, responde amablemente
          que no tienes ese dato exacto y ofrece revisar men√∫ o promociones.
        - Estilo: c√°lido, alegre, amable, un poquito divertido, sin sarcasmo y sin exagerar.
        - M√°ximo 2 frases.
        - Siempre incluir un llamado a la acci√≥n al final para "consultar men√∫" o "consultar promociones".
          Debe ser natural, como:
          "Si quieres, puedo mostrarte el men√∫ o contarte las promociones".
        - No inventes datos adicionales.
        - No mencionar que eres una IA.
        - Respuesta SIEMPRE en JSON.
        OPCIONES PARA futura_intencion:
        - "consulta_menu"
        - "consulta_promociones"
        FORMATO DE RESPUESTA OBLIGATORIO:
        {{
          "mensaje": "texto aqu√≠",
          "futura_intencion": "consulta_menu o consulta_promociones"
        }}
        Nada por fuera del JSON.
        REGLA CR√çTICA:
        NO puedes asumir el estado del pedido. NO puedes decir que est√° listo, procesado, en preparaci√≥n, entregado ni nada similar.
        Solo puedes repetir literalmente lo que aparezca en el campo "estado" dentro de pedido_info.
        Si "estado" no est√° presente en pedido_info:
        - debes responder que no tienes el estado exacto del pedido.
        - y ofrecer consultar men√∫ o promociones.
        PROHIBIDO:
        - Decir que el pedido est√° "listo", "procesado", "en camino", "confirmado" o cualquier estado NO presente literalmente en el dict.
        - Interpretar o adivinar datos.
        - Inventar palabras relacionadas al estado.
        """
        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"Eres PAKO, representante alegre de {nombre_local}."},
                {"role": "user", "content": PROMPT}
            ],
            max_tokens=200,
            temperature=0.8
        )
        raw = response.choices[0].message.content.strip()
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] responder_sobre_pedido tokens_used={tokens_used}", "DEBUG")
        try:
            log_message(f'Respuesta cruda de GPT en <ResponderSobrePedido>: {raw}', 'DEBUG')
            data = json.loads(raw)
        except:  # noqa: E722
            data = {
                "mensaje": f"{nombre}, aqu√≠ en {nombre_local} estoy para ayudarte con tu pedido. "
                           f"Si quieres, puedo mostrarte el men√∫ o contarte nuestras promociones.",
                "futura_intencion": "consulta_menu"
            }
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <ResponderSobrePedido>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <ResponderSobrePedido>: {e}")
        return {
            "mensaje": f"{nombre}, tuve un problema procesando tu solicitud, pero si quieres puedo mostrarte el men√∫ o las promociones.",
            "futura_intencion": "consulta_menu"
        }
    
def responder_sobre_promociones(nombre: str, nombre_local: str, promociones_info: list, pregunta_usuario: str) -> dict:
    """
    Similar a responder_sobre_pedido, pero ahora responde √∫nicamente
    sobre promociones y nada m√°s. Basado SOLO en promociones_info.
    """
    try:

        # Convertir valores a JSON-safe (Decimal, datetime, etc.)
        promociones_serializables = []
        for promo in promociones_info:
            limpio = {k: to_json_safe(v) for k, v in promo.items()}
            promociones_serializables.append(limpio)

        PROMPT = f"""
        Eres PAKO, la voz oficial, alegre y amigable de {nombre_local}.
        Estas son las promociones disponibles hoy:
        {json.dumps(promociones_serializables, ensure_ascii=False)}

        PREGUNTA DEL USUARIO:
        "{pregunta_usuario}"

        REGLAS IMPORTANTES:
        - SOLO puedes responder bas√°ndote en las promociones dentro del JSON mostrado arriba.
        - Si el usuario pregunta algo que NO est√° en las promociones (precio, disponibilidad, fechas, condiciones, etc.)
          debes responder: "No tengo ese dato exacto", y ofrecer consultar men√∫ o ver m√°s promociones.
        - Estilo: c√°lido, amable, alegre, un poquito divertido, sin sarcasmo y sin exagerar.
        - M√°ximo 2 frases.
        - Siempre incluir un llamado a la acci√≥n para "consultar men√∫" o "consultar promociones".
        - No inventes datos adicionales.
        - No menciones que eres una IA.
        - NO inventar promociones nuevas, solo usar las listadas.
        - Siempre haz un llamado a la acci√≥n al final para hacer pedido con base a las promociones listadas.

        OPCIONES v√°lidas para futura_intencion:
        - "continuacion_promocion"

        FORMATO DE RESPUESTA OBLIGATORIO:
        {{
          "mensaje": "texto aqu√≠",
          "futura_intencion": "continuacion_promocion"
        }}

        NING√öN TEXTO por fuera del JSON.
        """

        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-5.1",
            messages=[
                {"role": "system", "content": f"Eres PAKO, representante alegre y amigable de {nombre_local}, experto en promociones."},
                {"role": "user", "content": PROMPT}
            ],
#            max_completion_tokens=350,
            temperature=0.85
        )

        raw = response.choices[0].message.content.strip()
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] responder_sobre_promociones tokens_used={tokens_used}", "DEBUG")
        try:
            data = json.loads(raw)
        except:  # noqa: E722
            data = {
                "mensaje": f"{nombre}, aqu√≠ en {nombre_local} tengo varias promociones buen√≠simas. "
                           f"Si quieres, puedo mostrarte m√°s o llevarte al men√∫.",
                "futura_intencion": "continuacion_promocion"
            }

        return data

    except Exception as e:
        log_message(f'Error en funci√≥n <ResponderSobrePromociones>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <ResponderSobrePromociones>: {e}")
        return {
            "mensaje": f"{nombre}, tuve un problema procesando las promociones, pero si quieres puedo mostrarte el men√∫ o las promos disponibles.",
            "futura_intencion": "continuacion_promocion"
        }

def interpretar_eleccion_promocion(pregunta_usuario: str, info_promociones_str: str, respuesta_previa_promocion: str, pedido_dict: dict) -> dict:
    """
    info_promociones_str: viene como STR desde intencion_futura ‚Üí lo convertimos a lista
    pedido_dict: contiene items, total_price, etc.
    """
    prompt = f"""
        Eres un sistema experto en an√°lisis de promociones.
        ### Productos del pedido:
        {pedido_dict}
        ### Promociones disponibles:
        {info_promociones_str}
        ### Mensaje previo del chatbot:
        "{respuesta_previa_promocion}"
        ### Mensaje actual del usuario:
        "{pregunta_usuario}"
        Tu tarea:
        1. Detecta qu√© productos del pedido califican para cada promoci√≥n.
        2. Eval√∫a TODAS las promociones y determina la(s) que realmente aplican.
        3. Calcula el total_final correspondiente a la mejor promoci√≥n (mayor beneficio).
        4. Devuelve SOLO la mejor promoci√≥n aplicable.
        5. Si NO aplica ninguna promoci√≥n, responde con:
        - valida_promocion = false
        - total_final = total_original
        - idpromocion = ""

        ### Importante:
        - No inventes promociones, usa SOLO las del input.
        - Usa los precios reales en pedido_dict['items'][i]['matched']['price'].
        - Solo una promoci√≥n final debe seleccionarse.

        ### Salida OBLIGATORIA (JSON PURO):

        {{
        "valida_promocion": true/false,
        "idpromocion": "",
        "total_final": 0,
        "nombre_promocion": "",
        "motivo": "Explicaci√≥n clara"
        }}
        """
    client = OpenAI()
    response = client.responses.create(
        model="gpt-5.1",
        input=prompt,
#        max_output_tokens=500,
        temperature=0
    )
    try:
        raw = response.output_text   # ‚Üê ESTE ES EL CORRECTO
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] interpretar_eleccion_promocion tokens_used={tokens_used}", "DEBUG")
        data = json.loads(raw)
    except Exception as e:
        log_message(f"Error en <interpretar_eleccion_promocion>: {e}", "ERROR")
        data = {
            "valida_promocion": False,
            "idpromocion": "",
            "total_final": pedido_dict.get("total_price", 0),
            "nombre_promocion": "",
            "motivo": "Error interpretando la IA"
        }
    return data

def pedido_incompleto_dynamic_promocion(mensaje_usuario: str, promociones_lst: str, json_pedido: str) -> dict:
    try:

        PROMPT_PEDIDO_INCOMPLETO = """
        Eres la voz oficial de Sierra Nevada, La Cima del Sabor. Te llamas PAKO.

        El cliente escribi√≥: "{mensaje_usuario}"
        El gestor de pedidos detect√≥ que el pedido est√° INCOMPLETO o POCO CLARO:
        {json_pedido}

        Tu tarea:
        - Responder SOLO con un JSON v√°lido.
        - NO inventar productos. NO mencionar nada que NO est√© en el men√∫.

        Otras reglas:
        - Si el cliente pide algo que NO existe en el men√∫, ind√≠calo y sugiere 1 a 3 opciones reales.
        - Si pide algo muy general (ej: ‚Äúuna hamburguesa‚Äù), sugiere opciones del men√∫.
        - SIEMPRE pedir que el cliente vuelva a escribir todo su pedido claramente,
          excepto cuando est√© mezclando cosas fuera de la promoci√≥n (ver regla nueva).

        Responde SOLO este formato exacto:
        {{
            "mensaje": "texto aqu√≠",
            "recomendaciones": ["op1", "op2"],
            "intencion": "consulta_menu"
        }}

        Reglas estrictas:
        - No inventes productos.
        - Usa coincidencia aproximada para entender la intenci√≥n del cliente,pero la respuesta final debe ser EXACTA del men√∫.

        Aqu√≠ est√° las promociones disponibles:
        {promociones_str}

        LAS HAMBURGESAS SE LLAMAN:
            "Sierra Veggie"
            "LInsaciable"
            "Sierra Bomba"
            "Sierra Coste√±a"
            "Sierra Melao"
            "Sierra Clasica"
            "Camino a la cima"
            "Sierra Queso"

        CUANDO PIDAN UN ADICIONAL EN CUALQUIER PRODUCTO, Usa coincidencia aproximada para entender la intenci√≥n.
        PERO la respuesta final siempre debe ser una salsa EXACTA del men√∫:
            "Carne de res 120g"
            "Cebollas caramelizadas"
            "Cebollas caramelizadas picantes"
            "Pepinillos agridulces"
            "Pl√°tano maduro frito"
            "Suero coste√±o"
            "Chicharr√≥n"
            "Tocineta"
            "Queso coste√±o frito"
            "Queso cheddar"

        CUANDO PIDAN SALSAS, Usa coincidencia aproximada para entender la intenci√≥n.
        PERO la respuesta final siempre debe ser una salsa EXACTA del men√∫.:
            "Salsa de tomate"
            "Salsa mostaza"
            "Salsa bbq"
            "Salsa mayonesa"

        CUANDO PIDAN BEBIDAS, Usa coincidencia aproximada para entender la intenci√≥n.
        PERO la respuesta final siempre debe ser una bebida EXACTA del men√∫.:
            "Fuze tea de manzana 400 ml"
            "Fuze tea de lim√≥n 400 ml"
            "Fuze tea de durazno 400 ml"
            "Kola Roman 400 ml"
            "Quatro 400 ml"
            "Sprite 400ml"
            "Coca Cola Sin Az√∫car 400 ml"
            "Coca Cola Original 400 ml"
            "Agua normal 600 ml"
            "Agua con gas 600ml"
            "Limonada de panela org√°nica 350Ml"

        CUANDO PIDAN ACOMPA√ëAMIENTOS,Usa coincidencia aproximada para entender la intenci√≥n.
        PERO la respuesta final siempre debe ser un acompa√±amiento EXACTO del men√∫.:
            "Platanitos maduros"
            "Papas Coste√±as (francesas medianas + 4 deditos de queso coste√±o)"
            "Coste√±itos fritos + Suero Coste√±o"
            "Anillos de Cebolla"
            "Papas francesas"
        Acepta coincidencias parciales SOLO si es OBVIO que se refiere a un producto real.
        Nunca adivines si hay m√°s de una opci√≥n posible.
        si el pedido es general, no espec√≠fico, sugiere opciones del men√∫. siempre con un call 2 action.
        """
        promociones_str = str(promociones_lst)
        prompt = PROMPT_PEDIDO_INCOMPLETO.format(
            mensaje_usuario=mensaje_usuario.lower(),
            promociones_str=promociones_str,
            json_pedido=json_pedido
        )
        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-5.1",
            messages=[
                {"role": "system", "content": "Eres PAKO, asistente oficial de Sierra Nevada."},
                {"role": "user", "content": prompt}
            ],
#            max_completion_tokens=200,
            temperature=0.8
        )
        raw = response.choices[0].message.content.strip()
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] pedido_incompleto_dynamic_promocion tokens_used={tokens_used}", "DEBUG")
        try:
            data = json.loads(raw)
        except Exception:
            data = {
                "mensaje": "Por favor elige solo los productos de la promoci√≥n o inicia un pedido desde cero escribiendo 'menu' u 'hola'.",
                "recomendaciones": [],
                "intencion": "consulta_menu"
            }
        return data
    except Exception as e:
        log_message(f'Error en funci√≥n <pedido_incompleto_dynamic_promocion>: {e}', 'ERROR')
        return {
            "mensaje": "Por favor elige solo los productos de la promoci√≥n o inicia un pedido desde cero escribiendo 'menu' u 'hola'.",
            "recomendaciones": [],
            "intencion": "consulta_menu"
        }

def mapear_modo_pago(respuesta_usuario: str) -> str:
    try:
        """Mapea la respuesta del usuario al m√©todo de pago estandarizado."""
        client = OpenAI()
        PROMPT_MAPEO_PAGO = f"""
        Eres un clasificador experto en interpretar el m√©todo de pago que un cliente escribe en WhatsApp, incluso cuando lo escribe con errores, abreviaciones o de forma muy informal.

        Debes analizar el texto del usuario y responder exclusivamente uno de los siguientes valores:

        - "transferencia - nequi"
        - "transferencia - daviplata"
        - "transferencia - bre-b"
        - "transferencia - otro"
        - "efectivo"
        - "tarjeta"
        - "nfc"
        - "desconocido"
        - "datafono"

        Reglas:
        1. Aunque est√© mal escrito, identifica la intenci√≥n correcta.
        2. Si menciona:
        - nequi / neki / nekii / nequi bbva ‚Üí "transferencia - nequi"
        - daviplata / davi / dabiplya / daviplaya ‚Üí "transferencia - daviplata"
        - bre-b / breb ‚Üí "transferencia - bre-b"
        - ‚Äúmovil‚Äù, ‚Äútransfer‚Äù, ‚Äútransfe‚Äù, ‚Äúpse‚Äù, ‚Äúlo hago por el celu‚Äù, ‚Äúpaso por app‚Äù ‚Üí "transferencia - otro"
        - "datafono", "dat√°fono", "d√°t√°fono", "datafon" ‚Üí "datafono"
        3. tarjeta, tc, td, targta, tarjta, cr√©dito, d√©bito ‚Üí "tarjeta"
        4. nfc, acercar la tarjeta, contactless ‚Üí "nfc"
        5. efectivo, cash ‚Üí "efectivo"
        6. Si no puedes entenderlo ‚Üí "desconocido"

        Formato de salida OBLIGATORIO (JSON puro):
        {{
            "metodo": "uno de los valores permitidos"
        }}
        Aqui el mensaje del usuario:
        {respuesta_usuario}
        """
        if not respuesta_usuario:
            return "desconocido"

        prompt = PROMPT_MAPEO_PAGO 
        response = client.responses.create(
            model="gpt-3.5-turbo",
            input=prompt,
            max_output_tokens=60,
            temperature=0
        )
        raw = response.output_text
        log_message(f'Raw response de <mapear_modo_pago>: {raw}', 'DEBUG')
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] mapear_modo_pago tokens_used={tokens_used}", "DEBUG")

        # Normalizar y sanear la respuesta: eliminar fences de c√≥digo y espacios
        try:
            clean = str(raw or "").strip()
            # eliminar bloque ```json ... ``` o ``` ... ``` si existen
            clean = re.sub(r'^```json\s*', '', clean, flags=re.I)
            clean = re.sub(r'^```', '', clean, flags=re.I).strip()
            clean = re.sub(r'```$', '', clean, flags=re.I).strip()

            if not clean:
                log_message("mapear_modo_pago: respuesta vac√≠a despu√©s de sanear", "WARN")
                return "desconocido"

            # Intentar parsear directamente
            try:
                data = json.loads(clean)
            except Exception:
                # Buscar primer objeto JSON en el texto
                m = re.search(r'\{.*\}', clean, flags=re.DOTALL)
                if m:
                    try:
                        data = json.loads(m.group(0))
                    except Exception as e:
                        log_message(f"mapear_modo_pago: fallo al parsear objeto JSON extra√≠do: {e}", "ERROR")
                        data = None
                else:
                    data = None

            if data and isinstance(data, dict):
                metodo = data.get("metodo", "desconocido")
                log_message(f"mapear_modo_pago: metodo detectado desde JSON -> {metodo}", "DEBUG")
                return metodo

            # Fallback por keywords si no hay JSON parseable
            text = clean.lower()
            if "nequi" in text or "neki" in text:
                metodo = "transferencia - nequi"
            elif "daviplata" in text or "davi" in text:
                metodo = "transferencia - daviplata"
            elif "bre-b" in text or "breb" in text:
                metodo = "transferencia - bre-b"
            elif any(k in text for k in ("tarjeta", "tc", "td", "targta", "tarjta", "cr√©dito", "credito", "d√©bito", "debito")):
                metodo = "tarjeta"
            elif any(k in text for k in ("nfc", "contactless", "acercar")):
                metodo = "nfc"
            elif any(k in text for k in ("efectivo", "cash")):
                metodo = "efectivo"
            elif any(k in text for k in ("datafono", "dat√°fono", "datafon")):
                metodo = "datafono"
            else:
                metodo = "desconocido"

            log_message(f"mapear_modo_pago: metodo detectado por fallback -> {metodo}", "DEBUG")
            return metodo
        except Exception as e:
            log_message(f"mapear_modo_pago: excepci√≥n inesperada al parsear respuesta: {e}", "ERROR")
            return "desconocido"
    except Exception as e:
        log_message(f"Error mapeando m√©todo de pago: {e}", "ERROR")
        return "desconocido"

def solicitar_metodo_recogida(nombre: str, codigo_unico: str, nombre_local: str, pedido_str: str) -> str:
    try:

        prompt = f"""
Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
Te llamas PAKO.

El cliente {nombre} ya confirm√≥ su pedido con el c√≥digo √∫nico: {codigo_unico}.
Este es el pedido que hizo:
"{pedido_str}"

TAREA:
- Haz un comentario alegre, sabroso y un poquito divertido sobre el pedido.
- Estilo: c√°lido, entusiasta.
- M√°ximo 1 frase en tres lineas.
Despu√©s:
- Pregunta amablemente d√≥nde quiere recibir su pedido.
- Menciona el local: {nombre_local}.
- No saludes estamos en medio de una conversaci√≥n
- Lista ambas opciones:
  ‚Ä¢ Recoger en tienda
  ‚Ä¢ Env√≠o a domicilio (depende de la zona).
Incluye el c√≥digo √∫nico del pedido en el mensaje.
FORMATO ESTRICTO:
{{
  "mensaje": "texto aqu√≠"
}}
"""

        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": "Eres PAKO y respondes siempre en JSON v√°lido."},
                {"role": "user", "content": prompt}
            ],
        )

        raw = response.choices[0].message.content
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] solicitar_metodo_recogida tokens_used={tokens_used}", "DEBUG")
        # normalizar a str
        if isinstance(raw, dict):
            mensaje = raw.get("mensaje", "")
        else:
            raw_str = str(raw).strip()
            try:
                parsed = json.loads(raw_str)
                if isinstance(parsed, dict):
                    mensaje = parsed.get("mensaje", "")
                else:
                    mensaje = raw_str
            except Exception:
                mensaje = raw_str

        mensaje = mensaje.strip() if isinstance(mensaje, str) else ""
        if not mensaje:
            # fallback seguro (texto por defecto)
            mensaje = f"¬°{nombre}, tu pedido ({codigo_unico}) qued√≥ delicioso! ¬øVas a querer domicilio o prefieres recogerlo en el restaurante?"

        log_message(f'Respuesta de <solicitar_metodo_recogida> (mensaje): {mensaje[:300]}', 'DEBUG')
        return mensaje

    except Exception as e:
        log_message(f'Error en funci√≥n <solicitar_metodo_recogida>: {e}', 'ERROR')
        return f"¬°{nombre}, tu pedido ({codigo_unico}) qued√≥ delicioso! ¬øVas a querer domicilio o prefieres recogerlo en el restaurante?"
    
def generar_mensaje_confirmacion_modificacion_pedido(
        pedido_json: dict,
        items_menu: list,
        promocion: bool = False,
        promociones_info: list = None,
        pedido_completo_promocion: dict = None,
        model: str = "gpt-5.1",
    ) -> dict:
    """
    Presenta el pedido al cliente y finaliza SIEMPRE con:
    ‚Äú¬øDesea modificar algo de su pedido?‚Äù

    No realiza confirmaciones ni preguntas adicionales.
    """
    raw = ""

    try:
        client = OpenAI()

        # ------------------------------------------------------------------
        # PROMPT NORMAL
        # ------------------------------------------------------------------
        if not promocion:
            prompt = f"""
Eres PAKO, asistente de WhatsApp del restaurante Sierra Nevada, La Cima del Sabor.

RECIBES un JSON de pedido validado:
{json.dumps(pedido_json, ensure_ascii=False)}

Y una lista de productos del men√∫:
{json.dumps(items_menu, ensure_ascii=False)}

TU MISI√ìN:
1. Presentar el pedido al cliente:
   - Lista cada producto.
   - Incluye sus modificadores (si existen).
   - Muestra precios individuales.
   - Muestra el total.
   - No inventes productos ni precios.

TONO:
- Cercano, muy amigable y natural.
- Profesional y claro, sin sonar rob√≥tico.

RECOMENDACIONES (SI APLICA):
1. SI EL PEDIDO TIENE MENOS DE 2 PRODUCTOS:
   - Ofrece 1 producto adicional del men√∫.
2. OFRECER 1 acompa√±amiento, bebida o adici√≥n:
   - NO menciones el nombre exacto del producto del men√∫.
   - Usa descripciones gen√©ricas y apetitosas.
     Ejemplos:
       - ‚Äúunas papitas bien crocantes‚Äù
       - ‚Äúuna bebida bien fr√≠a‚Äù
   - S√ç incluye el precio real del producto.
   - No inventes precios ni categor√≠as.
   - Si ya hay bebidas no recomiendes m√°s bebidas.
   - Si ya hay acompa√±amientos no recomiendes m√°s acompa√±amientos.
   - Si ya hay adiciones no recomiendes m√°s adiciones.

CIERRE:
- Si das recomendaciones, finaliza exactamente con:
  "o ¬øtu pedido est√° bien as√≠?"
- Si NO das recomendaciones, finaliza con:
  "¬øConfirmas tu pedido?"

FORMATO OBLIGATORIO (JSON LISO):
{{
  "mensaje": "mensaje breve en lenguaje natural presentando el pedido y cerrando con la pregunta obligatoria",
  "intencion_siguiente": "preguntar_modificacion"
}}

REGLAS:
- No incluyas texto fuera del JSON.
- No uses emojis.
- No inventes productos, precios ni condiciones.
- No incluyas las descripciones de los productos del men√∫.
- Si el cliente pide papitas se refiere a una porcion de papas francesas.
"""

        # ------------------------------------------------------------------
        # PROMPT PROMOCIONES
        # ------------------------------------------------------------------
        else:
            if promociones_info is None or pedido_completo_promocion is None:
                raise ValueError("promociones_info y pedido_completo_promocion son obligatorios cuando promocion=True.")

            prompt = f"""
Eres PAKO, asistente de WhatsApp del restaurante Sierra Nevada.

RECIBES:
1) Pedido original:
{json.dumps(pedido_json, ensure_ascii=False)}

2) Pedido final con promociones aplicadas:
{json.dumps(pedido_completo_promocion, ensure_ascii=False)}

3) Promociones vigentes:
{json.dumps(promociones_info, ensure_ascii=False)}

TU MISI√ìN:
- Presentar el pedido final al cliente.
- Explicar brevemente cu√°l promoci√≥n aplica (si aplica).
- Indicar los precios finales por producto.
- No inventes datos.

FINAL OBLIGATORIO:
‚Äú¬øDesea modificar algo de su pedido?‚Äù

FORMATO JSON EXACTO:
{{
  "mensaje": "presentaci√≥n del pedido + pregunta obligatoria",
  "intencion_siguiente": "preguntar_modificacion"
}}

REGLAS:
- No uses emojis.
- No incluyas texto fuera del JSON.
- Tono c√°lido y profesional.
"""

        # ------------------ Llamado al modelo ------------------
        response = client.responses.create(
            model=model,
            input=prompt,
            temperature=0
        )
        log_message(f'prompt: {prompt}', 'DEBUG')
        raw = response.output[0].content[0].text.strip()
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] generar_mensaje_confirmacion_modificacion_pedido tokens_used={tokens_used}", "DEBUG")
        clean = raw
        clean = re.sub(r'^```json', '', clean, flags=re.I).strip()
        clean = re.sub(r'^```', '', clean).strip()
        clean = re.sub(r'```$', '', clean).strip()

        return json.loads(clean)

    except Exception as e:
        log_message(f'Error en funci√≥n <generar_mensaje_confirmacion_modificacion_pedido>: {e}', 'ERROR')
        return {
            "mensaje": "Hubo un error generando el mensaje.",
            "intencion_siguiente": "preguntar_modificacion",
            "raw_output": raw
        }

def solicitar_confirmacion_direccion(cliente_nombre: str, sede_info: dict) -> dict:
    """
    Genera un mensaje personalizado para confirmar la direcci√≥n de env√≠o,
    usando ChatGPT con tono c√°lido y cercano.
    """
    try:

        PROMPT_CONFIRMAR_DIRECCION = """
        Eres la voz oficial de Sierra Nevada, La Cima del Sabor.
        Te llamas PAKO.

        El cliente se llama: {cliente_nombre}.

        Informaci√≥n de la sede asignada:
        - ID sede: {id_sede}
        - Nombre sede: {nombre_sede}
        - Ciudad: {ciudad_sede}
        - Distancia desde cliente: {distancia_km} km

        Direcci√≥n detectada del cliente:
        "{direccion_envio}"

        TAREA:
        - Env√≠ale un mensaje c√°lido, alegre y amigable al cliente llam√°ndolo por su nombre.
        - Dale un contexto breve de que ya tenemos la direcci√≥n detectada.
        - Pregunta SIEMPRE si esa direcci√≥n est√° correcta para realizar el env√≠o.
        - Tono: amable, cercano, estilo ‚Äú¬°Hola {cliente_nombre}! Qu√© alegr√≠a tenerte por aqu√≠ üôå‚Äù.
        - M√°ximo 1 o 2 frases antes de la pregunta.
        - No uses groser√≠as ni sarcasmo.

        FORMATO DE RESPUESTA (OBLIGATORIO):
        {{
            "mensaje": "texto aqu√≠"
        }}
        Nada fuera del JSON.
        """

        prompt = PROMPT_CONFIRMAR_DIRECCION.format(
            cliente_nombre=cliente_nombre,
            id_sede=sede_info.get("id"),
            nombre_sede=sede_info.get("nombre"),
            ciudad_sede=sede_info.get("ciudad"),
            distancia_km=sede_info.get("distancia_km"),
            direccion_envio=sede_info.get("direccion_envio")
        )

        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres PAKO, generador oficial de mensajes c√°lidos y profesionales de Sierra Nevada."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=150,
            temperature=0.85
        )

        raw = response.choices[0].message.content.strip()
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] solicitar_confirmacion_direccion tokens_used={tokens_used}", "DEBUG")
        try:
            data = json.loads(raw)
        except:  # noqa: E722
            # fallback seguro
            data = {
                "mensaje": (
                    f"¬°Hola {cliente_nombre}! Qu√© alegr√≠a tenerte por aqu√≠ üôå "
                    f"Tenemos registrada la direcci√≥n: \"{sede_info.get('direccion_envio')}\". "
                    "¬øes correcta? si no lo es envianos la correcta"
                )
            }
        return data

    except Exception as e:
        log_message(f'Error en funci√≥n <solicitar_confirmacion_direccion>: {e}', 'ERROR')
        logging.error(f"Error en funci√≥n <solicitar_confirmacion_direccion>: {e}")

        return {
            "mensaje": (
                f"¬°Hola {cliente_nombre}! Tenemos la direcci√≥n: \"{sede_info.get('direccion_envio')}\". "
                "¬øEst√° correcta para hacerte el env√≠o?"
            )
        }

def generar_mensaje_invitar_pago(
        nombre_cliente: str,
        valor: float,
        duracion: str,
        distancia: float,
        direccion_envio: str,
        codigo_pedido: str,
        valor_total_pedido: str,
        model: str = "gpt-3.5-turbo"
    ) -> str:
    """
    Llama a ChatGPT para generar un mensaje cordial que:
    - Sintetice valor, duraci√≥n, distancia y direcci√≥n de env√≠o.
    - Invite al cliente a realizar el pago.
    """

    try:
        prompt = f"""
Eres un asistente amable de una hamburgueser√≠a.
Genera un mensaje CORTO, c√°lido y claro para un cliente.

Datos:
- Valor del domicilio: {valor}
- Duraci√≥n estimada del env√≠o: {duracion}
- Distancia aproximada: {distancia} m
- Direcci√≥n de env√≠o: {direccion_envio}
- Nombre del cliente: {nombre_cliente}
- C√≥digo del pedido {codigo_pedido}
- Valor total pedido: {valor_total_pedido}

Instrucciones del mensaje:
- Resume los datos de manera natural.
- Confirma que esa es la direcci√≥n de env√≠o.
- Invita al cliente a realizar el pago para continuar con el pedido.
- No inventes informaci√≥n adicional.
- Tono amable, profesional y cercano.
- Siempre di el codigo del pedido, valor del domicilio y total del pedido
- Di que estara en camino una vez se confirme el pago.
"""
        client = OpenAI()
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Eres un asistente de pedidos experto en atenci√≥n al cliente."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.5
        )
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] generar_mensaje_invitar_pago tokens_used={tokens_used}", "DEBUG")

        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"Error al generar mensaje: {str(e)}"

def generar_mensaje_seleccion_sede(nombre_cliente: str, model: str = "gpt-3.5-turbo") -> str:
    """
    Genera un mensaje personalizado con ChatGPT invitando al cliente
    a seleccionar una de las sedes disponibles.
    """
    try:
        prompt = f"""
Eres PAKO, la voz oficial de Sierra Nevada, La Cima del Sabor.
Tu misi√≥n es hablar de manera c√°lida, confiable y amigable.

El cliente se llama: {nombre_cliente}

Genera un mensaje corto y amable invit√°ndolo a escoger una de las siguientes sedes:

üìç **Sedes disponibles**
- Caobos: Cl 147 #17- 95 local 55, Usaqu√©n, Bogot√°, Cundinamarca

Instrucciones:
- Habla como asistente conversacional (no en formato t√©cnico).
- Menciona su nombre.
- Invita a seleccionar una sede.
- No inventes sedes nuevas.
- Se detallado con las direcciones de cada una
- No enumeres
- Pide que escriban el nombre de la sede para recoger
"""
        client = OpenAI()
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Eres un asistente experto redactando mensajes conversacionales."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.7
        )
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] generar_mensaje_seleccion_sede tokens_used={tokens_used}", "DEBUG")

        return response.choices[0].message.content.strip()
    except Exception as e:
        log_message(f"Error al generar mensae seleccion sede {e}", "ERROR")
        return f"Error al generar mensaje: {e}"
    
def mapear_sede_cliente(texto_cliente: str):
    """
    Usa ChatGPT 5.1 para identificar la sede mencionada por el cliente
    y retorna sus datos completos desde la BD.
    """
    client = OpenAI()
    # 1. Obtener sedes desde BD
    sedes = execute_query("""
        SELECT nombre, direccion, id_sede, latitud, longitud
        FROM sedes
        where estado = true
    """)

    if not sedes:
        return {"error": "No se encontraron sedes en la base de datos."}

    # Construir un diccionario para ChatGPT
    lista_sedes = [
        {
            "nombre": s[0],
            "direccion": s[1],
            "id_sede": s[2],
            "latitud": s[3],
            "longitud": s[4]
        }
        for s in sedes
    ]

    # 2. Prompt para ChatGPT
    prompt = f"""
Eres un asistente experto en normalizaci√≥n de texto.
Un cliente escribi√≥: "{texto_cliente}"

Tu tarea: identificar cu√°l de las siguientes sedes quiso decir el cliente.

Sedes disponibles (datos reales):
{lista_sedes}

        Reglas:
        - Debes devolver el nombre EXACTO de la sede seg√∫n est√° en la lista.
        - Si el cliente escribe con errores, corrige e interpreta.
        - Si escribe solo una palabra ("virrey", "galerias", "centro mayor"), mapea a la sede correcta.
        - Si no puedes identificar ninguna sede, responde "NINGUNA".

        Devuelve SOLO el nombre EXACTO de la sede, sin explicaciones.
        """

    # 3. Llamada a GPT-5.1
    completion = client.chat.completions.create(
        model="gpt-5.1",
        messages=[
            {"role": "system", "content": "Eres un asistente preciso para mapear sedes de restaurantes."},
            {"role": "user", "content": prompt}
        ]
    )
    # Registrar consumo de tokens

    nombre_predicho = completion.choices[0].message.content
    tokens_used = _extract_total_tokens(nombre_predicho)
    if tokens_used is not None:
        log_message(f"[OpenAI] mapear_sede_cliente tokens_used={tokens_used}", "DEBUG")

    if nombre_predicho.upper() == "NINGUNA":
        return {"error": "No se pudo identificar la sede mencionada."}

    # 4. Buscar la sede real en la tabla
    for sede in lista_sedes:
        if sede["nombre"].lower() == nombre_predicho.lower():
            return {
                "nombre_sede": sede["nombre"],
                "direccion_sede": sede["direccion"],
                "id_sede": sede["id_sede"],
                "latitud_sede": sede["latitud"],
                "longitud_sede": sede["longitud"]
            }

    return {"error": "La IA mencion√≥ una sede que no existe en la BD."}

def generar_mensaje_recogida_invitar_pago(
        nombre_cliente: str,
        nombre_sede: str,
        direccion_sede: str,
        valor_total_pedido: float,
        tiempo_pedido: str,
        codigo_pedido: str,
        model: str = "gpt-5.1"
    ) -> str:
    """
    Genera un mensaje amable para pedidos con recogida en sede.
    """
    try:
        client = OpenAI()
        prompt = f"""
Eres PAKO, la voz oficial de Sierra Nevada, La Cima del Sabor.

Tu tarea:
Generar un mensaje c√°lido, claro y corto para un cliente que recoger√° su pedido en una sede.

Datos:
- Nombre del cliente: {nombre_cliente}
- Sede de recogida: {nombre_sede}
- Direcci√≥n de la sede: {direccion_sede}
- Valor total del pedido: {valor_total_pedido}
- C√≥digo del pedido: {codigo_pedido}

Instrucciones del mensaje:
- Habla con tono amable y profesional.
- Di el nombre del cliente.
- Confirma la sede y su direcci√≥n donde recoger√° el pedido.
- Indica en cu√°nto tiempo puede pasar por √©l.
- Indica el valor total del pedido.
- Menciona claramente el c√≥digo del pedido.
- No mencionar domicilio ni distancias porque es recogida en tienda.
- No inventar informaci√≥n adicional.

Finaliza: Preguntando al cliente en cuanto tiempo pasara por su pedido
"""

        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Eres un asistente experto redactando mensajes cordiales y personalizados para clientes."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4
        )
        # Registrar consumo de tokens
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] generar_mensaje_recogida_invitar_pago tokens_used={tokens_used}", "DEBUG")


        return response.choices[0].message.content

    except Exception as e:
        log_message(f"Error en generar mensaje recogida invitar pago {e}", "ERROR")
        return f"Error al generar mensaje: {e}"
    
def extraer_info_personal(mensaje: str) -> dict:
    """
    Usa ChatGPT para extraer informaci√≥n personal del cliente
    a partir de su mensaje en WhatsApp.
    Devuelve un dict con campos tipo_documento, numero_documento, email.
    Siempre retorna un dict con las 3 claves; si no se extrae, el valor ser√° "No proporcionado".
    """
    try:
        prompt = f"""
Eres un asistente experto en extraer informaci√≥n personal de mensajes de clientes.
Un cliente escribi√≥ el siguiente mensaje: "{mensaje}"
Tu tarea: extraer la siguiente informaci√≥n si est√° disponible:
- Tipo de documento (ej: CC, CE, TI, PA, NIT, PEP, PT, RC)
Si te dicen Cedula de ciudadania, responde CC.
Si te dicen Cedula de extranjeria, responde CE.
Si te dicen NIT, responde NIT.
Si te dicen Pasaporte, responde PA.
Si te dicen Tarjeta de identidad, responde TI.
Si te dicen Permiso especial de permanencia, responde PEP.
Si te dicen Registro civil, responde RC.
- N√∫mero de documento
- Email
Devu√©lvelo SOLO en formato JSON EXACTO, sin texto adicional, por ejemplo:
{{
    "tipo_documento": "CC",
    "numero_documento": "12345678",
    "email": "correo@ejemplo.com",
}}
Si no encuentras un campo coloca exactamente "No proporcionado" como valor para ese campo.
"""
        client = OpenAI(api_key=get_openai_key())
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres PAKO, asistente experto en extracci√≥n de datos."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0
        )
        raw = response.choices[0].message.content.strip()
        # Registrar consumo de tokens
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] extraer_info_personal tokens_used={tokens_used}", "DEBUG")
        # Limpieza b√°sica de bloques ```json``` o ``` alrededor
        if raw.startswith("```"):
            raw = raw.strip("`").strip()
            if raw.lower().startswith("json"):
                raw = raw[4:].lstrip()

        # Intentar parsear JSON directo
        try:
            parsed = json.loads(raw)
        except Exception:
            # intentar extraer first JSON object with regex
            import re
            m = re.search(r'(\{[\s\S]*\})', raw)
            if m:
                try:
                    parsed = json.loads(m.group(1))
                except Exception:
                    parsed = None
            else:
                parsed = None

        # Normalizar salida garantizando llaves requeridas
        resultado = {
            "tipo_documento": "No proporcionado",
            "numero_documento": "No proporcionado",
            "email": "No proporcionado",
            "nombre": "No proporcionado"
        }
        if isinstance(parsed, dict):
            for k in ["tipo_documento", "numero_documento", "email", "nombre"]:
                val = parsed.get(k)
                if val and isinstance(val, str) and val.strip():
                    resultado[k] = val.strip()
        return resultado
    except Exception as e:
        log_message(f"Error en extraer_info_personal: {e}", "ERROR")
        logging.error(f"Error en extraer_info_personal: {e}")
        return {
            "tipo_documento": "No proporcionado",
            "numero_documento": "No proporcionado",
            "email": "No proporcionado",
            "nombre": "No proporcionado"
        }
    
def direccion_bd(nombre_cliente: str, direccion_google: str):
    """
    Genera un mensaje amable para confirmar la direcci√≥n guardada
    """
    try:
        client = OpenAI()
        prompt = f"""
Eres PAKO, la voz oficial de Sierra Nevada, La Cima del Sabor.

Tu tarea:
Generar un mensaje c√°lido, claro y corto para un cliente que confirmara la direcci√≥n que tenemos guardada en la base de datos

Datos:
- Nombre del cliente: {nombre_cliente}
- Direcci√≥n del cliente: {direccion_google}

Instrucciones del mensaje:
- Si la ciudad se repite simplificalo a una vez
- No saludes al cliente probablemente este en mitad de la conversacion
- Habla con tono amable y profesional.
- Di el nombre del cliente.
- Confirma la direcci√≥n que tenemos guardada la cual se usar√° para el domicilio.
- No inventar informaci√≥n adicional.
"""

        response = client.chat.completions.create(
        model="gpt-5.1",
        messages=[
            {"role": "system", "content": "Eres un asistente experto redactando mensajes cordiales y personalizados para clientes."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.4
    )
        # Registrar consumo de tokens
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] direccion_bd tokens_used={tokens_used}", "DEBUG")
        return response.choices[0].message.content
    except Exception as e:
        log_message(f"<direccion_bd>Error en generar mensaje confirmaci√≥n {e}", "ERROR")
        logging.error(f"<direccion_bd>Error en generar mensaje confirmaci√≥n {e}")
        return f"Error al generar mensaje: {e}"

def get_direction(text: str) -> str | None:
    """
    Extrae una direcci√≥n del texto del cliente usando el LLM.
    Retorna la direcci√≥n como string (si se encontr√≥) o None.
    """
    try:
        if not text or not isinstance(text, str):
            return None
        client = OpenAI(api_key=get_openai_key())
        prompt = f"""Eres un asistente experto en extraer direcciones de texto libre.
Extrae S√ìLO la direcci√≥n del siguiente texto y si no encuentras direcci√≥n responde como "No presente".
Texto: "{text}"
RESPONDE √∫nicamente con la direcci√≥n, nada m√°s."""
        response = client.chat.completions.create(
        model="gpt-5.1",
            messages=[
                {"role": "system", "content": "Eres un extractor preciso de direcciones."},
                {"role": "user", "content": prompt}
            ],
 #           max_tokens=80,
            temperature=0
        )
        raw = response.choices[0].message.content
        # Registrar consumo de tokens
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] get_direction tokens_used={tokens_used}", "DEBUG")
        if raw == "" or raw is None or raw == "No presente":
            return None
        # normalizar a string y limpiar backticks
        if isinstance(raw, dict):
            raw = json.dumps(raw, ensure_ascii=False)
        addr = str(raw).strip().strip("`").strip()
        if not addr:
            return None
        if "bogota" not in addr.lower():
            addr = addr + " BOGOTA, COLOMBIA"
        log_message("Direcci√≥n extra√≠da: " + addr, "INFO")
        return addr
    except Exception as e:
        log_message(f"Error en get_direction: {e}", "ERROR")
        return None

def corregir_direccion(direccion_almacedada: str, mensaje_cliente: str) -> str:
    """
    Usa ChatGPT para corregir o mejorar la direcci√≥n almacenada
    bas√°ndose en el mensaje del cliente.
    Retorna la direcci√≥n corregida o la original si no se puede corregir.
    """
    try:
        if not direccion_almacedada or not mensaje_cliente:
            return direccion_almacedada

        client = OpenAI(api_key=get_openai_key())
        prompt = f"""eres un experto en direcciones tu trabajo es corregir completar y revisar direcciones, debes comparar la que tenemos almacenada en nuestra base con el comentario proporcionado por el cliente y revisar si debes completar la direccion si es la misma o si debes cambiarla totalmente por ejemplo tenemos esta calle 1 #45 sur "esa direccion esta mal, por favor a esta "calle 45 23" debes cambiarla toda si tenemos calle 123 #53 sur y el cliente dice " es calle 123 #53 norte" debes modificarla y si tenemos calle 45 y el cliente dice falta sur oriente la completas como calle 45 sur oriente UNICAMENTE DEVUELVE LA DIRECCI√ìN COMO RESPUESTA NO DES EXPLICACIONES NI AGREGUES NADA APARTE DE LA DIRECCION
Esta es la Direccion almacenada: {direccion_almacedada} y este es el mensaje del cliente {mensaje_cliente}"""

        response = client.chat.completions.create(
            model="gpt-5.1",
            messages=[
                {"role": "system", "content": "Eres un asistente experto en correcci√≥n de direcciones."},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        raw = response.choices[0].message.content
                # Registrar consumo de tokens
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] corregir_direccion tokens_used={tokens_used}", "DEBUG")
        # normalizar a string y limpiar backticks
        if isinstance(raw, dict):
            raw = json.dumps(raw, ensure_ascii=False)
        addr = str(raw).strip().strip("`").strip()
        if not addr:
            return None
        log_message("Direcci√≥n extra√≠da: " + addr, "INFO")
        return addr
    except Exception as e:
        log_message(f"Error en corregir_direccion: {e}", "ERROR")
        return direccion_almacedada

def _extract_total_tokens(resp) -> int | None:
    """Extrae total_tokens de distintos formatos de respuesta OpenAI (robusto)."""
    try:
        # objeto con atributo usage (p. ej. chat.completions)
        usage = getattr(resp, "usage", None)
        if usage:
            return int(getattr(usage, "total_tokens", usage.get("total_tokens") if isinstance(usage, dict) else None) or 0)
        # dict-like respuesta
        if isinstance(resp, dict):
            return resp.get("usage", {}).get("total_tokens")
        # algunos wrappers exponen output_text y usage como dict
        return None
    except Exception:
        return None


def clasificador_consulta_menu(pedido_resumen: str) -> str:
    """
    Usa ChatGPT para clasificar si es una pregunta solicitando el menu o aclaracion de prodcuto
    """
    try:

        prompt = f"""
Eres PAKO, asistente de WhatsApp del restaurante Sierra Nevada, La Cima del Sabor.
Tu tarea es determinar si el siguiente mensaje del cliente es una consulta sobre el men√∫ o una aclaraci√≥n sobre un producto.
Mensaje del cliente: "{pedido_resumen}"
Responde SOLO con una de las siguientes opciones:
- consulta_menu si el cliente est√° preguntando por el men√∫ o dice que quiere ver el menu o que le des el menu o que le muestres el menu
- aclaracion_producto si el cliente est√° preguntando algo sobre un producto espec√≠fico.
BAJO NINGUNA CIRCUSTANCIA PUEDES USAR ALGO DIFERENTE A ESTAS DOS RESPUESTAS Y NO DEBES A√ëADIR NADA MAS.
"""

        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "Eres PAKO, asistente experto en clasificaci√≥n de mensajes."},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )

        raw = response.choices[0].message.content.strip()
        # Registrar consumo de tokens
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] clasificador_consulta_menu tokens_used={tokens_used}", "DEBUG")
        log_message(f'Respuesta de clasificaci√≥n: {raw}', 'INFO')
        return raw
    except Exception as e:
        log_message(f'Error en funci√≥n <clasificador_consulta_menu>: {e}', 'ERROR')
        return "error_clasificacion"
    
def get_name(text: str) -> str | None:
    """
    Extrae un nombre del texto del cliente usando el LLM.
    Retorna el nombre como string (si se encontr√≥) o None.
    """
    try:
        if not text or not isinstance(text, str):
            return None
        client = OpenAI(api_key=get_openai_key())
        prompt = f"""Eres un asistente experto en extraer nombres de texto libre.
Extrae S√ìLO el nombre del siguiente texto y si no encuentras nombre responde como "No presente".
Texto: "{text}"
RESPONDE √∫nicamente con el nombre, nada m√°s."""
        response = client.chat.completions.create(
        model="gpt-5.1",
            messages=[
                {"role": "system", "content": "Eres un extractor preciso de nombres."},
                {"role": "user", "content": prompt}
            ],
 #           max_tokens=80,
            temperature=0
        )
        raw = response.choices[0].message.content
        # Registrar consumo de tokens
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] get_direction tokens_used={tokens_used}", "DEBUG")
        if raw == "" or raw is None or raw == "No presente":
            return None
        # normalizar a string y limpiar backticks
        if isinstance(raw, dict):
            raw = json.dumps(raw, ensure_ascii=False)
        name = str(raw).strip().strip("`").strip()
        if not name:
            return None
        log_message("Nombre extra√≠do: " + name, "INFO")
        return name
    except Exception as e:
        log_message(f"Error en get_name: {e}", "ERROR")
        return None

def clasificar_confirmaci√≥n_general(pregunta_usuario: str, items, model: str = "gpt-4o") -> dict:
    """
    Usa ChatGPT para clasificar si la pregunta del usuario est√° relacionada con el men√∫
    de la hamburgueser√≠a o no.
    """

    client: OpenAI = OpenAI()

    prompt: str = f"""
    Eres un asistente que clasifica preguntas de clientes de una hamburgueser√≠a.

    Debes responder con un JSON EXACTO con la siguiente forma:
    {{
        "intencion": "intencion detectada"
    }}

    IMPORTANTE: TENER EN CUENTA EL CONTEXTO DE LOS MENSAJES ANTERIORES PARA DEFINIR LA INTENCION

    Las posibles intenciones son:
    - "solicitud_pedido":
    * si la pregunta del usuario est√° relacionada con agregar quitar modificar o solicitar productos del men√∫ de su pedido tenga o no tenga.
    * cuando el usuario conteste a si a las preguntas del agente sobre probar pedidos va aqui 
    - "confirmar_direccion":
    * si la pregunta del usuario est√° relacionada con confirmar o cambiar una direcci√≥n de env√≠o.
    * si el usuario dice si a la pregunta del agente cuando pregunta direccion va aqui
    * si el usuario afirma en un contexto con direcciones
    - "confirmar_pedido" : 
    * si la pregunta del usuario est√° relacionada con confirmar o  un pedido existente.
    * si el usuario confirma un pedido
    * responde si a la pregunta del agente de confirmar pedido debe clasificarse como confirmar pedido
    * si responde a la pregunta del agente de si su pedido esta bien con una afirmacion
    * Cuando el usuario confirme que su pedido esta bien como esta
    * responde si a la pregunta del agente de confirmar pedido debe clasificarse como confirmar pedido
    * CUANDO EL MENSAJE ANTERIOR DEL AGENTE TERMINE CON "o ¬øtu pedido est√° bien as√≠?" O "¬øConfirmas tu pedido? Y EL USUARIO RESPONDE AFIRMATIVAMENTE VA AQUI
    - "sin_intencion": Cuando no puedas detectar ninguna de las dos anteriores intenciones. 

    Este es el men√∫ completo si la pregunta incluye un producto del menu o se refiere a comidas o bebidas es relacionada:
    {json.dumps(items, ensure_ascii=False)}
    
    Ahora clasifica la siguiente pregunta del usuario:
    "{pregunta_usuario}"

    Devuelve SOLO el JSON, sin explicaci√≥n adicional.
    """

    try:
        response = client.responses.create(
            model=model,
            input=prompt,
            temperature=0
        )
        log_message(f'prompt: {prompt}', 'DEBUG')
        text_output = response.output[0].content[0].text.strip()
        # limpiar posibles fences/triple-backticks u otros prefijos
        try:
            text_output = _clean_model_output(text_output)
        except Exception:
            pass
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] clasificar_confirmacion_general_chatgpt tokens_used={tokens_used}", "DEBUG")
        # Extraer JSON dentro de fences ```json ... ``` o buscar primer objeto JSON
        clean = text_output or ""
        m = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", clean, flags=re.IGNORECASE)
        if m:
            clean = m.group(1).strip()
        else:
            clean = clean.strip()
        if not clean.startswith('{'):
            m2 = re.search(r"(\{[\s\S]*\})", clean)
            if m2:
                clean = m2.group(1)

        try:
            result = json.loads(clean)
            return result
        except json.JSONDecodeError:
            logging.error(f"Error al parsear JSON en clasificar_pregunta_menu_chatgpt: {clean!r}")
            log_message(f'Error al parsear JSON en <ClasificarPreguntaMenuChatGPT>: {clean}', 'ERROR')
            return {"clasificacion": "no_relacionada"}

    except json.JSONDecodeError:
        logging.error(f"Error al parsear JSON: {text_output}")
        log_message(f'Error al parsear JSON en <ClasificarPreguntaMenuChatGPT>: {text_output}', 'ERROR')
        return {"clasificacion": "no_relacionada"}
    except Exception as e:
        logging.error(f"Error en <ClasificarPreguntaMenuChatGPT>: {e}")
        log_message(f'Error en <ClasificarPreguntaMenuChatGPT>: {e}.', 'ERROR')
        return {"clasificacion": "no_relacionada"}
    
def generar_mensaje_sin_intencion(
        mensaje: str,
        items: list,
        model: str = "gpt-4.1-mini",
    ) -> str:
    """
    Llama a ChatGPT para generar un mensaje cordial que:
    - Responda a un mensaje sin intenci√≥n clara.
    """

    try:
        prompt = f"""
Eres un asistente amable de una hamburgueser√≠a.
Genera un mensaje CORTO, c√°lido y claro para un cliente.

Datos:
- Mensaje del cliente: {mensaje}
- Menu {json.dumps(items, ensure_ascii=False)}
Instrucciones del mensaje:
- Resume los datos de manera natural.
- No inventes informaci√≥n adicional.
- Tono amable, profesional y cercano.
- Responde la duda del cliente de la mejor manera posible relacionando el contexto entregado en los mensajes.
- Si no hay una duda pero hay una peticion relacionada al pedido intenta que describa su pedido lo mejor posible
"""
            
        client = OpenAI()
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Eres un asistente de pedidos experto en atenci√≥n al cliente."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.5
        )
        log_message(f'prompt: {prompt}', 'DEBUG')
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] generar_mensaje_invitar_pago tokens_used={tokens_used}", "DEBUG")

        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"Error al generar mensaje: {str(e)}"


def get_tiempo_recogida(text: str) -> str | None:
    """
    Extrae el tiempo en el que pasara el cliente por su pedido
    usando un LLM
    """
    try:
        client = OpenAI(api_key=get_openai_key())
        prompt = f"""Eres un asistente experto en extraer tiempos de recogida de texto libre.
Extrae S√ìLO el tiempo del siguiente texto y si no encuentras tiempo responde como "No presente".
Si el usuario menciona una hora especifica regresa la hora en formato h:MM (ejemplo 2:30 )
Texto: "{text}"
RESPONDE √∫nicamente con el tiempo cuando puedas convertirlo a minutos hazlo, nada m√°s.
EJEMPLO:
2 horas -> 120 minutos
1 hora  -> 60 minutos
30 minutos -> 30 minutos
15 minutos  
media hora -> 30 minutos
en una hora -> 60 minutos
faltando 20 para las 9 -> 8:40
faltando 15 para las 3 -> 2:45
a las 7 y 45 -> 7:45
a las 8 y media -> 8:30
8:30
2:15
7:45
"""
        response = client.chat.completions.create(
        model="gpt-5.1",
            messages=[
                {"role": "system", "content": "Eres un extractor preciso de tiempos de recogida."},
                {"role": "user", "content": prompt}
            ],
 #           max_tokens=80,
            temperature=0
        )
        raw = response.choices[0].message.content
        # Registrar consumo de tokens
        tokens_used = _extract_total_tokens(response)
        if tokens_used is not None:
            log_message(f"[OpenAI] get_direction tokens_used={tokens_used}", "DEBUG")
        if raw == "" or raw is None or raw == "No presente":
            return None
        # normalizar a string y limpiar backticks
        if isinstance(raw, dict):
            raw = json.dumps(raw, ensure_ascii=False)
        name = str(raw).strip().strip("`").strip()
        if not name:
            return None
        log_message("Nombre extra√≠do: " + name, "INFO")
        return name
    except Exception as e:
        log_message(f"Error en get_name: {e}", "ERROR")
        return None